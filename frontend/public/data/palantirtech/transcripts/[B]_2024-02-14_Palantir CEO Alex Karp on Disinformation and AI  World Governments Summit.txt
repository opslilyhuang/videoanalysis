================================================================================
METADATA
================================================================================
Title: Palantir CEO Alex Karp on Disinformation and AI | World Governments Summit
URL: https://www.youtube.com/watch?v=umANP9Ev2B4
Published: 2024-02-14
View Count: 87,503
Duration: 1281 seconds
Score: 62.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

It is great to have you, Alex, when it comes to big data analysis, few companies have tracked the sort of path that Palantir has done, which employees its technology to solve problems of national security, military tactics, former CIA director David Petraeus has described your company as transformative in its impact on counterterrorism. For those who don't know, and I'm sure most of you do here, for those who don't, this was co-founded, what 2003, some 20 years ago, by yourself and Peter Teal, given much of the work that you do is with governments and consequently is somewhat shrouded in secrecy. I think Palantir is at one scene as a fascinating company and at the same time quite frightening, but I certainly accompany that is full of intrigues. I'm absolutely delighted to get this opportunity with you today. Let's start with a very simple question. When do you stick in a pin in the map of emerging technologies and say, AI arrived? When was that? It captured the public imagination with large language models. And then we, because of precursor technologies we built, we had a huge advantage. That's why the US commercial market for us is a bananza. But yeah, but it's about, there's a lot of counterintuitive things about this revolution. But one of, in fact, it's almost all counterintuitive, which is why it's so confusing for most people. But one of them is the starting point of it is not the starting point people realize. And then on the winners, losers, it's just very different than any other revolution. And that's why it has to be approached in a way that is with fresh eyes. So let's talk about the winners and losers as you see them now. Because that will help us, perhaps, debunk some of the, perhaps, confusion that people have for them. Well, part of the confusion is purposeful, because US tech is the dominant player. And in the US context, they don't want anyone to know. Because if you're the only people getting rich, you kind of try to hide that. Then I would definitely view this country as, it's very counterintuitive to the word say US Emirates, or US because of a lot of the technologies are built there. But if you wanted to just do a simple diagnostic of who's going to win and who's going to lose, take this conference, print out the agenda and the people who attended, and measure every other conference against this. And what you'll see is just a minute, they had the right people, they had the right topics, they had the right waiting of topics, they had the right understanding of the issues. Even there, this just shows you, this is an expression of an underlying understanding of what the technology is. And that is inconceivably valuable in a world where very, very few people understand what the outlines of what large language models are, what they can do, what they can't do. Then in America, we have the problem that this is a revolution that will raise GDP. But at the same time, the relative delta between the poor and the rich is going to get even greater. So that's something no one wants to talk about. Then you have the problem, say in continental Europe where you're basically pretending the revolution isn't happening because the providers aren't from there. And then you have a culture like this one where you have a small number of people. It's much easier to, who are very technical. And then the whole issue of this isn't going to really help everyone as much as it will help a small group of people. That's not a problem. So you have identified as we start to look at winners and loses. You've identified the US and the Emirates. And I know you're not doing that because we're sitting here. I mean, you've clearly defined why it is. I view one of my smarter decisions as investing here over a long period of time, primarily with my own energies and with our office. But it's, this is a revolution where small beats big. So that's what you saw in the battlefield. That's what you see. Small smart already in tech outperformed large, not as smart basically. Where smart here means knowledgeable. And but this is basically that times a thousand. So you predicted, I think it was just last month at Davos, that within a decade around 95% of the world's top tech companies will be American. Due to what you describe as the US lead in AI. So let's just be very clear about what it is that positions the US. Well, it's currently like 84% of the top 50 companies. But that's purely, yeah. So well, it's very hard to explain why these things work, why they do, why they don't. But the simple thing is, the large language model, even technically, it's, it pen tests means it is actually putting pressure on your enterprise, on your culture. And the stronger and more robust your product already is, that's the unfairness of it. It's like if your product is already strong, if your culture's already strong, if your society's already strong, you leapfrog. It very much exposes weak products, weaker institutions, lies in your institutions, thinness in your institution to make a large language model actually work in a consumer environment. So like we power almost 20% of hospitals in the US two years ago, we powered almost none. And it's because you need tech, you need to be able to interact with the large language model without exposing your data, provide tooling to it. So it's no longer a genius idiot. So you can task it with things while being able to constrict where it has access to and where the access control model, meaning who gets to decide, is not eviscerated. And so these are all things you would already need an enterprise, just very few enterprises have them. And it's very similar culturally, if your people are technical and educated and loyal, you can build on top of that base and you just go like this. And then you have just again the inequality of all of it, which is very hard for people to accept. But that's an inequality defined in a way that is historically maybe not as relevant. Well, there are implications, of course, for nations that don't have access to the same level of technology. How can we strike a balance in embracing the innovation of artificial intelligence and establishing regulations that ensure privacy, security, ethical considerations, and equity at the end of the day? Why not? It isn't an imbalance. I'm interested in people that are aligned with America and people who run just in wonderful societies win. So there's the balance side of it. That's what we're taught to believe. I'm not interested in balance. I'm interested in winners. The winner is winning. And then there's the equity side of it. It's like, how do you deal with it in America? The obvious reality that while GDP will grow, the people who are in this business are going to be 10, 100 times wealthier. And that's very hard to explain to a society. How do you build partnerships on the defense side with allies where you share the IP we've built and they can build on top of it? Which we're doing. So we're giving to allies or selling to allies, infrastructure that will allow them to use AI that they build. So there are ways to share in the proceeds and in the actual benefits. But I don't think the idea that we, everyone wins is it all going to work. And I'm definitely not part of that view. What does a commercial space look like for you? And what are you taking from the work that you have done, which has today been majority government led into the commercial domain? I just want this audience to get a real sense of where you see the opportunities. It was historically commercial, in talk about two years ago. Now, certainly if you do customer numbers, it's primarily commercially led in the US. And what I'm learning is, there's just a lot of products out there that are, it's poetry. Like you just get poetry. So, and people doing all sorts of power points. But if you show up to customers, I go all over America and I say, take all your best products, everything you've done, any vendor, and then compare it to what you can do in Poundchair in 10 hours. And you're basically comparing, it's unfair because you're comparing a poetry to like, I want to task a satellite to tell me when weather conditions are going to affect my agricultural product. I want to task, I want to task my enterprise to tell me when churn is likely to happen into these contexts. I want to be able to have a right function in this part of my enterprise. I'm interested in margins or in the hospital context. You know, I want to more efficiently allocate and more justly allocate beds. I want to make sure that doesn't happen on class race background. I want to get nurses and doctors involved. And then the margins are completely different. You can do this within weeks. And so, then the use case I'm most excited about and commercial is, you can take culturally specific manufacturing. So, we power a battery company from Japan in America. So, you can build the factory like it was built in Japan. You can teach workers and manage those workers and have them manage production as if they were Japanese workers, but with cultural identity in this case, American could be Emirati. So, de facto, you can now build things that could only be built in one culture in another culture. And so, this has incredible, almost incomprehensible impact on cultures. Because now, it's like, well, we could only build ships in the past in this one culture. Yeah, but now you can build them in Kansas City. And you can build them with workers who are not as technical. And you can do this. So, you know, that alone changes the GDP of cultures. It changes the ability of cultures to invest and do things that were not possible in the past. There is some authentic concern out there, which I wonder whether you sympathize with, empathize with, have any consideration for. The risks of outsourcing data analysis and decision-making based on data analysis to a machine algorithm. Do you see a risk in our seeding decision-making control to large, powerful AI models who, of course, while smart, are not human? Look, there are... There's the general risk of what happens when the computer takes over. Then there's the intermediate risk, which is what you're talking about. But again, the risk you've outlined is architecturally controllable. Your enterprise, for example, our product will allow you to granularly control what things are controlled by the computer, what things are controlled by algorithms. There's something in software called a right function, meaning who gets to have the decision? This can be controlled down to this individual, sub-individual in this role, but you need the right products to do it. A lot of the concerns in this area are because your software is software that was built for a world that was non-disjointed, peaceful, where your software product was primarily sales, where you were not... I did not have an enterprise where software and software defined products, both in military and commercial, powered to some extent by AI, where that was not the case. One of the big problems with reducing everything to a moral discussion is, in many cases, the moral discussion is actually masks intellectual and commercial engineering ineptitude. These are engineering problems. Is this about messaging then? Is this about communicating? No, it's about the engineering actually working. It's not a messaging problem. It's again why a small culture, whether Silicon Valley or the Emirates massively outperforms a larger culture because there are moral and equity issues here, no doubt. But a lot of the issues we pretend are moral are actually engineering. Who controls the AI under what conditions can it write to something? What kind of decisions can be made on the battlefield? Who gets the side between life and death is very similar, not morally, not intellectually, but technically, who controls where the satellite flies? Who tasks the satellite? Is a human? Is it a computer under what conditions? Should it be? Well, there's a lot. It depends the context. So, you know, if you're running a massive agricultural arm, you probably want the business person to say, I want to expand this amount of resources on satellite coverage in return that's not a moral decision. It's a competence decision. If you make it incorrectly, you will be defeated by the person installing a better product. You were very bullish about the states. You've said that you see that as the US with regard to tech as a winner going for it. You've name checked the Emirates and you've been, you know, not so enthusiastic about Europe, for example. I spent half my life. Like I want Europe to win. We need to admit. The first step in winning is recognizing where you're at. And so, like, you have to... Yeah. Can I then just... It's not because you've been very bullish about the states. And yes, you and your longtime deputy, Nicholas Zamiska, running a new book, The Technological Republic. It promises to be a sweeping indictment of Silicon Valley, as I understand it. And you've talked about Silicon Valley having lost its way. Well, that's lost its moral way. Like the primary mistake Silicon Valley makes is that because the obvious truth that a lot of the high quality revenue of the world is going to flow to Silicon Valley, Silicon Valley has decided to obfuscate that by embracing the thinnest, most obvious half lies ever produced that are only there to make you feel comfortable at the fact you're losing while they migrate all high quality revenue to... What's the explainment you mean by that? You know, do... Well, let's pretend we're doing nothing bad while running companies that reduce your intellectual acuity down to some kind of fake affiliation that to which you don't belong. I mean, it's like over and over and over and over again. But the more important thing to understand is it is a way of explaining to the world, I win you lose, but you get to pretend you're happy because you get to participate in an ideology that doesn't work. And again, what the book is actually about, and it's not that it's like, how do you raise a civilization where people have an ability to repel these obvious half lies? And there are many ways to do it. One way is to have enormous internal integrity in your culture, like the Emirates. Another way to do it is to teach classic liberalism or embrace religious backgrounds. The way we've done it, the way we're doing it in our elite culture is the haves convinced the almost haves that they're participating in something they're not participating in. And by the way, this has massive technical consequences because then the leaders embrace things that will never work technically because they feel like the thin ideology that they've embraced will also work technically. And in fact, you have to go very deep to understand the actual underpinnings of an enterprise of technical products and how they work. And it's that laziness that the comfort with laziness that will undermine your company, your culture, your society, and everybody who's interested in full alignment with their company, culture and society has to find a way to fight against it. And that's what it's actually about. And that's what you see in our, in all modesty in our products. There are metaphors for fighting back against that. You are a warrior for Western values for democracy. Democracy around the world is under attack. And we face what are a standard thing. The primary thing that is eviscerating democracy. It's always produced as like, I'm not against fighting fake things. It's you have to fix actual problems. Democracy is not an excuse for having nothing that works. If it does not work, nobody is going to buy into it. And one of the most important things we have to push back on is, you know, oh, it can't work because we have these five things that don't work. Nobody has time for that. We are in very dangerous times. Every part of your society actually has to work. How do you define work? I put in a dollar, I get more than a dollar out. That's working. It's not working. And you know, the people who pervade that massively underestimate the intelligence of the people they're talking to. People have no time for that. And if you're spending time on this, you know, we invest lots and nothing happened and we invest more and nothing happened. It's not the input. It's the output. And it's like we need a relentless focus on that across the world. And that is the only thing that will stabilize this society. And everything else just mess. Malfunctions, misfunctions, corroge your society and produces the worst people ever because only the people who use that to advance themselves understand it doesn't work and understand they can manipulate people by that. It has to be fought against at every element. And to that point, Alex, I just want to close with this because I'd be remiss if I didn't ask this. There are growing concerns about AI's role in the sort of disruption that we see around the world at present. False and misleading information fueled by AI was top of the global risks report released at Davos. This year, does do you share these concerns? Was it the top of a lot? OK, good. Top of a list of, I compare this conference to that conference. I don't want to guess like it's just yes. Of course, it's a problem. But the primary problem is not disinformation, which I'm against and I would help fight. But the primary problem is that the people listen to it because primary functions of their government aren't working and they're asking themselves why doesn't it work. And so you have to fix those underlying functions. Pretending that is the primary risk democracy is a totally a backfire move. Of course, it's a risk. Of course, it should be dealt with. Of course, security services should fight this. And the power and influence into a country is illegal unethical and should be fought. And I would be happy to help out fighting that. But the primary risk to society is not fake information. It's a society that's willing to believe the fake information because they're wondering, why doesn't my school work? Why doesn't my border work? Why haven't I been taught things in school that don't work? Why do I know nothing about software? Why am I being told that poetry will pay my bills when in fact it's not even good poetry? It's like that is the primary risk to a society. And all this other stuff is just a way of saying, I can't deal with the primary problems. I can deal with the secondary problems and it won't work. I wish we had more time. We don't. We're out of time. Alex Carp, co-founder and CEO of Palantir Technologies. We thank you very much indeed for joining us this morning.