================================================================================
METADATA
================================================================================
Title: Q&A Discussion | Palantir CEO Alex Karp at FoundryCon US
URL: https://www.youtube.com/watch?v=9BpKijrg9iw
Published: 2023-02-07
View Count: 16,490
Duration: 1798 seconds
Score: 55.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

As Sasha said, thank you all for coming. I think this is a great way to open up with some thoughts from you, some questions from the audience. You know, we were recently in Switzerland. You had a fireside chat like this with Mr. Rubenstein. He had a lot of questions about your hair. I'm not going to ask any questions in that line of questioning because it's a bad road for me to go down. But I think that you should see his wig. It is baller. He doesn't wear it in front of customers because it's kind of melts under the light, but it's otherwise. But one of the other things that came up there was the announcement of the... Lock word laughs. They really wanted to see the... I was making notes of you fall. They wanted to see the... It comes in curl, straight, all sorts of... You announced the new foundation there. But by the way, you... How long have you been a palancier? Last time we did this with the journalist, which I thought very well done, but then one of our thoughts was to bring in a veteran so that you can also kind of see the dynamic. So, you've been a palancier for nearly... 14 years. Yeah. And now you're head of our oil and gas. Yeah. Okay. Any case. So now we can go to your question. Escape the government basements when the business we had was national security and defense only and now in the energy and oil and gas space. Yeah. And so your question was about... The foundation. If you can talk about the intent and vision. Well, you know, we'll probably talk more about it, but we started our company with Clandest and Services in the United States, built certain data protection capacities that meant it was the only product you could really buy in Europe. And so even though we're not acknowledged in many European countries, almost all the anti-terror work happens and there and then we're involved in finding terrorists all over the globe with that product. And then we built Foundry and Foundry ended up being the platform for COVID distribution in the US and Britain and saved millions of lives, especially under privileged lives. And now we're involved in supplying... We've been involved in supplying software to the US Special Forces and US Army and allies for the last 15 years, but then supplied a software package that is responsible for most of the targeting in the Ukraine. And so in that process, we've learned a lot about what it means to build and implement enterprise software for large institutions, which is very different than building it for the consumer internet. We've learned about how does an institution assess effectively or not effectively software. And I believe that the central advantage the US has is its ability to build technology and implement software, especially enterprise software. We've seen this of late educating especially our leaders so that a larger portion of our $850 million spend on defense, which I support, goes to things that are differentiated, meaning Russia and China are not as good at building them. And some of that obviously will auger to our benefit, but most of it's really just... I spend half my life abroad, so it's probably easier to see what's so special. But I can tell you, if you're running around Germany, no one can understand why almost all the interesting, if not all the interesting software companies are within a 300 kilometer radius of here or started here. That's just a really special thing, and we want to help legislators and others understand that. Talking about the 300 kilometer radius from here, one thing that I think is interesting in looking at the past few years is that 2021, a lot of our customers who build things sell things, put them out, went through sort of a winter during COVID. No one was flying, the oil price went negative for a period of time. And if you look at it now, a lot of those businesses are now booming. Everyone's back traveling, everyone's back moving around, people can't supply enough, right? And tech is going through its own winter around here. How do you think of those two worlds coming together and then how do we fit into both of those? Well, I mean, of course the mature answer would be something like, yes, you know, I don't know, tech will learn to grow and it's a maturing process. And I don't know, I'm probably someone wrote talking points for me, something like that. It's, you know, tech has really failed America in so many ways, especially consumer internet. And we don't like to talk about it publicly because it's kind of embarrassing. But tech in America, you know, dual purpose technologies, what Silicon Valley was was building things largely for the military, repurposing them for civilians. And that powered a lot of what it made America and makes America really interesting and powerful, including in my view, our moral expansion because it's much easier to get along with people if everybody is happier and wealthier. And then you had this movement recently where tech, with exceptions and, you know, it's been very focused on, you know, turning each one of us into a product and pretending they love us because they say banalities that none of them believe, even if they're true, they don't believe them. And so, you know, it is hard to be generous to tech, plus most people in tech are not that likable. And so it is just like obvious banalities, I don't know, we've not somehow, you probably kind of think they're going to get, you know, it has to be a better reminder. But it, and then, but one of the, there's two problems in tech. First of all, you know, it's like some of the companies really are not, like the tech is just not deep enough to be valuable in bad times. It's maybe interesting and good times. And second of all, it's just psychological. If you, most people in tech, you know, went from being unpopular in high school to believing they would own the high school. And it's, it's just not, it's very hard for people to tech to accept that it's going to be a bad couple of years. I think that is actually helpful for tech because maybe we can go back to a world where tech is fully aligned with its customers. And, you know, even on the national security front, for years and years we're the only company that insisted on working with the US government in this town. You know, I'm not in favor of everything the US government does, but, you know, so I, I think that will lead to a process. And on, on the other hand, I'm very happy for all of you that it's better times, you know, it's like those are really hard times. I think there are a lot of lessons learned. We believe that hard times exposes real technical challenges, our product will work better. But then we want to grow with our partners and, you know, into good times. And we believe that in good times and bad times, just like we've done in national security and work, you can really win big. You know, we like to partner and win, not partner and we moderately, you know, humble, hop forward. Yeah. One of those, I think, another contradiction in my mind is, you know, we, your mid-year letter, we talked about being incumbents, but we don't look like incumbents in the defense space. We talk about building products five years ahead of when they're needed or multi-year sort of visions. But as Sasha mentioned before, you talk a lot about dividing timelines in half, dividing them by five. From the outside, those can appear to be contradictions. How do you explain? Well, they are contradictions. Our company is a series of contradictions. We, we partner, we want the institutions that exist now to win. So we're very much on the side of existing institutions. But we believe that, you know, the way to do that is to innovate. We look for long-term partners. We, we're an engineering organization that must interact, say, in the government with mostly non-engineering organizations, which is, is, is often hard. You know, I've, I've joked to nearly, I, I spent half my life telling important people in Washington other places. I'm sorry that my engineer said the most inappropriate thing at the most inappropriate time. They didn't mean to tell you the truth. They, they really didn't mean it. They, they, please, please forgive us. And we have an incredibly, interestingly, partly crew of some of the more talented people in the world who, you know, sometimes we struggle to communicate internally. And then we're working on these deep problems that require teamwork. We build these products that like PGA would change the world on counterterrorism. The whole list I gave you and some that I hope will. And then most exceptionally, just the way the war has gone in the Ukraine, which is mostly, obviously, that my view, the hero is in the Ukraine and their tenacity, but, you know, our product, according to reports, is responsible for changing the way targeting is done. But these products are built before anyone believes they're useful. So that's put us under enormous pressure. We are, we're a public company, which means we have a responsibility to our shareholders. I believe our most important shareholders, some of you are in this room, are kind of smaller shareholders who put their own money up. And so, and at the same time, we run the company where our primary responsibility is to a higher good, which in my view is helping the West win. So that, and we build the products for that. And there's a famous saying in the valley, ask for money, get advice, ask for advice, get money. And I think a lot of these contradictions work because if you're really working to a higher goal, it's much easier when the person in front of you, you know, you're going to run a view and behind you and next to you that you work day, they're like driving you nuts to actually say, well, okay, they drive me nuts, but we're going to get this to work. And even in our relationships, like any real long-term relationship is going to have miscommunication and difficulty. How do you get beyond that? How do you get to the actual substance of problem? You need kind of a cultural bridge of some kind. And we have a strong culture inside our company, which allows us to also work with other strong cultures because we recognize a strong culture on the other side. So it's a series of contradictions. I mean, we didn't even have salespeople until recently. We just, I was talking to, I don't know what we call, Samir, but like our nominal head of sales, or I don't know, we don't really have titles, but it's like we have a hundred accredited, meaning they've sold something salespeople in US commercial. And this is a business we haven't given fourth quarter results, but it's a business is doing well, very well. And so like we're at the way, we don't even know how to do basic things. Like, what is a business, business, sales? So it's like, and yeah, and so there's just a long and long list. And that's even the public version of contradictions. I have lots of other ones. I can share with you guys over coffee or tea or champagne or something. You mentioned Ukraine, there briefly. I want to ask one question about that before we open it up to questions from the audience. We've mentioned quite a few times in interviews that you think a turning point there or a sort of very dynamic combination is advanced technology with individual heroism at the front lines. And I think as someone who spent time in the intelligence and defense space, the motivation for coming to this company was a company that works in that field. For a room that is largely people in the commercial and private sector, what do you think that looks like for commercial entities with that same technology, but what is that version of bravery or heroism? Well, first of all, you know, there's a lot of rifts on the Ukraine, but one of them is just the most obvious is it's like, no one thought they would do this well. We thought they might do this well because we've seen that technology in the hands of very competent, driven people. Now they're in a war zone and they're putting up their lives and people, you know, so it's a different thing than what we're doing or what most of us in the room are doing. But we've seen that how disruptive technologies can be and we've seen this multiple times because we have, we've launched multiple products that have literally changed the dialogue on, you know, as mentioned, CT, COVID data protection, how terrorism, all sorts of data management and all sorts of industries. And now modern war fighting, where we're essentially integrating AI on the battlefield. And I think one of the big banalities is, you know, most people up until recently somewhat correctly suspected that the software either wasn't working or wouldn't work or wouldn't be useful. They didn't think a battle would be one in part because of software. Not only in part, I mean the heroism, you know, I think the way what we're doing, we're going to find in the next five and ten years is that, and this is where I think American industry and industry that is, where America has a lot to teach the world, you have to adapt, find things that work, implement them very quickly, iterate with a partner you trust and build something really new and disruptive. And then you can do it so quickly the adversary doesn't realize it's coming, doesn't believe it's going to come by the time you've done it, it's done. So it's like a lot of these things that like, you know, I mean the Ukrainians were implementing and using our software like within hours. So it's like, you know, but the thing is, this dialogue, this kind of dialectic of your competition may still be stuck in a world where this is not determinative. And that's just a huge advantage for people who move. And I actually think this is just an advantage for companies that are either in America or learning from America because America is this adaptive capacity that is unique. And I've found a lot of my life abroad, historically half our businesses abroad with some of the best partners in the world. And we learn a lot from them, but this like testing, if you just look at what America's gone through from like, you know, five years ago, it was all power points and now it's a lot of its churning data, but we're moving to like running your business from analytics and AI, business decisions, down to implementation. And there are a lot of hidden problems there that you have to iterate to understand. So I think this is just another example of, you know, software is eating the world and it's eating it for a good reason. Yep. Great. Let's open it up to questions from the audience. Hold on a second. They'll bring a microphone over. Yeah, I was like, should I yell out the question? Nice to be here. Thank you so much for the invite. I'm from Microsoft. My name is Priya Narayan. I had a question related to the Ukraine war. It's a modern warfare. And obviously we know it's technology driven. I had a question with respect to this where Panty is going with all of the algorithms. Do you have an algorithm to shut down the nukes in the future? Well, that's a different kinds of technologies that we partner with people that maybe could do things like that. We're still very much on kind of like, you know, the still pure software side, which in my view should be 5% of the US budget is not that. What I would say on that is, you know, there's a lot of talk about AI because it's now clearly moving into something that is not away from something that was once clearly a fraud. And Palantir, as is relics, it's an open secret that Palantir has been involved in the US government's most important, some of the US most important AI offensive capabilities. And my personal view is I had Russia actually understood. In fairness to Russia, I'm not in the business. I don't think anyone understood how powerful these capabilities were. You wouldn't have had this war. And then it makes that nuclear conflict a lot less likely. So, but yeah. Hey, Dr. Carp, how's it going? Also really privileged to be here. So thank you. My name's John Birch. I work at PG&E. My question is, you know, I've my experience with the platform has been really fun. And one of the things I like about it is that it really incentivizes kind of a social aspect. So I find foundry to be like much more of a social platform than any other data platform I've used. And so I'm curious if you could speak a little bit to kind of how important that is to you and what's your vision for kind of increasing that kind of like incentivizing collaboration and other things within a company that's using your tools. Oh, thank you for the question. You know, just so you know, you don't have to call me. It's Dr. Carp. I only ended up being Dr. Carp because in the beginning we had no money, no revenue, no clients, and no one would invest in us. The only thing I had was this, I was a doctor and something by the way which is German philosophy is not that relevant. But I'm very happy to be honored, you know, 20 years later as Dr. Carp makes me, you know, I still turn around and think my dad is a pediatrician. I'm like, what's my dad doing here? He's still judging me for not being an academic, still being judged. You know, the interesting thing about PowerCheer platforms is it is both social and not social. And so the part that is social is like, look again, if you look at what makes attack company work, why are there so many tech companies here? Okay, well, I spent a lot of my life in Germany and like, various things. I don't think Mike's experience is the people at Stanford I knew and the people at Germany, I knew were the same level of intelligence at least. So, and there are lots of other cultures. It's because Americans find ways to work together in teams and that's how you get all the insights into a product and then systematic work over five, six years. But then what's built into our product often in the callandescent space particularly valuable, you can then have a subset of people you work with and a subset of people you don't work with is otherwise called civil liberties protection. And that's also crucial because you can't advance one of the mistakes technically is you have a blob like a data lake where everyone has to see everything or doesn't see anything. And that also is in collaboration. First of all, even if you were allowed to do that, you might not want to do it. And even if you wanted to do it, who then has the rights to then make the decision is also a big issue because you want to simultaneously have dialogue but then the decision making capabilities have to be defined and controlled especially since impalenture you could actually make decisions. But to your point, in the end, the reason why our counterterrorism product changed the world, especially in Europe and my view stopped Europe from moving very far to the right because it was able to stop terror attacks within the context of data protection. The reason why we were able to distribute COVID vaccines and PPE so effectively and the reason for these other worst successes is we are giving a technology that represents a culture that will work when that culture is crucial because of the macro conditions. And then in general, we have some of the most interesting and difficult people in the world. So I honestly love seeing you guys. Also, I really like meeting our clients and partners but it's also like day out of jail. People are so reasonable. It's like, we want to succeed and if it succeeds, our parent hearings are a lot less reasonable. But it's like you're building a culture of like, well, what would make a company like yours more effective? You would actually need to have access to all the data, be able to dialogue around it. But people have different levels of technical complexity. They have different rights to the data. They should have different rights to data and then in many contexts, this is regulated or should be regulated. And so the vision of that really was a vision we articulated 20 years ago as that this will be the vision for how data is managed. And because the vision was so difficult, you had to rebuild like PG product, we rebuilt how software works. And that's why, and then it's the same with all these other products we're delivering. And then what happens when we're successful is macro condition comes together, culture, especially adaptive cultures morph to those macro conditions, but they morph to the macro conditions in a way that's also constrained. Like no regulated large institution or less regulated is going to allow everyone access to all data under all conditions where everyone has a right to write to the code base. That would be presumably not ethical and it would destroy your company. But on the other hand, you really do want the person on the ground to be able to say, hey, but this is a stupid decision, Dr. Carb. Your decision is really dumb. Let me show you why, which is again my day at Palantir. But yeah, so I think like in the, and like this is again, it's like in the war-fording context, you see this because one of the things that's made the Ukrainians so successful is they have morphed their culture to how we'll be thought in the future. Our product helped them do that, but it's like it's also, it's just not going to be fought the same way and the same thing on the front line in your companies. So yeah, that's a big part of what we're actually doing. By the way, we're very bad at articulating this. So it's like very grateful for your question because it's like we tend to just like sell the engineering. Now where we've been reasonably good at it is like if you read the data protection, the legislation promulgated around the world, it literally looks like what our product was built to do. So there is a way and when you do it, people are like, oh, this is possible and then they codify it. But I would say where we get a very, very failing, great at Palantir is we, we're like, we're doing all these things. We just don't buy their detainee, buddy. And we need people to like actually use them and show people in the world because that's how you get to change. And on the last note, you know, it's like we are in a weird way like a societal movement that is a business as well. And so that's like I find it very, very gratifying when we hear that we're not changing your culture but we're augmenting it and then you're changing our culture because we're learning from you like, okay, well this worked, this didn't. Matt. May I get a spoon? Gordon from Pfizer. A generative AI, this kind of conversational AI. We're seeing it with chat GBT and open AI. Where do you think that's going? Are you going to incorporate some of those capabilities into foundry? We partner with lots of technologies and pretty much open to partnering with whatever you guys want to partner with. I think my personal slightly off the record view is something like, and there's a lot of AI in the military, some of which should not be exported, some of which should be. And so while we'll be partnering, I'm sure one department with lots of companies, it's like the bigger issues going to be for us. What are the ethics around AI? Like for example, like, first of all, there are huge ethical issues on the battlefield. If you use an algorithm to generate a military decision and it goes wrong, he's responsible. What is the delegation process once the war starts? What are the ethics of deciding if you go to war? Can you do that with augmented techniques? When you're at war, what are the constraints to our adversaries, do our adversaries pay attention to these screens? If not, what does it mean for us? And then what sorts of technologies can you bring into the civilian context? Because in the civilian context, you have lots of other hugely legitimate concerns around like ethics, data protection, discrimination. And because of our work in the counterterrorism context over the last 20 years, we have a lot of views about what you should do in a civilian context and what you should not be able to do. And then the interesting thing is there's just this constant while AI is becoming more and more important, there are like, well, what powers the AI? Does the AI stock have segmentated data so that you can prevent the algorithm from making horrifically a moral decision? By the way, how would you know what the inputs are into the AI algorithm? So you have to know. Even if you don't care, let's just say you don't care. You will have to care. Like in your business, you will have to care what went in there because a regulator is going to ask you, well, what were the variables that went into this decision that allowed you to make ABC decision? The regulator is very likely not to be that technical. So you're going to have to show them in the data stack where the how is the decision made? So these are all sorts of things we're going to be very, very involved in both from a tech implementation part and also in our work as like our foundation and other things. Explaining to companies and legislators, I was just in DC like one of the biggest questions that people are asking is like, okay, well of course we want to use generative algorithms or AI in healthcare context. But how do you do that without violating legal and ethical norms? Let's just, even if you got rid of the legal norms, which none of us will be able to do or presumably want to do, you would still have enormous ethical issues around this. And those issues are actually, one of our biases is many ethical issues are actually technical issues. And we're in the business of being able to delineate those ethical issues while enhancing your performance. So it's like one of the unfortunate debates you have in the civil liberties context is you have like this bivirication where one side is like, well, you're going to have to have terrorism and unfortunately you may die. And the other side is no terrorism but unfortunately your personal lives are personal life. And I don't want either. And so what our products should do, what our products do do is allow you to solve terrorism and protect data or use AI in your context of the kind of work you're doing without violating norms. And importantly, arguably unfortunately, or unfortunately, show it to a regulator because otherwise your whole business is going to get shut down. And that's something that we were natively involved in over the last 20 years. By the way, this also ends up, you know, the people think I got involved and we got involved in data protection for mostly the right reasons. I believe in it. I don't think you can solve terrorism. You're never going to get consensus in terrorism. The consensus is, yeah, but we're going to take away civil liberties. And you're not going to have a functioning society if you don't stop terrorism. So that was my logic in the beginning and we fought against investors who were like, why the f are you investing in this? It's going to be a money loser. But it's post 9-11. But there's also kind of the business reasons why I believe this is crucial for our business. There's a learning process like we saw this in CT. We've seen this in healthcare. We're now seeing an AI where everyone's like, oh, I want the results. And you need those results. However, you are going to find the results have to be done within a context that requires a really robust platform that takes five, six years to build. And so it ends up being a business bonanza for us. And that's the wrong reason why I'm very involved in this. The beginning was a 100 percent moral and I fought against some of the more interesting people in the world that it is. And now, just like whenever we build a new platform, I want to know, well, how is the data segmented, how are we protecting data, how are we making sure, and it gives me better cards with my progressive family. But that's not the reason why I'm working on it every day. So with that, thank you very much for coming. Real pleasure to have you here.