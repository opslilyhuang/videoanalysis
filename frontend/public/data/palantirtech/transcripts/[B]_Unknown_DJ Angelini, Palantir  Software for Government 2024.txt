================================================================================
METADATA
================================================================================
Title: DJ Angelini, Palantir | Software for Government 2023
URL: https://www.youtube.com/watch?v=4Gr8n7Jl08k
Published: Unknown
View Count: 0
Duration: 0 seconds
Score: 37.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 其他
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Hi, everyone. My name is DJ Angelini. I'm a senior architect in our federal business here at Palantir, and I'm excited to talk today about the investments that we're making to help companies in the defense tech ecosystem deliver mission critical capabilities at scale. Over the last 20 years, Palantir has delivered foundational technical infrastructure. That's modular, open, and capable of accelerating the time to delivery for critical government missions. And we do this in a variety of ways. Try and make complex software delivered in complicated form factors as quickly and easily as possible, whether that's classified cloud regions, on premise environments, air-gapped environments in the edge, as well as enabling access to core enterprise data and core enterprise insights with data security and appropriate guard rails in place. All of this was developed through years of forward deploying our engineering efforts in the field, getting the job done, learning, and incorporating that back into how we develop and how we deploy software. In our mission now is to bring the technologies that have made that possible, that have allowed Palantir to scale in these domains to the broader defense community. We believe this is vital to ensuring credible deterrence of our adversaries as we heard earlier this morning, and is driving force behind our recent announcement of Palantir government web services, which is our investment in accelerating the defense industrial base. You've heard from others in the session about the capabilities of Apollo and the Fed Start program, which help companies enable complex software deployment and development for innovators and defense. In today, I want to share some technology that we've been building that helps expand the integration surface area beyond the underlying infrastructure and into the core data foundation, the core data fabric, which we call the ontology. Our goal is to expose the defense ontology, one that we've spent years of building through data integration, refinement, and iteration, to enable first class interactions with those that have the authority and mandate to access that data via our ontology SDK. The ontology SDK provides access to the full power of Palantir's ontology technology directly within a developer's development environment and ultimately their external applications. Native integrations with the ontology allow apps to leverage the robust features that come with it. So, the ability to map and understand the relationships between various entities within an organization. The ability to perform high-scale queries, searcher rounds. The ability to both codify and exercise foundational organization logic through right back and so much more. In applications that integrate with our ontology, inherit the robust and granular access controls relevant to the underlying data. Things like row and column level access controls. Implementation of security markings that identify PII or PHI data. Classification based access controls and more. The ontology SDK accelerates the integration and helps to securely develop applications that can power critical mission outcomes and going to show you a little bit of the couple of ways that we help do this. So to start off, using the ontology SDK technology, developers can build first class interactions that based on data that's relevant to a mission's particular application context. In this video, a user has published an application interface that's specific to a particular workflow. In this case, related to space domain awareness. While the ontology for organizations that we work with are incredibly large and incredibly complex, the SDK app integration allows you to configure only the information necessary to meet a given purpose within this application framework and help integrate external applications just on this core set of data. This is really security by design. The ontology SDK uses a token that's scoped only to the entities that you want your application to access for its purpose and automatically intersects those permissions with those of end users, allowing you to safely scale app development and deployment across your enterprise. In addition, these interfaces are version controlled and allow upgrade and downgrade mechanics, which is incredibly important when we're integrating external apps with the ontology because the ontology and application needs evolve over time. On top of demonstrating our application creation and configuration, our OSDA configuration automatically generates domain-specific developer documentation relevant specifically to this app integration. All of the metadata that enriches the ontology is presented to end users and the ontology relationships pre-load sample queries with domain-specific context. For example, in this demonstration video, I am looking at a sensor site object, which is natively linked in the ontology to sensor task objects. In the API documentation, we auto-populate this relationship for the end developer. So external developers can copy these code snippets not just though that they work, but they make sense within the organization's data model. We know they make sense because they've already structured them in their ontology. They've modeled that relationship up front. These snippets can be generated in TypeScript, Python. You can generate raw curl commands, and we're looking to expand the perimeter of this technology across the board. So once I've generated an application integration that's scoped to the data that's necessary to meet my app's mission, understand the data domain through purpose-built data documentation. And gotten familiar with my data domain, I can quickly integrate that data into my external applications using ontology-aware development. Here we're looking at a custom external application that I've developed. And let's say I want to populate this left-hand panel with some information that's stored in my ontology. If I open up the code for this app in my IDE, I can quickly start using ontology metadata to fast track my development efforts. Here my NPM package is installed and I can immediately get to developing. As I write my code, information about my ontology is auto-populated with all of the rich information that exists within my ontology description. So entity names, descriptions, documentation. And it's brought to me within my IDE. I don't need to leave my development environment to access it. Without ever leaving the developer interface, the ontology is brought to me with autocomplete into. In this example, I want to materialize information that I have about sensor sites. I want to filter down to particular types of sites and provide some front-end polish on top to make this information clear and clean within my UI. After just a few lines of code, the information is immediately available in my friend-end application. In data loads within my application, automatically integrated with all of the robust granular permissions that are stored in my ontology. Without ever a developer needing to implement complex security logic in their application development. Here I can now explore the application, see the information, and interact with it in real time to read from and write back to my data foundation. On top of that, OSDK also natively integrates with Palantir's AIP capabilities as well, which many of you have heard about throughout the day. And we have an AIP showcase downstairs. I encourage you to check it out. But here I built an AIP logic block using a service called AIP logic. And this logic block takes information about a sensor, looks to linked entities and information about that sensor, to understand relevant intelligence context, information about its location, et cetera, to help propose to me a potential tasking event that I as an analyst can initiate within my application. AIP combines the power of generative AI, a robust ontology, and tools available to execute complex computation in the platform. But with two lines of code, I can integrate this AI interaction directly into my external application as well. On top of this logic block and on top of our ontology. Really bringing generative AI capabilities and generative AI decision making to interfaces within and outside of Palantir. So here you can see when I execute this query, we're interacting with our AIP platform and getting generative AI assistance in initiating a new sensor tasking request. What I've shown is just a glimpse of our OSDK tech and just one of the ways we're expanding Palantir government web services. On the horizon, we've been incredibly excited to announce witchcraft, our next open-source project, which is an application server that can help enforce and maintain some of the really difficult to manage standards that make deploying in government context hard and bootstrapping even harder. And the keep-it-believe described are only the start of what we plan to provide for the defense tech ecosystem. We're committed to enabling our customers and partners where they want to leverage our harder and experiences of delivering to the government and create more seeds at the table to meet the important missions that are facing our government today. Thank you. Awesome. So that concludes our lightning talks. Thank you all. Thank you to our earlier speakers, Martin Craig, for their incredible demos of their products. Let's give them a round of applause. I encourage everyone to take another look at your schedules for the afternoon tracks. They will start shortly. And I'll be around throughout the day if you want to chat further about our Entology SDK. Thank you all.