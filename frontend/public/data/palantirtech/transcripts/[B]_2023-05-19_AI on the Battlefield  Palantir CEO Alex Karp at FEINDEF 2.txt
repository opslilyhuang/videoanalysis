================================================================================
METADATA
================================================================================
Title: AI on the Battlefield | Palantir CEO Alex Karp at FEINDEF
URL: https://www.youtube.com/watch?v=HergHd1lnbM
Published: 2023-05-19
View Count: 38,424
Duration: 2777 seconds
Score: 45.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Good afternoon, everyone. Dr. Alex Carp, volunteer CEO, is one of those who are obviously in the defense industry who requires no introduction, but at the same time deserves a long one, because he and his company are often misunderstood by the media, the public and some experts. So I hope in this conversation we will have the opportunity to dispel some of the misconceptions and myths around Palantir. In 2003, Alex Carp, founded Palantir alongside Peter Thiel, Stephen Cohen and other entrepreneurs, and it has served as his CEO since then, 20 years now. He's been a degree from Stanford, a law degree from Stanford, and a PhD in philosophy from Geth University in Germany, where he studied under the great German philosopher, Jörgian Habermas. His profile is quite unusual, both in the tech and in the defense fields. But under Mr. Carp's and orthodox leadership, Palantir has grown and evolved and has become one of the main providers of big data analytics software powered by the state of the art artificial intelligence. His AAP platform is trusted by government agencies, armies, law enforcement organizations, and Western companies alike to provide better and faster making decision processes. Palantir was named after the scene stunts depicted in the Lord of the Rings. These were seven mythical gems, which allow the user to communicate and see far away, even into the future. Palantir's platform is not magical, but some of its functionalities may appear to be so. So during the next 45 minutes, we will have an engaging conversation with Mr. Carp, and confident that he will share with us some insights into Palantir's work, its platform, his vision for the future. Ladies and gentlemen, thank you very much for being here and please welcome Dr. Alex Carp. Thank you. Thank you. Okay, Mr. Carp, you were among the few business people and analysts that forso they were in Ukraine. And despite the skepticism, a general skepticism among military and geopolitical pandits, what actions did you take to ready Palantir for the conflict? What lessons can we, the defense community and the defense industry learn from your experience? Well thank you, I'm very happy to be here. It is true that we were very palantirian when it has come to world events. But we built these software platforms five, six, ten years before people believed they were valuable. And so we've been working on AI in the context of organizing the battlefield and identifying enemies for the last. And depending on how you look at it the last five, ten years. And then we, I believe that software that is not ready for the battlefield or cannot be tested on a battlefield or a battlefield simulation should not be purchased. So we, we've been focused on that for a very, very long time. I think the big lessons for the world are less so for the, I do think there are, the lessons for the defense industry governments are much more software is determinative AI can have a material and will have an increasingly material effect on the battlefield software that exists on PowerPoint or paper or is being built by hand arguably is unlikely to be valuable. It's also very expensive. I think the bigger lessons for society though are we, we, we, we have about 30% of Western society in my estimation most people in my family, most people I studied with that believe pretty in a philosophical I would even argue theological way that in the absence of armaments. But countries will in kind of what would be called in technical terms, auto poetic meaning they will self-generate peace. And then this is a very big serious well thought through position that happens to be completely theological. And so it, and because it's theological one has to respect it, understand it, give great sympathy to people who purvey it. It's, it's very heartfelt. It's sure there are people who take advantage of people who believe that mostly far and intel services. But it's not, it is truly, they're truly, they're truly convinced of it. It's not performative. And it's, it's completely wrong. And it, besides being wrong, it, but even wrong is the wrong way to frame it because it's an internal theological system. So you can't really say a theological system is wrong. But the application of it to the real world creates huge dangers because in fact the rule of law is backed by military power. And the reason we have rule of law and border integrity is because as a last resort or even better as a deterrent those rules are enforced. And it's not this self generating Kantian mechanism that theologians of the radical peace doctrine or peace doctrine believe that it will exist without, without inability to defend it or even without, I would say, military superiority. You, you even traveled to, to keep to meet President Zelensky being the first CEO to do so. Palantir is well-known for deploying its staff along the clients, even when those users are literally in the trenches. So what was your experience there? Do you think it was useful for Palantir's role in the world or your child to keep? Because I imagine your insurance company went crazy about this. Well, you know, I didn't, you know, Palantir's involvement in war zones and in Ukraine is, I wouldn't say, you should say necessary. Again, if you believe that the very fundamental moral, fundamental basis of our society depends on being able to have a deterrent or in the worst case scenario defend yourself. You look at, you look at Ukrainians and their leader as very special people who are courageous, courageous in a way that, you know, might experience there in very kind of small discussions where everyone I met was aligned and willing to fight and put their life on the line. So, you really, if you're in the business of defending the West's values in real terms, so not in an argumental context of a philosophy debate, but on the battlefield, it was very important for us, Palantir, to offer what we have both most importantly on the software front, but, you know, also, and in going to see them and just support moral and also, quite frankly, to help chain other CEOs into going. It's like, you know, if you're really supportive of Ukraine, why haven't you gone? What are you doing with your products? Now, maybe some of those products don't really work, so, but the ones that do, and also the moral support. And what's going to happen after the war, you know, so we really, I really want to point our best foot forward. You have said, and I quote, that artificial intelligence has gone from fraud to junk to becoming crucial and critical in the world. But still many people, even some experts don't truly comprehend how this works. Can you provide that with some? Well, actually it's interesting to just use your RIF on experts. So, I think if you look at experts as a term, which basically means this became true five years ago, and it's now consensus now, that's how you earn money as an expert, mostly. Because if it were true, and you knew it five years ago, you would build a business around it. So, if you just take the term, you have, of like, expert, and you said, experts were right 10 years ago when they thought it was a joke. And IEI, they were, they were already wrong about being software, being determinative. But they were, but, but then in the last five years, the experts, and this is why quite frankly, they're almost no useful AI tools in a product form on the market. They're just very, very, very few. Because those experts have enormous power, and they control investing decisions in the venture community, they control capital allocation in the context of, of, of the capital markets. And so, that's been an enormous advantage to us, because these experts are provide consensus, when the consensus is consensus, after a couple years. But it is the case that what's now determined among the battlefield, meaning being able to, as an example, identify an adversary in a very large country that's hidden, being able to then do an Intel operation in software, in conformity with legal and moral norms, is one of the most important things that you can have now. Even against an adversary, as in the Russian case, which has been spending $65 billion, roughly a year for decades, and is well known for being its military acuity on the battlefield. Can you provide us some specific examples or use cases of artificial intelligence on the battlefield right now? Well, you know, a lot of this you have to read about, and there's some really good things that are written about this. But it has been written that there's a 20 to 50 times delta between what was available on identification of adversaries, and what is available now. I tend to think that underestimates how valuable this is, because the knowledge-based compounds, so it ends up being maybe even at some point in order of managing more than that. But I think you can read the news. Read the news. Many people here also involved inside governments doing really important work in the context of NATO. You can read the private feeds of how this actually works. I have the opportunity to see a demo of the platform, and I have to say that with great power, it comes great responsibility. How can we ensure that artificial intelligence technologies such as volunteers do not pose a risk for our civil rights and our privacy, and at the same time allowing the platform to do its job? Well, you know, in the least in America there are two schools, basically. Those that think still that large language models are a joke, and then you have those of you, those people who believe that large language models and AI are proposed a fundamental danger to humanity. And I kind of have a third position, which is that they're very, very dangerous potentially. But we have super, super effective adversaries, and if we don't invest in this, they will, and we currently have an advantage. So people who tend to think they're dangerous, and people who, you know, in a weird way, I'm aligned with them because I do have real concerns about how you use algorithms and large language models in the west context of western governments so that they do not eviscerate the civil liberties that make what we, this is how we live in better. And there's a lot that goes into it, and I don't want to derail here, but large language models, which is what in civilians are focused on, military is focused, arguably, it's a very interesting method of debate is everyone's focused on large language models, and we are too at balance here. But the most important operational uses of AI have been on the battlefield, and they're using more generative AI, which is closer to just a different kind of math. But large language models can tell you a lot about the world rapidly, efficiently, but really can't tell you how they got to the conclusion, which makes their use in inside western democracies. And even on the battlefield, quite difficult, you're not going to authorize taking out an adversary without understanding the data feeds that went into it, you're not going to arrest somebody nor could you without, nor should you be able to, without understanding the data feeds that went into it and which ones didn't. So, as everyone who's living in a constitutional democracy knows, the utilization of the data requires ethical and legal navigation. And even on very basic things like exposing health records to a large language model, that's not legal, not ethical, and not desirable. Your soldiers and operators have a right to privacy as well. And by the way, are going to be very unhappy implementing something that eviscerates that legitimate right of privacy. And so, a lot of those things are very, very counter-intuitive. It does happen that we've been building tools to deal with those issues for the last 20 years. And we are rolling them out, especially actually in US commercial, where there's just a really strong demand for products that are really products. Do you have gold that the country or the countries with harnesses the power of the artificial intelligence with shape, our geopolitical future? So, I want to know what's your opinion on how our strategic rivals in China are doing in this field? Well, you know, this is a very legitimate question. And the classic answer is to this question that you're going to hear a thousand times is, and then China is very advanced on internal AI and certain kinds of AI. And Russia is an incredibly intellectually advanced country with some of the best mathematicians in the world, if not the best mathematicians in the world. So, there is, so the classic answer is, you should be scared, and therefore we should spend more, which my answer is, we should be scared that we don't focus on our own enterprises and where we're ahead. And this is why I'm spending a lot of time in America trying to convince leaders that 1% of our DOD budget should be spent on software that's productized, where productization means it's been used on the battlefield. And you get extra points where it's been sold to any commercial client at least twice. It's like, because we have an enormous advantage in the large language model context and the algorithmic context. But we tend to spend, and again, I'm very in favor, I don't know that you obviously need hardware. But why is it that such a small portion of our budget goes to the thing that we are differentiated at as opposed to things where we're arguably less differentiated. And then where there's spend on software, it's almost on software that's being built by hand. And it gets tested on the battlefield after it's built, which is a very dangerous way to do software. And then it's so valuable that no commercial clients ever bought it. It's like, you know, if you have a software business and you have 200 million in revenue or 20 million in revenue, honestly nowadays you have some flimsy product with 20 million in revenue and you can claim it's AI because it works. But that's arguably you will get like a billion two billion dollar investment if you know how to navigate venture people, which is largely telling them they're stupid all the way through the process. Okay, so just what we have to start asking a question. If all these people are building software for prob, I don't know, call it a hundred two hundred billion dollars a year globally. Why am I the only company in the world with a US commercial market that's growing almost 70% despite me as a frontman last year. Okay, so you should ask yourself ask the people supplying software. This looks really valuable. Has it been tested? What commercial client has ever used this software, any software product you've ever built? Commercial defined as they are not government. By the way, I'm not saying commercial software is better. I'm not saying you should only buy or even majority buy from commercial vendors, but we have to ask and answer these questions and ask and answering these questions will put us significantly far ahead of our adversaries so that we don't have to focus on their terrible situation. And we have structural advantages building a large language model in our authoritarian context can be very hard teaching that model all the 50,000 things that can't ask answer data feeds that cannot. It's very, very hard, which is why our adversaries would love us to talk and spend tons of time talking about how we can't we can't implement these things we can't implement these things. And then people who don't have products tell us that they can't implement these things. So it's like, you know, it's funny. I tell people this, but we spend a lot of time providing and energy investing in things that scare adversaries. But I'm very, I have a huge admiration in in those adversaries and that admiration should lead us to saying, how do we invest where we are legitimately better than they are? Well, many people perhaps recognize, uh, Palante for its knowledge involvement in capturing the Latin. The perhaps it's left known that your sub word your platform has evolved and has been addressing all the global crisis of the moment from the war on terror in the United States, but also here in Europe to border control to natural disaster relief. Then the fight against the pandemic now the war where Palante is not only supporting the Ukrainian armed forces in planning operations and the quality of military targets, but also it's helping NGOs to manage the interests of refugees and also activists to investigate war crimes. What's next for Palante in this path of evolution? What are you working right now that you can share with us? Well, yeah, we're, I mean, our biggest focus right now is just rolling out the things we've built to wield large language models, getting that into a form where we can scale it, embarrassing people who purvey our purveyors of power points. But honestly, care about that a lot less than commercial. I do care when you know people go to governments. You know, we don't really spend a lot of time. It's like we're building these things whether it's again the the dynamic knowledge model so that you can the large language model can actually understand your enterprise, the security around it, the handoff function. Seeing if some of the things we built in the context of like that knowledge model can actually make larger language models more reliable in the intermediate data range. So not with small data sets and not with infinite ones where there's could be a lot of value and there's not a lot of focus. And then we rely on our unfortunate bias that the world is getting more dangerous, more disjuncted, and the more dangerous and more disjunctive it is, the more valuable powerful software will be. So it's not like we didn't predict the value of foundry for COVID. We didn't. It's true. I thought that the war in Ukraine would happen, but I didn't think years ahead. I just thought when I saw the data. But the products that are useful in these contexts, you know, we're building on it. Now we're, you know, again, we're scaling US commercial. Really with a very, very nascent new and learning how to do it Salesforce at a pretty anomalous rate for any company, but for a company that is 20 years old, completely shockingly exceptional. And with, and as a company that's primarily focused on value, not on sales, I believe in end of one. For public appearances and interviews, you have a stress that the importance of know how versus money and that meeting powers, such as Spain, other southern European countries can leapfrog their security and their defense game with the right tools. Palantir has been working here in Spain for four years. What can you tell us about the work you're doing here? And from your perspective, are we doing it right? That we working on it? I've been told I can't say anything about our role in Spain. I have to try. So that's what I've been told. And we have Palantirians out here waiting to jump on stage. There's a whole list of words and things that they're ready to intervene on every and any second. But my guidelines here were Spain is a wonderful country. We know it very well. I love the food. I understand when I'm being yelled out in Spanish, which is true. And I'm very happy to come here and we have people who like us. We can't mention. That's what I was told to say. I understand that so there in Europe plays a role in the global strategy of Palantir. Yes. Well, again, I'm very bullish again without mentioning anything about individual users of Palantir. But what I've seen in this country is the people we interact with are very strong partners. So they it's a very direct feedback loop. We have deep experience on the implementation of anti-terror products, products for special forces, products for identifying enemies. So the dialogue is one of like deep knowledge, but also willingness to ask us how would you use these products effectively. And then there's a lot of engineering talent here. I think Spain is probably underestimated in the depth of engineering talent. We don't underestimate Spain. And it's been, and quite frankly, my parents are working here with our Spanish clients. And it may be a bigger problem that like everybody who speaks Spanish wants to be here, including some people who barely speak Spanish. It's like, go to speak Spanish and like, where did you learn it? Well, I've watched some movies in English. Some songs. Palantir recently achieved profits last year. And again, it's expected that you stay in profit all this year. And Palantir's goal in your own words is to become the leaders in constitutional and ethical use and monetization of AI in America within two years. Well, I think we're the leader already, but in two years, you're so-called experts will acknowledge it. So I was like, you know, yes. And by the way, one of the things that you're, I think, alluding to you, though, is I, you know, if you say like ethical AI, it sounds like you, I don't mean you, but it sounds like, oh, AI, that doesn't work. But what we actually mean is in the military context, AI that's deadly scares the bjeebers for trying to use less foul words out of our enemies. And it's precisely dangerous because it can work within a framework that is allowed within our countries. So you've access to every bit of data. You're allowed to have access to, you're not allowed to have access to data. You can use proprietary data, but in a way that is segmented. It's an interesting thing and very counterintuitive, but it's not that the ethics and the efficacy are in contradiction. It's that the efficacy and the ethics are linked and are in a kind of a relationship where they can only be a combustion agent where they confront each other. And so it's not like one of the things that people believe, and I don't want to fight about all the time, because it's like they believe if you got rid of the ethics, you would have better AI. But in reality, like if you look at adversaries, getting rid of the ethics would mean actually in their way of seeing it, imposing weird odd non-ethical constraints on the large language models, and they won't even work. And also in the commercial context, certainly in the US, but a non-ethical AI is not implementable in your enterprise, so it's completely academic. And the chief issue you have as an enterprise is that while you're convinced your enterprise has world-class software, the person down the street who had a business much weaker than yours is going to out-implement you, financially with our products, and going to change the margins of their business to such an extent that you are going to have a competitive disadvantage, you may not be able to dig your way out of. Anyway, the variability of outcome is something that Europe needs to think about a lot, because the American landscape is going to commercial, so less relevant and less important than some of the issues we're dealing with. But the variability of willingness to try technology, so we have very big European clients and they're embracing it, but as a generalization, this is going 5, 6, 7 times faster in America, and the effect on efficiency, safety, margins is going to be enormous. And I view myself as, I spend a lot of my life in Europe, parts of my family, lived in Europe for a thousand years. We have to be those of us who are legitimately winning the West to work means Europe works very well, America works better. This is something that we need a much higher level of concern about. And I imagine for this purpose of becoming leadership, you are not already, the dual use of the technology, the civilian purpose is important, because many people may wonder what is going to do an AI-defense platform for my business. I don't know if you... Well, I mean, the example that is banding around for our platform, very simply, you have, pow and tear powers, I think 10, 15% of all hospital beds in America, but the same thing you add in COVID, you have a million hospital beds and two million patients. How do you select the patients that are the most efficacious for you? Okay, well, it's not just financial because there are huge ethical concerns about who gets a bed, who should get a bed that are not, may actually be anti-correlated to what your algorithm wants you to do. But if you can bring the algorithm and your ethics and harmony, you change the margins of your business at both top line and bottom line enormously, or you are doing research on your insurance provider and you have to read millions and millions of documents, you are doing research on first-suparming pharmaceutical industry, you have to understand every bit of research in the world. But if a thousand people working on that, you can increase their productivity by 10X, as long as you can titrate the information so that it doesn't go into your core store of truth because there's some portion of that that is unreliable, and some decisions that can't be made without bringing that information into an environment where its veracity can be tested to a point where you can make billion, $2 billion, $3 billion investment decisions. As we have said, you have a unique profile for CEO of the defense tech company, indeed for any CEO, and perhaps that particularity is reflected in how volunteers approach to some business, because you have made some bulk moves. For example, in the beginnings, you didn't want to sell your product to five stars generals in bases or headquarters, but you traveled to the front lights and sell the product to the soldiers and commanders on the Afghan battlefields. For example, you also saw the US Army because you were not treated fairly. This, in the addition, is focused on innovators and startups, and I don't want you to recommend them to see the Spanish Army. But by the way, we sued the US Army not to buy poundier, but we did something very valuable for every entrepreneur in the world. We sued the US Army so that they would have to buy products that were proven to work, not products that were proven on a 4,000-page PowerPoint. But so that wasn't by poundier, it was by works. And honestly, maybe one of the most important things we ever did for the United States of America, not just for us, but for everyone, including the entrepreneur's referencing, because it's very hard to compete. We have limited resources in our country. We have to be very careful with an investing, jujish, and by the way, we have to defend this not just to our allies, people who broadly are realistic about the nature of defending our countries, but also to our skeptics, who would like nothing more than to point to programs that don't work so that they can get rid of some of the programs that do work. And that we need for our very survival and our rule of law. So if you, you know, there's an expression in French, key ambiance, sativian, which basically means you care about someone, you're kicking them in the fanny occasionally. And that was an act of great caring for my country. And it was not, you know, directly. And of course, it has helped parents. You're just like it's helped every innovative company, and randomly run into companies, European companies are now selling into America. And sometimes, you know, doing their best to compete against us. And they're like, you know, Dr. Carp, I love you. And it's because of that. So, yeah, but do you have some crucial lessons that you can share with our entrepreneurs on advice that they do with the give them? Yeah, build something that you find something you believe in, surround yourself by other people believe in it, make sure that they're exceptional. Raise more money than you think you need. Never stop raising money. Which in the American context means when you run into venture people, tell them how stupid they are immediately and always because their basic view is if I was as talented as this person is, I'd be even a greater asshole than I am. And of course, many of them, some of my best friends, some of them are, but you really have to be careful about being nice because they'll equate that to be weak. And, you know, you're going to have to fight hard and long. Certainly, if you're in the enterprise context, in government context, this is a very, very long process. You have some advantages if you're in a, you know, NATO country because you can work with any NATO country and you could also have access to the United States of America, which is the most important defense market in the world. And one that's open to buying software pretty much from anywhere and other products, hardware products. And be wary of the experts. You really, you know, put this way. If the experts all love you, run for the hills, find another idea because that just means that the idea is dated. And that 50,000 people are going to be doing it. It's reached, either it's reached this peak price. And or it's highly competitive. And I tend to think it's almost always wrong. So, you know, that doesn't mean that every idea has to be insane and every insane idea is if so facto valuable. But you want to be really careful. If you, if you, if you, if you can identify five experts and they love the idea, you, you really want to be hanging out with your buddies who are kind of off, you know, off piece. And they really like the idea. That's the better idea. But you have said many times that volunteer lives in a constant the economy, in a duality, working a fine line between security and privacy, sovereignty and profit. And all we know that defense companies have challenging public relations. Do yourself have basic criticism from activists and some misunderstanding even from your peers in Silicon Valley. Anyway, I just, you've mentioned that I, I just want to clarify, not all of it is a misunderstanding. Many of the people don't like us completely understand what we stand for. And I'll tell you what we stand for. The West winning, strong defense, deterrence, competence, money well spent, no waste. We believe that violence should only be used in the constitutional framework on the battlefield, but we support the use of violence in that context. Many of our adversaries do not support war fighters. Think war fighters are bad people. And in general, would like to not associate with war fighters or people involved in intelligence. And we're honored to support those people. And many of those people looked at me like I was a crazy person coming into their base and their headquarters. And we may not agree on every political issue, but I have great reverence for those young men and women who put their life at risk. And it's not a misunderstanding that we support them. It's not a misunderstanding that we support America. It's not a misunderstanding that we're proud that agencies use our product. It's not a misunderstanding that even though we don't always agree with every decision about internal politics and war that we are broadly supportive of working with Western allies. So everybody who's in NATO and America that we think the long-term benefits of supporting these institutions are crucial. It is a misunderstanding, but I don't really believe the people who misunderstand it, really misunderstand it, that we are somehow eviscerating data, exporting data to third parties, taking products that are used in Europe and the data somehow ends up in America that we're not the world's leader in data protection civil liberties. By the way, we've made a ton of money because of our focus on that. And a lot of the people who misunderstand that are either not a misunderstanding it, but they equate likability, meaning they don't like me because I'm pro-you with never being right, which is a dangerous way to argument, to argue. And this is something I would tell young entrepreneurs. The minute you go into this death trap of cognitive decline that the person you don't like is wrong, you are really, really missing the opportunity to go deeper on their thought process and get ideas that will be crucial for your survival. B, we struggle because some of our platforms have no competition. So if you can't compete with parents here, you sure as hell can malign us. And C, I'm not everyone's cup of tea. It's okay, I never was. Honestly, I'm pretty popular in some places now, I can't even believe it. I'm like, what is this? Even a couple of experts like me. And I don't know. It's mainly because I've learned that I have to bash experts and venture capitalists to be loved in Silicon Valley, to be loved by them. So I tend to think, and I'll tell you, the other thing I would say is to all you critics of parent year, please continue because we have attracted and retained the best people in the world over 20 year period. Not a two year period before the start up gets acquired, not a five year period before you go public and everybody leaves a 20 year period. And one of the main reasons is every time you say the world's dumbest thing about parent year, the smart person in the room says, huh, that doesn't, it can't quite be that simple. Let me, let me see how their architecture actually works. Let me see how they unify a fanatical focus on civil liberties with making big tendies. Let me see if this weird thing they've called an ontology actually could power LLMs. Let me see if those LLMs can actually need a data protection civil liberties platform that's been built over the last 20 years to actually work. Let me see why they are succeeding in the US at 70% last year despite having a nascent force. Why are they growing 28% in the US if all these criticism add off of a very large scale. So it attracts and retains the smartest people much like when people are attacking your services. Many smart people like, well, I think we do need an army. Huh, I maybe I'll go figure out what challenges they're solving. And so it is like a very great way to continue to attract and retain people. And you know, I often wonder where we left Silicon Valley because I had people protesting in front of my house in the mornings and the evenings. I used to joke with foreign visitors. Don't bring food. We're going to get the hot dogs and roast them on the flames right in front of Palatir. And we pretty much could do that by the way. And you know, it is one of the reasons why we are still a company that where people doing important things look 22. We have these products that every expert still aligns. And then we have all these tribute bands. If you want to see the most hilarious thing ever, there's like in every city in every country, there's a tribute band to Palantir, Palantir of Cockroach.com. And they copy everything I do. In fact, I'm now buying wigs. So I'm going to hand them out to all the tribute bands. And that's because of the products we build, the thin criticism and the disruption, most importantly, disruption of our adversaries and our helping our war fighters. And so I'm very proud of the whole thing. And I don't think most of it's a misunderstanding. We have time for our final question. Many Manhattan break scientists later with their work in the atomic bomb. And right now we see many scientists and experts and the total leaders warning us about the rise. Yes. Well, yes. The Oppenheimer quote. And I think I was in trouble for saying yes. And he got to criticize building a bomb because he was still alive. You know, it's the AI is potentially very, very dangerous. And if we did not have these really serious adversaries that are willing to viscerate the rule of law and will change the rule of law and change rights of privacy. And our series and not and committed to these ideas is it's not it's not even that you are adversaries are inherently bad. They have a different world view for how the world should work. And without an ability to deter them, we will be living like they want us to live. And so if those adversaries would change and my personal view is invest in AI to the point where adversaries are like, look, we got to stop this. And then you can reach a deal based on the rule of law. Okay, I think we run out of time. I want to thank Dr. Carp for being here with us and share his thoughts and everyone of you. Thank you very much.