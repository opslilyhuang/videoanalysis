================================================================================
METADATA
================================================================================
Title: LLMs as Great Artists | Palantir CEO Alex Karp Q&A at AIPCon
URL: https://www.youtube.com/watch?v=3UjvRi6k5Gk
Published: 2023-09-18
View Count: 15,236
Duration: 2688 seconds
Score: 55.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Delay to have you here. A lot has happened for us. When we finally had revenue in about 2008, we started to look for a place that was not a basement. In the early days in that basement, we invited our first customer, which is a famous clandestine service in America, and we had no product, we had no people. We all gathered around much like you try to make yourself larger in front of a bear, so it doesn't need you to prove we had people. That's how it began. When we moved over to Palo Alto, it was a big moment for Palantir. We felt we had arrived because we had built this product, P.G., which really did shift the history of the world, especially in Europe, by reducing terrorism in accordance with civil liberties. One of the true isms of business is you're really succeeding at the place where no one believes you actually care. I cared, we cared about data protection of liberties, and we went very deep on these issues. Some of those issues, not all of it, are super important for the AIP product that we're delivering, by the way. We began, we launched the product just under five months ago, and now we have 150 companies using that product, 50% growth in the last month. We're changing our go-to-market because we have no resources away from 12-month pilots to essentially a boot camp where we all roll up our sleeves over two days, and we'll show you at working. Both because, quite frankly, we don't have the resources, and we like to humiliate people out there saying they have products. We're better way to do it. We will show you your enterprise working in two days, talk to other people. The central reason we have had these precursor technologies, ontology, branching, and understanding of what it would mean to interact with algorithms, whether they're normal algorithms of the kind that are used on the battlefield or large language models, was a deep understanding of NLP. How do you ask and answer questions? They're different in this context, but the core issue we had in building that product was how do you unify data sets where part of the data has to remain unknown to either machine learning or to the end user. Those products are not isomorphic. Those questions are not exactly isomorphic to how do you interact with a large language model, which is not exact in a way where you can extract value that needs to be exact under conditions where you for legal, moral, and ethical reasons cannot expose and business survival reasons your knowledge of the world to a third party's LLM. There's jarringly similar use case, and this is why we have all these people adopting the product because quite frankly, unless you spent 20 years looking at those, you would make certain mistakes. Intelligence operatives have to work with things they know are true and data sets that they would are hoping are true. At the time you really couldn't interact with the text very easily. So dealing with something has become very, very powerful, but that's not exact, and the kind of exact algorithmatic things you would need to make operational decisions to write to your enterprise. It just takes a long time to believe that that's how you have to build it and longer to build the product. So I associate Palo Alto with our ascendancy, this building with our ascendancy, and our commercial business and quite frankly our government business in the United States with a really cool right. Then just kind of obvious a dendum, I was just at this gathering organized by Senators leader Schumer. There are many things that happen there, but it's very hard to explain how in reality, if you even took the people who were not in the room and then the people who like the league below them and the league below them, you would still have a stronger tech community than any other country in the world. It's just actually kind of bonkers, like you have any one person on the tech side in that room has a larger tech business than probably any other country besides America. And so we're at this moment where, you know, and we're fighting very hard to get adoption on the battlefield. Some of which is happening, it's a lot of it's sensitive, can't really go into it, but obviously we believe not quickly enough. But one of the things that you are doing quite frankly without realizing it is you're putting pressure on our government to adopt AI in a way that will improve all of our lives with the fifth guardrails in the civil context and with guardrails in the military context, simply because you're going to adopt things and you're going to call, you're going to run into Senators and Congress people and generals and colonels and sergeants and healthcare providers and people at the VM, but why is my product better than yours? And this is probably the most, I mean there are many reasons why I'm super happy about the work we're doing in US commercial and quite frankly, just amazing. I never thought we'd get to the point where the growth was so significant. We are just trying to scrap to figure out how we can do these things. But one of the orthogonal reasons I'm very happy about this is there's no better way to conjole an organization to work faster. In this case our clandestine and military services than to say, okay, well, you know, you paid a billion dollars, you have a jolope, I paid five million and I'm running my whole organization. And so I'm very passionate about this for lots of reasons, but that's also one reason. And I think we have some questions and try to keep me out of purgatory. I'm already skating a fine line. Luckily my co-founder, I didn't appreciate the value of, we have these F shares, which basically means it's harder to fire me. But then I go to these meetings and like, you know, I get away with speaking a plain English because of these F shares, but I'm realizing I'm skirting on thin ice. So maybe, yeah. I don't know, someone's going to ask a question. Please welcome Senior Director of Government Services at Cisco, Mike Youngers. Good morning. Are we going to sit down or stand up or? I'm standing by you. You know, you do you. It's your show. I know it's honored to be here with you today. It's not my show, it's actually your show. And you want to stand hop? I do not want to hop. Thank you. I don't want to dance. So I used to play the drums and I used to be able to do that sort of thing, but I can't do that anymore. But I do have a question for you and you've kind of started talking through that already this morning. I work in the government solutions part of Cisco and I'm fascinated by this kind of government to commercial, commercial to government. I have some history previously with Incutel and I read Shoms Blogs this past weekend about Palantir government web services and that's what's enabling what we're working for inside of Cisco. But the thing I'm fascinated by, I'm just fascinated by the company in general, the people here are unbelievable. And I've watched a lot of companies try to bring technology that was built for the government to commercial and a lot of companies try to bring commercial technology to the government. And I've seen very few companies succeed and it feels like you guys are succeeding in doing that. I'm curious, like what is it that what's the secret? Like how are you able to do this when so many other companies fail at that? Well I appreciate the question. There's just to be fair, somewhat fair to us or not to me. A lot of companies succeeded at this, it's just they haven't succeeded in the last 50 years. So a lot of the innovation, I believe, one of the reasons America was less divided in the past was that you had tech companies that dedicated themselves to building products for the government that then repurposed them for commercial. So then reframing the question would be like why did that stop and why are we able to do it? And arguably we're even succeeding more in commercial than we are anywhere else. Well first of all we do attract and retain the very best people in the world. And we do that by, I mean it sounds corny but we are a believer culture and that believer culture allows us to unify under a belief which by the way does exclude people. If you don't think the US government should have the best software in the world, if you're uncomfortable with the fact that we supply our software to the battlefield in the US and to allies, we respectfully ask you not to join volunteer. By the way not in like you're an idiot, we have this belief structure, that belief structure allows us to get people. It's like one of these things where the narrowing of the selection leads to a broader ability to deal with different kinds of difficult people. You may know from your organizations many of the most talented people in the world have one thing in common, they're very difficult. And then that belief, by the way obviously I'm not saying we're not like it varies day to day and God knows I've been frustrated by, I get most frustrated by the people I believe in when I feel like. And then I think the secret is if you are really doing something because you believe in it, you are often solving the problem that the customer called this clandestine services in America or the DOD or somebody, it's not the problem they want to pay you to build, it's the problem you believe they need to solve. That's a subtle difference and the giving them a solution which unfortunately in our culture is often a long services program that where the person being paid absorb no risk, which is one of the reason why these things often don't work at a cost that's crazy, but the customer is getting what they want. What we're doing is going to a very different level of abstraction and saying, but what is the question that they are asking that's technical, what will be the question that will, you should be asking tomorrow the next day in a thousand days and can we build something at that level of abstraction? The negative version that we have internally is, since we know that in the beginning we are very unpopular, it's like how good can the product, the product has to be good enough that even though we're the least popular people in the room, they're still going to buy it. That's very deep in our DNA, like our ugly duckling DNA, it's like a real thing. We believe, we're not the ugly ducklings anymore, but don't tell us that, certainly don't tell our people that. We need to build products, ugly duckling products, meaning you're going to buy this product despite the fact you do not enjoy being in the room with us because it will save your life. If you build products like that, and then I'll tell you on the commercial thing, I think what is really resonating, like if you talk around, talk to people here, of course, we're a commercial company, you're a commercial company. They're always misalignments. We're much less misaligned with you than I believe any other company you'll ever interact with because in the end, we want to deliver things that work because we know that that's how we survive. Because we were so bereft of common sense, we have not played by the, like there's a playbook on how you build these companies. It's like, build in technology, hire thick sales force, hire CEO that Wall Street loves. Okay. Our product. That doesn't look, that's not us. Right. So, everybody, but that's the playbook you play. Everybody, like you go to venture, or any, that's the playbook. So everybody has this one playbook. We have another playbook. In our playbook, it's really hard to get to work. But when it does work, you end up with super loyal reference customers and partners, and they run around saying, yeah, okay. The first meeting may be weird, but you'll see. And then America is also shifted. Like we're not that outside the norm anymore, but I think that's how we did it. And for us, like, you know, now I'm very focused on empowering the younger people at Pound Year. Yeah. Like, and getting them on the forefront, getting their comp structure and other things to work for them, rebuilding the company in, it's slightly, it has to be a different company in an LOM AI world. But we must build products that transform the institutions we work with, where we're fully aligned with you succeeding. But like, in private, if you taped a conversation with us, what you would find is, sure, we have frustrations with X, Y, just like you do. Sure. Probably. Yeah. We're not, you're not going to find conversations where we're like, oh, what is this thin bullshit piece of product that we can get a salesperson to buy over a steak dinner that they're going to hate? It's not going to work. And it's going to boost our market cap because our CEO is really good at hanging out with analysts. And analysts believe something they read at Harvard Business School 50 years ago that no one believes, except for them. Yeah. And, you know, and, and then we don't do that. And if you want that, you go somewhere else and there's lots of opportunity for that. That's just not who we are. Yeah. Well, thank you. You said this in my first conference that I was here and you said, iterate with a partner that you can trust and we trust, volunteer and it's awesome to work with you guys. So I appreciate the spirit and the answer of that question. So thank you. Thank you. Thank you. Please welcome Chief Operating Officer at Cone Health, Mandy Eaton. By the way, I apologize for the dental music, but you don't have to sit in the chair. Nice to see you. Unless you want to. If I say, well, you said, are you going to stay in it? Whatever you want. Let's sit. Can I have something to drink? Yeah. I'm here. Yeah. Well. Thank you. Thanks, one by first question. Thank you. Thank you for having this conversation. I think this is great. Our industry healthcare typically lags in its adoption of technology. And there's a lot of good reasons for that. I'm curious for those of us who are trying to drive faster adoption. What recommendations do you have for us? We're, parents are doing charringly well in healthcare and there's a technical and I could explain. There's a lot product market fit to use jargon. But we, again, a lot of our DNA and our get to survive in an unfriendly environment. Like for us in the beginning at Palantir, we had to get users first at clandestine services and then in the military. In the military, these people are really know what they're doing. And many are not particularly technical. And you can supply the best product in the world as a matter of theory. But if none of them are using it, first of all, it's obviously not valuable. And second of all, the product can't get better because it gets better. And this is before we are doing algorithmatic things at scale really. Probably gets better by having more users. More users mean that cliche is more users mean more data. But what it really means is more insights on top of the data that allow you to understand the parts of the data that are valuable. And now we can do that on steroids. So the most important thing for getting innovation into the hands of the people is getting innovation into the hands of the people. And sitting there, I think the people running our hospital division, for example, have done an amazing job of like, you've got to engage with the frontline people. What is your actual problem here, by the way, like a culture of mutual honesty is crucial because in all large organizations, there's always at every level, there's alignment, but there's also misalignments. Maybe what the special operator wants to tell you is my biggest impediment to my work is the bonehead officer, right? But like, how do I build a product where I can do the work and then it feeds up to them but where they're not in the way of the work? You have all these issues like, hey, my real problem is not what I'm being told by the corporate people. And I'm going to block adoption unless you solve the problem I care about. And then, but if you identify that problem, you can also go to the people in charge and say, okay, we will get them to adopt this product. We need to build feature sets that get them to use it. And then because they're using the product, you can also guide the people. And when I say guide, I mostly don't mean control. What the more successful products do is they provide a range. So we did this early on with financial decisions. If you're working in a healthcare context, what we'll get brought adoption is, my dad's a doctor. If I tell my dad, hey, dad, I know how to build a business. He'd be like, why read a book? I'll tell you how to do it. There's something, right? So doctors are doctors. But if you provide a range of like, okay, well, this is where we think the decision should go and you get to iterate. You're empowering the end user. And that range guidance also gives the people who are managing the P and L of the business a lot of ability to control the kind of costs and risks that they're managing. And so what you really, and there's architectural ways in which our product is built for that. Again, because that's how we learn to survive. And also because we don't believe we can survive if you're not using our product. But you have to empower the people on the front end in a way where they want to use it in a way where they still get to make decisions because there's just some things that are never good. Like a doctor looks at a patient and will tell, has a feeling, is this patient healthy or not? And if you're going to tell the doctor that they can't have that, they're not going to use their product. Same thing for nurses. And so, but you can say, okay, we have capacity issues. And if you make these kind of selections, you will no longer have the capacity issues. And by the way, the frustrating part of you having to tell people know all day. And that's how you get adoption. And then you build on top of that and you get a very strong product. That's great. So people are really at the heart of this. And I think that leads me to my second question is when we think about AI and similar technologies, should we be thinking about that as job replicers, job changers or just efficiency drivers? Should AI and other solutions like this be helping us to keep pace with how fast our information uptake has become? Or can we do less or simplify things? I don't think there's one unified answer to this. I think in the healthcare industry where you have, you're very constrained by the number of people you could hire anyway. The primary focus will be making people who are already doing a good to very good job, much more efficient. So increasing the productivity of the workers. And then there are lots of reasons why. So you know, it's like you probably can get a lot more value out of the individual workforce you have. And that there'll be less replacement than people think. But that's also because the delta between what you're being asked to do and what you can do is so large. So you're dealing with thin margins, heavy regulatory environment and increased demand. So even if we, as we increase your efficiency, it's still going to be a long time before that's truly efficient. The, I think in broader society, what you will find is people who are at the nexus of either high training or high training and regulatory context, it will augment. I do think if you're not trained, you will have to be retrained because the current use of the LLM that's most efficacious is augmenting. It's still augmenting more than people want to acknowledge. It's especially if there's any actual output that matters. So like, you know, it's like moving from poetry to decision requires your augmenting the ability of a trained, thoughtful individual more than you are replacing them in the near term. And so, again, I think this is where you'll see a otherwise constrained environments in the US commercial outperforming other Western societies because they have the same issues, but they're rejecting the implementation of these technologies either directly or indirectly by making it, you know, most of the great providers are in the US and that's hard for some places to accept. Great. Thank you. Thank you. Great to see you. Please welcome from Panasonic Energy, Alex Meevsky. Martin, Dr. Carp. You sit, Stan. Oh, it's good. Okay. So, I want to ask you more about philosophical question this morning. So with all of the gloom and doom that's in the media these days around AI, especially in the context of arts and culture, what are some of the positive transformations that you think AI is driving humanity towards that most people aren't thinking about? Well, I mean, there are some dangers. So like, I don't, like, there are two camps here in broad, probably speaking, those that say it's all good and those that say it's all bad. And I think it's kind of pretty good and very good and then there, unless it goes all wrong and then it's a very bad. Great. And, but first of all, just, you know, this is probably not the right way to answer the question. I always am my mom's an artist. I grew up around artists. I kind of personally reject, like most people view artists as being painters, photographers, writers. I honestly, I view building a business as an art form. So, you know, like, I do think that if you change artists to, I want to do an creative endeavor, creative as defined by, I am going to build something that is not the way I would be taught in school to build it. However, deals with the underlying issues of your art. So, like, you do need to know how to be trained, how to paint in order to be a great artist, but then the great painters and writers are almost all, have all, have extended their art. So, if you read, you know, in philosophy, I could give you long list, but you can tell every single sentence is from this person. And if you change it to the basis of almost everything that we enjoy in this world, certainly in this country, was in the beginning some form of art, like the business that, you know, you're building the way in which you're adapting the people who create the most value. And then you also assume the people who do this are kind of often outside the norm, meaning they don't fit exactly into the current structures, part of the reason they do the art. I tend to see the LLM movement as enormously emancipatory. And I also think that, you know, my, the thing that's interesting about large language models is they're like many artists. They are absolutely unique in their capabilities, and then they also can't really go by a pack of cigarettes or get a coffee off the ground like they don't add well. They hallucinate, you know, I think if you approach large language models as they themselves are great artists as opposed to their great scientists, you'd have a much better accurate understanding. And therefore, I think they partner very, very well with creative people who also have are very uneven of which I would definitely include myself. That's not obvious. But it is, obviously everyone works at Pounder, believe me. They're like, why is Carp bumping his head turning the wrong left again, telling us to launch this product? And I think what you will find in a culture, again, okay, so we hire a lot of people from France, interestingly, because France has essentially one school that if you go there, you get to rural France and if you don't, you don't. And so, like you can just see structurally in a country where everyone gets to go to bat basically because we don't have one school, I don't know where you went to school, I don't care. No one cares. It's not even relevant. It's like, it doesn't matter. I don't know what your parents did, no one cares. Literally no one cares. It's all this stuff we have to talk about, no one cares. People care about your performance and are you doing something interesting and that's basically it. And we can, AI will hypercharge people who are doing something unique and interesting, whether it's inside an organization, meaning in a business that exists, building new organizations, transforming, I mean one of the things I admire about what you guys are doing is you're bringing a hybrid culture of Japanese production to America. Okay, that's much, much easier, I would say probably not possible without software and AI. But then what's going to make it particularly interesting is it is a hybrid culture. You're bringing certain things that Americans are very pragmatic, creative attitude, but built on top of a way of doing things that is for what you're doing arguably the best in the world. But that is, that is AI creation and action. You know, and it really does mean that the value you're creating is pretty much non-attenuated from you in a way that it was in the past. And it's particularly good if you're sitting in this country, which is why, you know, we see it at Poundchair, people flooding into Poundchair from all over the world because you can just work in your own context. So I think in the near term for many, many, many people that I find inspiring and disproportionately in America, this is going to be a freeing technology. And especially for people with artistic proclivities. And so I, it is one of the reasons why, you know, even personally, I wanted to embrace this earlier than others. And I think it's going to really make people with guardrails, obviously happier and wealthier. So following up a little bit on what you said around, you know, the Japanese and the American culture and bringing us together, the world seems farther apart than ever in my lifetime. So do you see AI and things like LM really bringing us back together? You mean the world in America, inside America or? The world in total. It seems like there's so many fractions. I, I'm going to leave the American, we are divided, which is an issue, but then maybe we get a lot of growth and suddenly we're less divided. But I don't think on the international stage is going to get better. It's going to get much worse. And, and then that's a separate discussion for, I mean, I'm spending a lot of my time meeting with people on DC and cajoling, begging, pleading, you know, there's some point two percent of the DOD budget, point two percent. Now, I'm not making that up. Point two percent is being spent on what you could call, what they're calling AI. And then what you, you know, software really depends on who builds it. It's not, it's, you need money and you need the right people and you need the right partners. And there's, it's all three components. And of course, America without going into details is pretty far ahead on certain elements. But you know, our main adversaries are aware of this. And the, the, in my view, and again, no one has to agree with me in this room, but I think you get world peace by US being clearly the strongest nation in the world because we're, for, you could argue about our pluses and minuses and faults. I think we spent a lot of time talking about that. But I'm not aware of any other country that is benevolent with great power as the US. I, in those of you in this room and others disagree with it. Okay, so I could just narrow it. Our adversaries will be very different than we would be if they had military superiority in AI. So that's a separate issue. But I think that's how you get a more unified world. But we're, that's not going to, it's going to be, in my, I, if I had to predict just going to be pretty rough. But Enkies, thank you for these questions. Yeah, I really appreciate it. Yeah, thank you so much. Please welcome, Telco Managing Partner at DXC, John Bame. Dr. Herp, how's it going? Very firm. Yeah, oh, yeah. Oh, my no notes. Perfect. So, I've been in and around quite a bit of launching of commercial on Foundry, handful of different organizations. First time I saw about six, seven years ago, and one of the big things leadership from Palantir is always saying is this technology is at least five years ahead of our next nearest competitors. Do you still feel like you've got that kind of a gap in between where you are today and other competitors in enterprise access, analytic space? It depends. You know, we have a number of products. Certain aspects of our product. The five years ahead is also euthanism for no one really understands why this works. Right. And they haven't started building. Now, I would say in the AI context, the context of time is shifted. So, like, people are doing what you would take ten years and like two years or a year. Certain products that aren't relevant for this audience, like PGA, Guy Nexus Peering, Apollo, might be... Like, there's no one else going to build them. Then you have Foundry. I don't think... I don't think anyone's going to build Foundry for lots of reasons. It's expensive, hard to build. It only looks really valuable now. So, like, because you... It was valuable before, but somehow it wasn't in the site, guys, that it... How valuable. It could be... Foundry until AI was like... It was kind of like a... God bless all of you who adopted it. I believe it is the best product on the market, but it basically was like... We will make your enterprise work better, but you're not going to have any fund. And so... And now it's like... We will get your enterprise sizzling, because if you have it, you can adopt AI in an ethical way and change your business. So, now it's kind of, for lack of a better word, it's sexy. So, there may actually be people who build components of Foundry. And, you know, I cannot believe that people are not focused on building, like, branching, ontology, logic. You... Everyone's going to need. But, you know, one of the things about being kind of, you know, like, from the outside, we just look... We're not following a playbook, so people are like, well, but where's the playbook aspect of ontology, branching? Where does that fit into my five, six, whatever, however they'd... So, in each one of these cases, we're de facto very far ahead. I think the five-year thing might... You have to compress that, because AI, large language models and copies, other things, will allow you to work quicker. And people see the roadmap, and quite frankly, if you're looking at P.J., you know, we have... I don't know, a large percent of the dressable market, but no one cares, because the market is very small. Right. Whereas, here, the market is infinite. It's the only market that matters. I'm still somewhat optimistic, because we owe a lot to the venture community. I think the venture community is going to have a very hard time, and that they want... They want a model where you... All the money isn't building new L.M.'s. And I believe all the value is in managing the L.M. in a safe, effective way in writing logic to it. And that's a subtle difference. If we are right, you want to be a company that's off the ground and has something like we have, existing client base, a reputation, something like Foundry, inability to implement ontology, understanding of tooling, the real... Even the understanding of you would need tools. Sounds very simple. And obviously L.M. needs tools, but even that is like somehow outside the financing Bailey Wick of most venture people. And then you have large companies. These companies are the best in the world at what they do. With notable exceptions, they, in my business, the software business, they're just not that many software engineers. And then it's like so. Their model is to acquire companies. Well, they're not that many companies to acquire. So I'm pretty optimistic about this, but on the other hand, internally, we are running very quickly. You know, we don't want to make the mistake of being ahead and then losing. Right. So you were saying about the compression of the time frame. So I think that one of the things right now, L.M.s are going and accessing human source material, humans have created that first level of material. And so you can take that 10 years of understanding down to one because all the source material is human generated. How do we prevent, as we layer, more AI generated content on top of, you know, out and even in the ecosystem of the internet? How do we keep these AI models from getting dumber by then consuming their own output and then using that in the next training set? Well, that's a super interesting question. I would say most people are worried about them getting smarter and then making us irrelevant. And I hope we have the dual challenge of that they get dumber and dumber. And then, of course, the way to solve that problem is you need foundry, you need logic, you need an ontology. But so that's the, that's, that would be the answer. There's a real chance that you're right that they get dumber and dumber. But yeah, and again, I think you should maybe explain that problem to the venture community. That's my critique. That's what they're selling. And you know, look, I, you'd be surprised we should not be running around telling people, look, your thing is going to fail. I do it anyway. But I partly because no one listens. And it's like, you know, but that's, that, that is a legitimate and profound critique of what most of the businesses are, they're being financed here are going to do. Thank you. Thank you very much. I think I may be, is this the time to throw me off the stage? Oh, others. Oh, yeah, I know. I can't. Okay, please welcome from Cleveland Clinic. Oh, I can't. I obviously mean you. Yeah. Thank you, Johnner. Hi. Thanks for having me. You know, my question has to do with your position in AI. And what sort of influence you see for patient care and hospital operations? Well, first of all, I'm, it's great honor. I think you were a first partner in your space. Yeah. Yeah. I just want to give a shout out to the Jeremy Drew in Parle. They're great. Yeah. And they're being below them very, I was in New York and over the weekend and some weird hour and they're all there. Well, so they're very special crew. Look, in your space, you have governance issues, you have ethical issues, you have privacy issues. Nobody, everybody wants effective care. Nobody wants their personal patient data exposed to anyone. You have very technical users, technical users do not use a product that tells them that they're not engaged with. So they need to be brought along. They need to be quite frankly, legal liability issues. So how do you protect healthcare providers from being randomly sued? And no, anyone who's got a relative or is involved in healthcare has a somewhat cynical view of how that happens or realistic view. And then the stakes couldn't be higher. And so the way you implement is you show the end user that this is reliable. It is augmenting their work. It's making their work safer and more effective. And you get them because only they can tell their peers that this is working to tell their peers this works. And then it's obviously very helpful when you have a misdyn driven organization like yours where people up and down the chain are really engaged in this. And then I do think in your industry, as I mentioned before, you guys are under a lot of pressure because of high regulation, litigious context, and margins that are pressed. And there is no answer for that besides implementing software. It's just that, because you can't change the other variables. And we could debate, if we could change the other variables, that would also be an option. And quite frankly, if I were in charge of that, I would be very open to discussions. But in reality, those are the constraints for now and probably for a long time. And then you have to get, proverbially, a lot more from the less. And that is what Foundry does, that's what AIP does. And that's why our partnerships in this area have gone very well. Yeah, no, it has. Can I just add to that sort of my philosophy with what I do is to try to be disruptive. And outside the box, basically, whatever I see, what's being currently done, I wanted to go opposite. And so I'm trying to leverage you guys and AI and the technologies. In your position, what would you say is the next step towards operations? How to leverage that AI technology in the hospital industry? Well, I mean, it's obvious in some ways, like identifying people's risk of clippity's, having an updated understanding of the literature and the treatment profiles, being able to give the absolute most accurate, understand current understanding of patient treatment data. We're probably not very far from what individualized or already individualized genetic based medicine, which is not going to be possible without AI and broadly defined. And I would say, you know, and a governance structure that protects everyone involved. Because you can't do individualized medicine without making an individualized assessment. Without the right governance structure puts the healthcare provider in a misaligned relationship with the person they're trying to treat. And there's a banality of healthcare, but it's like you have to have full alignment between patient and doctor. But then you're doing this in a data-rich regulated environment. It's a very hard use case. So, thank you for your time. Thank you. And welcome to our humble abode, and I hope you learn a lot. We will learn a lot from you. And thanks for coming.