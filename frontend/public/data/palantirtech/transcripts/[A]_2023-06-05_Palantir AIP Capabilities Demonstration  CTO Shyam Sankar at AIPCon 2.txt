================================================================================
METADATA
================================================================================
Title: Palantir AIP Capabilities Demonstration | CTO Shyam Sankar at AIPCon
URL: https://www.youtube.com/watch?v=akieze8_tSE
Published: 2023-06-05
View Count: 65,188
Duration: 1179 seconds
Score: 71.0/100
Rank: A (Active - 高参考价值)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

I am so excited to be here to launch AIP. This product we've been working so hard on, in my almost 20 years at Palantra, I've just never been excited about what we've been building to this level. It's not just the impact we've worked on, tons of impactful problems. It's really the speed that this impact is going to be happening in here. So AIP is really our core set of technologies that are designed to bring LLMs to your enterprise. To supercharge and accelerate your experiences, everything from integrating data, highlighting your ontology, building AI-enabled applications, and even AI agents and co-pilots. AIP enables you to deploy LLMs anchored in your data on your private networks. It enables safe handoff between the tools in your enterprise, the actions, and other AI models you've already built. It enables you to govern and control this so that you ultimately have deep trust in the AI. This moment, I mean, the AI technology is going to be massively disruptive. It's absolutely a case where the dynamics here are winner-take-most, if not all. So be the winner by disrupting first. And as I've been thinking about this, I've been thinking, where is the value likely to accrete? And I think I believe it's going to be in the workflow and the application layer. And that should be quite exciting for all of you here. And that's because the models are already commodities. The pace here is accelerating and exhilarating. This slide, you know, I made it a few weeks ago. It's already out of date. Falcon has been released with an Apache license yesterday. So we've gone in less than two months from Lama to Alpaca to Vikunia. We've gone from GPUs to CPUs. We've gone from massive cloud software stacks to running these models on a Raspberry Pi. So the editorial from this, like, what does this mean? This means that you're likely going to have a menagerie of models, not a single model. And you're going to be able to cheaply customize and tune these models to your needs. It also means that the biggest, baddest model is not the one that's most likely to win. It's going to be there's this gold elox of powered iteration speed. You know, what is the right size to model that you can iterate most quickly on? And the reason that's the case is that LLMs alone are not enough. You need tools. Actually, they need tools. For example, they need a tool that will help calculate the enterprise profitability of an account. Or compute the forward looking inventory for a specific product. They need access to an action registry to execute operations across the enterprise. They need access to a semantic layer with rich objects and links to actually define the proper grounding and act as an anti-holucinogen. And sometimes this is called retrieval augmented generation or rag. Probably have heard that term a few times now. It also needs access to a branching environment, something Dr. Carp was mentioning, where it can actually stage proposals or edits to the world for humans to actually review. So AIP comes not only with an incredible set of tools, it comes with a tool factory that you can build your own tools to augment them and make this maximally useful in the context of your enterprise. How do you get an LLM to post and invoice a NetSuite? You need to build a tool for that. Or how do you reallocate inventory and SAP? That's what AIP really empowers here. The vision here is really this kind of cyborg enterprise, reimagining human and agent teaming that business processes are managed by an army of human agent teams that employees oversee the AI and the AI's recommendations. Your enterprise is moving at machine speed. Let's build that enterprise together, brick by brick. Let's start with data integration and really an entirely new paradigm for that. When I was young, wizzy wig meant what you see is what you get. And I think now it really means what you say is what you get. You can move much more quickly building things by simply saying what it is that you want. So let's start by transforming some of these data sets that we see here. Very clearly I can see what the AI does and does not have access to. In this case it's just the metadata. So I can select the data sets that I would like to transform. And I can simply say something like give me all the claims from the West Midlands. I can say that in English, in German, or even Ukrainian. And what I get back is this series of transform boards that I can easily inspect and make sense of and see what is the AI doing. I can ask more complicated questions like give me the unique landlords with open cases and construct a geopoint column that has latitude and latitude. So I can visualize these items on a map and verify the location. So if we fast forward a little bit and we assume we have a more complicated looking graph here, and I'm new to it, I can actually ask AIP to explain to me what are these transforms doing. And you think about how that's going to transform how you do documentation, how you do change management, actually the comment, and a code commit when you're changing your pipeline itself. But why do I need to say anything at all? If I have my target ontology here on the right, and I have the data sets I'm trying to integrate on the left, why can't I just select it all and ask AIP to connect the dots for me? And what we will get back is a series of builder boards, which we can very clearly see what the purple annotation was AI generated content that I can step through and verify as a human that these make sense to me. AIP is your AI operating system. Every operating system has a command line. AIP is terminal. With terminal, I can easily interact with all of my enterprise knowledge and my enterprise applications through a large language model. Let me show you that. So we start off in our supply chain control tower, and we see that we have a new notification about a disruption to our Velenor distribution center. So this email is coming. So why don't we open up terminal, load up our distribution centers, and start. By simply saying I received this email, we'll paste in the content of the email, and then we'll ask to visualize the order statuses that are impacted by this context here. And what you can very clearly see on the right hand side is the handoff review. I can see both the chain of thought and the chain of tools that AIP is employing to answer this question for me. So it's interpretable, it's understandable. I get back the visualization. I select just those that are waiting for shipment, and I can drill down further into this. So the relevant question I think now is maybe to figure out what's the revenue at risk here. So what's the total value of my high priority orders that are impacted by this distribution center disruption? Again, I see through the handoff overview how AIP is breaking down to answer these questions. How is employing the tools that we talked about earlier to solve this for me? $13 million. I can see all of the objects I have access to here. You can kind of think about this as like LS at the command line. More importantly, I see all the tools I have access to. Not only the tools that are native to AIP, but also the tools that I've used the tool factory to custom build. So let's call one of those ML models now. I would like to run an order reallocation model that is specific to my enterprise. AIP will find it, bring it to me, and allow me as the human to go execute that model. So we get the results of that, but this is not the way to look at it. What I want to do is I want to look at this in the context of my operational applications. I ask to open up my operational inventory allocation application. And I can see I have 53 high priority orders with $13 million at risk. I can see on the map the distribution centers I'll be drawing inventory from. And on the right, I see the actual edits to my inventory plan that's being proposed to me. And from right here, I can take this operational decision. So I've taken a problem. I would have taken me 300 minutes this all, and I'll show you how you can solve this next time in three seconds. But you don't want to live in the command line all day long. You want to be able to create on the Rails workflows for your enterprise users. And you want it to fit them perfectly. You want to be able to adapt those workflows to their evolving needs. And you want to do that by simply just saying what it is that you want. So how did we build that supply chain control tower application? That we started terminal with. Well, by asking for that application. So if we start here, we provide a description. I would like a supply chain application that allows me to look at manufacturing plants, distribution centers, customers, and some other metadata. And this gets me 80% of what I want. I get the scaffolding of my product generated for me. Now I want to add some metrics to this. Let's look at OTIF. Let's look at monthly sales, deliveries. And I can get the widget created for me. Now this is not an application. It's a dashboard. To the extent I have a supply chain problem, I can see it, but I can't do anything about it. The alchemy of AIP is to be able to change that simply with a single spell. To ask for a button in the header that will allow me to reallocate my inventory. So let's do that. And we'll see the blue button appear in the top right. But how is that working? It's obviously not magic. This is a concrete manifestation of a tool. So if we go to the ontology and we look at the management application, I can see I have this function, reallocate product, that takes an Atari and source distribution center, product ID, an amount to reallocate, and that it triggers via a web hook, a call and write back to SAP. This again is a concrete manifestation of a tool. In this case, a human is clicking the button to employ that tool. But this is a little bit of foreshadowing where we will see how we give this to an LLM to supercharge our enterprise. Okay, whizzywig applications. Is that what I want? Because I think what I want is a whizzywig enterprise. I want to build an army of AI agents that do what I say for me. I want my employees to become managers of agents who review AI-generated recommendations. I don't want to be 100% better. I want to be 100 times better. Let me show you how. Let's build that together, brick by brick, starting with AIP logic. So here I'm going to build a new function. And the input to this function are going to be these emails I get about my supply chain. And then I can add a logic block. It could be a Python logic block. But let's make this an LLM logic block. And I will pass into this a prompt, which is both the content of the email, but also a task to read this email and extract locations from it. And I will define my output of this function. It's a string array of locations. It's called locations. This is an integrated development environment. So now I can go run my function, create some mock data around a hurricane coming in Southern Florida. And test and see what is this function able to extract from me here. How does it work? So let's run it. And we'll see we get back Miami and Florida, Dale. And we can open up the debugger to actually step through and see the interaction between my code and the LLM. And what are the prompts I'm sending? What am I getting back? How is that working? So great. But this is not what I want. I don't want string locations. I want to know what distribution centers are going to be impacted by this storm. So to answer that question, we have to give the LLM its first tool. The ability to query the ontology for our distribution centers and a prompt of how to use this tool. Use this as your location data set. And then I need to change the output. I no longer want strings. I want object references. I want an array of distribution centers as the output value. It's strongly typed here. So let's make that change and rerun our function and see what we get back. As you'd expect, we get distribution centers. You can hover over them. You can see these are rich objects that are defined, the semantics of my ontology here. And now the debugger is substantially more interesting. You can actually see the call and you can see how it's employing the tool of calling the ontology service to go figure out what distribution centers to return as answers. You can't make these up. These are, this is a retiable augmented generation. But I don't think this is what I want either. What I really want is the LLM to help me figure out what to do about the inventory shortages that are caused by this disruption. So let's enable that by adding another LLM block here. So we're chaining our logic together. And I'm going to pass in the email, the locations from above, and a new prompt to use these tools I'm about to provide to determine how to resolve the shortage. And so we're going to have three tools. The first is Reallocate product. We saw this tool earlier in the supply chain application and a prompt of how to use this tool. In addition to that tool, we're going to give it two more tools to calculate the shortage KPI and to get Reallocable Inventory. Now I want to change the output type as well though. Because what I want back is a scenario. I want an AI recommendation of edits to my inventory plan that I could consider making. Now when we run this, we will get back a rich set of edits to the inventory plan, a scenario that I can evaluate. But the debugger is substantially more interesting now. The first block here shows us where it's getting the distribution centers. And the second block shows us repeated calls where it's how the LLM is invoking different tools, the return values that be one of those calls. The chaining of these calls to ultimately arrive at the solution and to provide me this case. I can save that as a test. This is a unit test. I've expected input, expected output. Now I have an ability to regress over this model. If we also have the full telemetry. If you allow me a cooking show moment, say this model has, this function is run in production, you know, 5,000 times or so. I can see every production run of it. I have the full trace of the debug log. I can, for example, select just the times that we call the Reallocate product tool. I can select a single run of that and see what happened. Walk through the trace. I could save this as its own unit test. This is how you build fundamental trust in these LLM functions. It's how you ensure quality as you upgrade your model or model version change over time. The final part of this, though, is to turn that logic into an AI agent. So let's start by defining when I want my agent to run on a schedule or when a new email object is created, which would be the case, select the object type, and I connect it to the email alert categorizer we just built. I set up who has access to even approve the AI generated scenarios here. When we put this into production, we can go to a live view where we actually watch as the human agent team, the agents processing objects as they come in. I have full access to the chain of thought and the chain of tools that the agents are using. I can actually view the suggested AI edits in the context of the operational applications to make well informed decisions. I can switch to a view to see and manage my agents overall, the process view of how many agents do I have running, what process is really working on, what is this historical performance of these agents. There you have it. Brick by brick, we built this cyber enterprise with AIP. What you say is what you get. I think LLMs are going to change every aspect of user experience and software. So in addition to sharing what AIP is today, I also wanted to share a little bit of the sorts of things we're working on, how we're thinking about user experience in the future. We have started to experiment with cutting-edge approaches to UX that deeply integrate LLMs, ontology, and agents into your AI operating system. Let me show you some of those concepts. We start here and on the left we'll have a panel that has the ontology, agents, and logics directly accessible. On the right we have Leo, our AI co-pilot, that not only allows us to ask questions but more importantly, weals the applications itself. I want to create a new work plan. Leo tells me the first thing to do is data integration. It opens up the pipeline builder application for me. Through the ontology I can directly interact with. On the left I can see the objects and their relationships in the context of the apps here. I can ask Leo to bring the new data to bear both from the ontology side and the data sets that I need to integrate and use features that you've already seen to, for example, select this and ask AIP to connect the dots. I very clearly can see what content is AI generated and I have the explainability. I can step through, step by step and understand how this problem was broken down. And that trust is a core part of the concepts around human agent teaming here. Now I want to deploy this. Now it will open up a branch, a proposal. It will allow me to submit that to compare the depths between the old and new pipeline. I'm getting workflow assistance from the agent now. And then once I push this production, it will move me to an operational view where I can actually drag my agent to the business enterprise conbon process to start the automation. Through Leo, I have full access to see what does the agency, but on top of that, through what you say is what you get, I can build entire new widgets to help me in this context of human agent teaming see more and make better decisions. At a glance, I can see what data the agents do and do not have access to. And I can view the guard rails and the rules and security around any one of these agents. And I can also view that in the context of the operational applications themselves. I think every UI is going to completely change. This is the integration layer. I think I'm very excited about this. I think this is the moment that we should be wondering why should we not be even more impatient. How do we make decisions even faster? How do we think bigger about the potential of transformation of these technologies? We will have boots set up throughout the shire to show you more of this stuff. You can get your hands on it. You can play with it. We would love to ideate with you. Thank you all so much for joining us. Thank you.