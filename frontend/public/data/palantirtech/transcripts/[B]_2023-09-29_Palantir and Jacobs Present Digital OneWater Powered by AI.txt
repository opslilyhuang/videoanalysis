================================================================================
METADATA
================================================================================
Title: Palantir and Jacobs Present: Digital OneWater Powered by AI
URL: https://www.youtube.com/watch?v=_wVkzwNFBdk
Published: 2023-09-29
View Count: 5,891
Duration: 3509 seconds
Score: 55.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

My name is Nana Banqua and I'm your host. In today's joint webinar, by Jacobs and Palantir, we'll be exploring how we are utilizing emerging technology to take care of our water-elimited resource, specifically discussing digital one-water and the role and future of AI and water management. Before we begin, may I please ask attendees not to record the webinar. If you want more information, please reach out to us and we are happy to walk through the material in once-one sessions. We'll be kicking things off with an introduction on digital one-water and a primer on AI. This would be followed by demos of two digital one-water solutions, the first one being Smart2 and Networks with AquaDNA, and the second one, a demo-unassisted maintenance with Intelligent2NM. We will conclude with an interactive panel discussion. So please use the Q&A box at the bottom of your screen and we'll address as many of your questions as possible. With me from Jacobs today, we have Susan Moizio, Global Water Market Director, Greg Kennedy, Vice President of Water Solutions, John Reckman, Managing Director of Technical Services Group, and Jen Baldwin, a digital one-water strategic growth lead. Also with me today from Palantir, Gavi Rohas, a deployment strategist on the Palantir Jacobs partnership, and Jack Dobson, a deployment strategist on AI and ML solutions. There's a lot of very exciting information coming up and I will hand over now to Greg to give as an overview of digital one-water. Over to you, Greg. Thanks, Nana. And good afternoon, good evening, good morning, whatever you are in the world and listening to this. Next slide, please. So digital one-water. This is a concept we've had in Jacobs for, with a couple of years now in my colleague, Susan Jen and John, we've worked on this quite extensively to try and communicate both to the market and to our own staff, how we see the combination of data-driven, data-enabled water solutions with the various tools and digital transformation packages we offer as a company. Where we approach the market slightly differently with digital one-water, is we really think about how the client organizes themselves. And you can see it in the slide here that we think about their customer interaction, we think about their regular to compliance, we think about how they run their planning and investment, and we think about their whole asset life cycle. And what we really do is we try and get into understanding of challenges and what are the digital applications that they have or could be created to help them drive their performance into the future. And this is a kind of snapshot into some of the things we've been working on in the last couple of years. Next slide, please. For those of you that know Jacobs, you may have seen quite a few of our products in the marketplace or your company might even use them or you might have seen them at some of the seminars and conferences. We have AquaDNA, replica, Dragonfly flood model, or ARGO and Intelligent ONM. And the two that I want to draw you attention to for the purposes of this webinar are AquaDNA, screenshot on the left there showing how we manage the sewer networks for some of our clients, both during and after storm events and in the normal conditions. And on the right there, we have our Intelligent ONM product that was co-created with Palantir, that you're going to hear a lot more about later in this webinar. Next slide, please. And finally, I just want to say, like a big thank you to our partners at Palantir for hosting this event. It's been a real great partnership that's evolved over the past two years with Jacobs and Palantir. We are obviously, we pride ourselves on being domain experts. We have over 9,000 SMEs in the water industry globally. We deal with it every day. We have a very big company in that space and we love what we do. And the partnership with Palantir has really opened us up to a new way of working and new way of delivering a digital solution. And it's really challenged how we see the one-water cycle. Hence why we now have digital one-water. So thank you from Jacobs to Palantir. And we really look forward to working together. And what you're going to see in the rest of this webinar is some of the output of that partnership. And I think I'm handing over to Jack to talk to you about AI Prima. I think thank you very much Greg. And thank everybody for joining this webinar. Once again, my name is Jack Dobson from the Palantir side. I'm one of our commercial leads on AIP, which is our artificial intelligence platform. And it's very exciting to be here today to give you a very quick primer on artificial intelligence and different types of AI, how it's being applied in industry today. And then I don't want to steal too much of the time. I want to get straight into those demos. It's going to be the most exciting part of this webinar. So with that, let's jump to the next slide. And we'll start with a little bit of an intro into the different types of AI. As I talk through this, I want to call out the kind of pyramid shape on the left. Don't focus too much on that. Like it's not necessarily how these things build up. But I'm going to kind of go down it and talk about these different types of artificial intelligence. A lot of which you will have heard of, but maybe not seen applied in an operational or an industrial context. So starting off, AI, artificial intelligence essentially refers to the development of compute systems that can perform tasks that normally require human intelligence, like perhaps visual perceptions, speech recognition, decision making or language understanding. So this is kind of the umbrella term across everything I'm going to be talking about today. In simpler terms, AI is in the science or it's the science of making machines smarter. So I like to think of AI right off the bat as an opportunity to augment existing workflows and processes, allowing in this case, businesses to run more efficiently and more intelligently. This is the case, particularly in the engineering industry where the human element is critical to operations. And I'm sure you'll all know doubt this agree. And that human element can be supported and augmented in highly valuable ways by AI. So this isn't necessarily a brand new tool or placement mechanism. It's actually something that I see as an augmentation of the workflows we have today. Now dipping into machine learning, that's a subset of AI that allows us to create algorithms that enable computers to learn from data. So instead of explicitly programming how to perform a task, machines can use this data as an input to learn patterns and drive decision making, improving their accuracy and efficiency over time. Now ML can be a critical driver, not only augmenting processes like I mentioned earlier, but enabling optimization and improvement over time as more training data becomes available. Without training data could be decisions, it could be trends and outcomes of those decisions that are constantly developing and evolving with every day with every action that's taken out in the field. So you can consider that being a feedback loop to improve some of these models over time. Now digging deeper into kind of a deeper form of AI and ML. Generative AI is a term that you may have heard. It's obviously become extremely popular as all of attention around it over the past few months and years. And essentially this, Genai has the remarkable ability to generate content, the mimics human-like creations. So these models can produce images, text, even music, all by understanding patterns in their training data and then applying those patterns in new creative ways. Now one prime example of this is large language models. You may have heard of GPT-4 from OpenAI or other vendors like Google Bard, for example, Amazon Bedrock. There are multiple different languages out there. These are very quickly becoming commoditized. And essentially these models are the culmination of AI and ML. And on vast amounts of text-based data, for example, GPT-4 is trained on a vast amount of data from across the internet to actually understand and then generate human-like language with very impressive accuracy. If any of you have used chat with GPT, I'm sure you've been fascinated by its ability to answer questions in a human-like way and also generate what feels like new creative content. And on to questions, right? Essay is create poetry, even generate code. But of course, all of this is based on what it's being trained on before. It's important not to mistake this for original thought. This is purely recall based on the vast amounts of training, the vast amounts of parameters that make up these models. So that's a little bit of a primer. Before I wrap up, I want to talk a bit about the use cases, the actual deployments of these different types of AI. I'll hop to the next slide for that. Cool, perfect. So these are just some mic starting points around like how can you think about AI being applied in an operational context? And I won't dig through all of these. I'm sure you'll have the slides to refer to back afterwards. But I want to kind of cool out some of the key themes that I have personally seen in working with a lot of our companies deploying AI and ML, specifically large language models in particular over the last few months. I would really consider kind of look at the work you're doing today and the work your teams are doing today and think about bottlenecks. Perhaps there's a context bottleneck where teams are working today on a variety of tasks, but they don't necessarily have all the information that if available to them would actually improve decision making or perhaps that information is available to them. But there's just such a large volume of information that needs to be interpreted in order to inform a decision that no human operator is ever going to be able to consider all of that available context when actually making a decision perhaps it would be too slow or too cumbersome. That is a great example where a large language model can be highly valuable in actually be able to scale the interpretation of that information retrieving additional context from other sources or other locations in order to inform. Human driven decision making in the operational field. Similarly, perhaps you do have all the context you need, but there's a capacity bottleneck perhaps the volume of work and decisions that need to be made is just so large. Maybe every user needs to follow some sort of set process step by step, but you simply just don't have the head count to capture all of those decisions and run all of those processes. Imagine if you could scale that limit, limitlessly, well, this is an example where AI powered agents as we call them can essentially pick up some of those processes. It's important to know that this is then going to use a variety of different methods, but this can involve very specific instruction sets to an AI agent to carry out a specific process or again we could leverage some of those ML models to actually learn from the decision making and the process flows that have been established over time. I think a final thing I'll say on kind of how you can deploy large language models in an operational context. Good way to think about it is imagine if you had a naive intern on your team who's just joined the team, they have some basic training, but ultimately they're starting from scratch. You've got to think about what context do I need to provide this intern in order to understand exactly how to carry out a process. And then importantly, what tools do I need to give that intern in order to make decisions, take actions and actually carry that process out. This is exactly the same way that we think about LLM's. We think about how can we specifically provide instructions and context to inform an LLM on how to carry out a process. And then we can also provide the LLM with tools to maybe retrieve data, edit data, perhaps even run another model or perform some sort of action. This kind of context and tools paradigm is something you're likely going to hear come up in the demos and in subsequent discussions. But those are a few ideas on how you can think about use cases. I'd love to talk more about that in the Q&A section of the demo. Let's hop to the next slide. Cool, perfect. And as we start ideating around those use cases, it's important to consider some of the like common pitfalls and kind of trip ups that we've seen, especially from a palliative perspective, we work with. Over 100 customers now on deploying our AI platform out in the field and a lot of this is also kind of an educational process. This is the first time that a lot of these operational users have interacted with these forms of artificial intelligence. So what are some of the key things to bear in mind? Well, I think the biggest one to call out here is I mentioned chat GBT earlier in my talk. It's important to remember that these large language models in particular, they're not just chat. They are texting text out. That's an important paradigm to bear in mind. But the way to interact with them isn't just via a chat pod. Like there are ways, as I mentioned, of instructing these agents to go and carry out processes or retrieve data. There's a lot of varieties in which we can actually work with these models beyond just a chat based interaction. So it's important to kind of break out of that way of thinking as that is the only way that we interact with these models. I think the other thing I would just bear in mind is of course we want to meet the user where they're at. The meaning there is this is not yet another tool yet another platform that we want people to have to be upskilled on and learn from scratch. Like this isn't meant to be additional complexity to your existing workflow. The whole idea of deploying AI is to augment existing workflows. And to actually when we say meet the user where they're at is actually to enrich their existing workflow in a seamless way that makes their work more efficient, more intelligent without generating more of a training burden. And then I think the final thing like this is hit on by a couple of points here, but how do you do this in a way that is safe and secure? How do you ensure that these models and the AI components of a workflow are put on the correct rails to ensure that we have a human in the loop reviewing range. Revealing recommendations reviewing actions before they're taken and how do you also ensure that your intellectual property and your data is securely used in a secure way. Especially with these large language models, there are certain ways of using these models that are less secure where actually you're kind of providing that data back to the model to be retrained on. We are palent here in particular pride ourselves on working with these models in a safe and secure manner ensuring that your IP remains yours and yours only. And we can talk a little bit more about how we do that in the latter stages of the presentation or perhaps in a follow up conversation. But to recap, AI is not just chat like consider the different ways it can be it can be deployed. We're talking about how you'd enrich an existing process as opposed to developing a whole brand new tool or a new workflow and consider how we deploy AI in a safe and secure manner protecting IP while still enabling some of these powerful workflows. Lots more I could go into don't want to steal too much more time with that. I can hand back to Greg, I believe, and to talk about how he go through the stages of digital maturity. I've talked a lot about some of the advanced stuff. But what is the journey to actually get there? How can be a kind of a step by step journey? Any other to Greg? Thanks Jack. That's a, obviously an awful lot of stuff to get through and, you know, as you, as you told me before, it's really important to get an understanding of what the language is that's out there, how people are using it, how they're applying it. That's really been important for us when we're being on this digital one war journey for the past couple of years that terminology is different in different parts of the industry. It's different in different geographies and understanding where you are relative to both the technology landscape and where your competitors or where your compatriots are is a really important point. If you move on a slide, all we want to say before we move into the demos is it doesn't matter where you are on your own digital transformation journey. Every water company, in fact most utilities are somewhere. Everyone's been gathering data. We've had scatter for 10 to 20, 30, 40 years. We've all been somewhere on the curve. What the AI revolution is telling us is it doesn't matter where you are. There is advances and there are benefits no matter where you're starting. And that's been one of our biggest learning points in the last couple of years as we've developed and delivered our products with our clients that you are able to move up this curve pretty quickly. Understand where you are. Understand where you want to go and don't let that be a barrier to trying to adopt new technology and new workflow. With that, I'm very keen to get to our demos. So Jennifer, I'm going to ask if I can tell you up for the first one. I'm very keen for you to share our experience with the audience here about Aqua DNA and smarts your networks. We're thinking I'm going to share this screen. Let's see it. So I'm sharing this great. Hey, I'll see you sauce. So yeah, and Greg, thanks for that introduction. So, you know, what we're really focused on with Aqua DNA is that wastewater systems are complex and are generating more and more data that need to be managed. So we're potentially creating privacy and cybersecurity concerns. At our Wilmington site shown here where we operate and maintain the wastewater treatment and the combines who are overflows currently our CSO crew drives each asset to inspect it multiple times a week. Requiring traffic control and much drive time creating the safety issue for our employees. This approach leads to the maintenance screen never having a full picture of what's happening and can lead to dry weather overflows as the inspection frequency falls off. Aqua DNA is an intelligent digital one water solution that integrates data to perform ads to improve the performance of the wastewater system. Increased response to miss to events and increase effectiveness of the maintenance through. I don't have to spend half over half their day driving around anymore. The solution provides the operators enables the operators to react to and resolve incidents harmful to customers and the environment like overflows and blockages blockages in the tiny fashion. Also consistently assess asset performance and identify operational patterns and conditions leading incidents. By using both historical forecast data combined with AI, how predictive analytics at scale, it's letting providers and operators can transition from reactive proactive ways of managing a system to deliver safe and cost effective asset. So in this demo, I'm going to assume the role of woman to CSO operations and maintenance manager, Matt Copeland trying to manage events in the collection system efficient and planning operations to minimize overflows during both during wet weather and from an incoming storm events. So typically I'd be checking multiple disparate data sources to understand what's happening and plan. One source for the weather forecast another for the raw sensor reading and another for alerts. Logging into a code and a I get a view of what's currently happening in the system with all relevant information accessible for a single interface. With a view of my system showing all my assets highlighted by other status and timeframe. I decided to focus on what's happening here at CSO to better understand the cause and resolve it. So in some situations, I might receive an alert without the backup data to understand the cause of the alert. So here I see the sensor level reading over time. But I can also explore additional data related to sensor health, metadata and history to provide context on what is happening. For instance, is it higher than expected or dangerously close to over a point to get more insight into how this asset performs over a lot larger times. I'm going to zoom out to where I can see the level ratings, DBA from the base thing. Despite the alert that you can see here. We're still part below the over a full level. So we have time to see if the cause of the level spike is a blockage that's going to clear itself. Or if we need to send the maintenance crew out to clear it. Additionally, over here, we can see the impact of rain on the CSO since there's a spike in the level after a rate of it. This view enables identification of patterns with certificate impact on the collection system, allowing me to not only understand what's happened historically, but also correctively plan ahead. So far, I've been purely reactive, which helps with responding to bad situations in time. But the next level, the system ahead of time to avoid bad situations altogether, such as ahead of a smaller or intermediate storm forecast. So you go back to the home page, where I get another. I can see there's a forecasted rain alert and now I need to plan for it to minimize the effects on the collection and treatment system. Based on this, I then decided to run simulation of my system and surrounding areas to understand what's going to happen during this storm and what controls do I need to take to minimize overflows of my network. So in the day, this planning would be based either solely on the experience of the collection system operator or I'd have to get a modeler to prepare the inputs for a model from the model and then present back the results. Also without the ability to explore different scenarios via simulations, control sequences used in facilities are static and not fine to need changing operational conditions. So the rain different scenarios with the hydraulic model is not very intuitive for someone who doesn't have experience with modeling. So these methods can increase both time and resources to explore the scenarios. The awkward DNA, I can seamlessly go from getting a current view of my system to deploying a simulation model for the day of the expected rain, run and explore different scenarios, calibrate and optimize my model all in a smooth experience room and to review user interface. Reduce this time to go from receiving information on an incoming storm to bring a plan of action and this. So here the inputs are automatically adjusted by awkward DNA for the period of forecasted rain. To ensure the parameters used in the simulation are in line with what I expect, I review them before running the model. And also to give a full picture and make sure all inputs are considered, I'm not only simulating the flow and remebering this model shown on the right, which is our hydraulic model. But also the surrounding areas that flew into our system from the county as represented by the model shown on the left. So we're combining data model to forecast forecast flows from the county with the city's hydraulic model to get a full picture of the systems behavior during the rainy. For demo purposes, these models have been run already so I can go ahead and inspect the outfits. So here ahead of the storm in a few hours, I can see the control sequence the sequences to take to minimize overflows in the system. It's telling me where I have to have bounce fully open or fully close, I can configure the controls to explore to include only automatic automatically controlled sites and suggest manual interventions. I can also see what triggered each of these actions and decide whether to modify the set points. I have lost my screen here, sorry about this. Oh, this is my holidays. So here's stuff each. Then I can see what some points I need to change. So stepping through time. I'm going to simulate a behavior of my system. Sorry, at 7 a.m. I can see this storm arriving around midday. Then most of the pipes are going to cope pretty well. Now the storm is here. Most of pipes cope pretty well until about 9 p.m. When I feel pipes that are getting darker are seen spiked some flow, especially the pipes near the river. I can see the weather. I need to have maintenance on standby to deal with any flows around this time I look at specific assets. I can expect the I can expect the flow in the pipes where I see the spike at approximately 9 p.m. But also I can see spikes that I need to prepare for secondary spikes that I need to prepare for it around 3 a.m. So I can see the information I can take actions such as dispatching maintenance to where they are more needed. Most needed in the collection system ahead of the storm or rerun the simulation with different inputs to make sure I've optimized my control set points ahead of time. So to summarize with AI powered solutions operators get not only a current view of their network, but I'll also are provided with for active ways that may nging waste water systems to reduce with risks. And with that, I believe I'm going to be turning it over to Donna to give her demonstration. Hey folks, this is Gabby from Palantir and for so I'm actually going to give the maintenance demo just because of a couple technical difficulties that the setup. So I'm a deployment strategist out Palantir and you'll have to bear with me. We have Donna Isaac who's the planer scheduler at Wilmington where we're using the tools that I'm about to stop through. But you'll have to bear with me just sort of being the one to demo. So first, can you all see my screen? Okay, awesome. So I'm sure you're excited to get to get to the to get to the panel. So I'll try to whip through this very quickly to just show an example of how we're using LLMs, those large language models that Jack was talking about earlier in the context of maintenance. So one of our maintenance work with Jacobs has been in the context of maintenance planning and scheduling using AI to make more informed decisions about what work to prioritize one to balance both cost and reliability. But in this case, I'm going to step you through how from a technician perspective, especially if you have many retirements or maybe your short staffed how you can help really those junior mechanics. So better more reliable work, a little bit quicker and a little bit more informed with large language models. So for this example, the work orders and the models I'm going to show you are real, but the name and sort of the schedule is a little bit notional. So we'll pretend for the sake of this time, Joe Johnson. Additionally, all the tools I'm going to show you are mobile enabled. So out in the field, people can be on a tablet, say, but again, I'm just on a laptop for this. We wanted to make sure again to Jack's point where meeting field staff were there. So first you can see maybe Joe is not the hardest worker in this example. And I took one work order yesterday, which you can see green was completed. And today on September 27, or sorry September 21, I have two up on my schedule. So the first one we're going to click into here is just the air compressor and see what's happening. Okay. Actually, hang on sorry, this is the corrective work order. It slightly changed between my last demo and this one. So I just want to make sure we're starting with a preventative work order for the sake of them. Okay, so this is a preventative work order. And it's telling me basically have to do a monthly calibration on a portable gas detector. If you scroll down, you can see maybe some information about the asset name, you can get information from the CMS system from the tasks, but it's also common site staff are really busy. Don't always have the time. And so someone didn't fill in necessarily when they were setting up the CMS preventative maintenance schedules, all of the procedure information. So now's a junior mechanic. I'm like, wait, how do I actually do this calibration on the center. There's some information here about maybe the safety information I need or like who I should be notifying when before I conduct this maintenance, but it doesn't actually step me through exactly how I should do this on the equipment. So Joe's a little bit confused. This is where we start to give him more information instead of having to maybe wait around for an expert or go back to the maintenance hub to ask for assistance. So first, if we just click on the asset, we can pull in other information about the asset. So I can see an image. Right, at least I know what I'm looking for now. We can see information about the type of asset. And then additionally, this can be really helpful more so for corrective maintenance, but sometimes it's helpful for preventative maintenance to in case there is anything weird with the asset. I can just really quickly see at the bottom here any recent work orders that were performed on this asset and then any notes from the previous technician. So looks good. There's nothing sort of abnormal. Maybe we were sort of missing out on some of the maintenance schedules for this asset previously. But I'm still confused. I still don't actually know how to do the calibration. So we're going to head over here to the doc assist where we've been able to do what's called fine tuning of a large language model to help assist the toes of the world when they're out in the field. So again, instead of having to wait for an expert that might not have that much availability during the day or go back to the maintenance hub and maybe start looking through different manuals, the maintenance handbook, etc. I can just ask here. How do you perform a calibration on a portable gas. I'm a terrible seller. So the risk of a live demo is in the correct spelling. Okay, great. So as this is loading and actually running the AI in the background, they'll just talk you through what it's doing. So the AI is both aware of all information in the public domain. So you can think of them like a super maintenance expert that's taken into account all of the information in books or websites or training courses about how to be a mechanic. That anyone could access sort of in the public domain, but critically, it's also taken into account information about this specific site will mean to Delaware and this specific asset. So it's not like asking chat GPT to just give you a generic answer, but rather it's really informed about how we can help Joe do the maintenance that he has here. You can see it's performed sort of the answer and right here at my fingertips now it's giving me both a sort of a summarized answer and it's pulled up the operating manual for the specific asset and told me the page references that I want to check out. So I can get that more detailed information when I need it, even if someone hasn't perfectly filled out all this EMS time or all of the CMS procedures for this work order. At the end of the day, it can save people time too because you don't have to be maybe quite as detailed in those procedures. Additionally, it's worth just calling out that this is not only pulling from the asset, but where it's applicable. We're also able to and have fine tuned the LLM to include Jacobs sort of proprietary handbook on how to do maintenance. So if you were asking questions that were specific to the best practices that Jacob specifically wants their technicians to be following at Wilmington, the AI is aware of the fact that Joe sits in Wilmington is not just a generic mechanic out on the internet or whether is a mechanic specifically for Jacobs and is also wearing able to serve up those sort of like safety practices or best maintenance procedures from Jacobs. I'll just show one more thing and then again, we'll kick to the panel so that we can get really into the discussion is imagine that maybe I discover some problems as I'm doing a maintenance on this on this asset or in the case of say if I was looking at a corrective maintenance work order in the dress of time, I'll just show you guys here. If I was looking at a corrective maintenance work order, there's not usually tasks, right, like you didn't know what was going on. There's just some notes. So what we're able to do is say, hey, I don't have 20 years of experience troubleshooting this kind of an asset. So I don't necessarily have that experienced mechanic intuition for what might be going wrong. But the AI does. So the AI is able to take into account both all of the historic work orders that have happened at this site on this asset, take all of the notes from past mechanics, both for this specific asset and for similar assets. And again, that maintenance expertise that exists in the public domain, along with the proprietary Jacobs handbook about how to do best maintenance. And with that, I'm able to ask the AI like, hey, something seems a little wrong. Could you please suggest for my current situation, maybe some potential causes and help me troubleshoot. Again, it can not that it will necessarily give you 100% the answer, but it can be really helpful to help them start thinking how to trouble through and thinking through possible ideas. Okay, so this is the fun of a live demo is these answers are slightly different till last time I did this. So let's see what happens. So the potential causes that it's everything at this point given the live data coming in from Wilmington is maybe there's been a faulty sensor calibration. You could also see if there's worn out or damaged parts or maybe there's sort of inaccurate readings do check external factors. So let's take a look at worn out or damaged parts. Let's say that something's going along there. And what it's doing now is again digging into that expertise combining the data at the specific site with the Jacobs best practices with all of the maintenance expertise that exists in the public domain. And it's going to suggest a few different things that I can check out. So you can either inspect and repair the gas support. You could perform a monthly calibration to maybe prevent these sorts of issues from happening or most likely is just replace the worn or damaged parts. So for more complicated examples of more complicated assets, you can imagine this being incredibly helpful to help your sort of more junior mechanics, operate more seamlessly without depending as much on the very few experts that you might have at a site. So this can help them have the right information at the right time. That's not just generic but specific to their site and their asset. And with that, I'll kick it to Nana to start the panel. Thank you Greg and Jack for the interest of just one water and AI primer and Gabi and Jen for the demos. It's very exciting to see the application of both simulation models and large language models and different areas in the water industry. We've started to receive some questions. Please keep them coming in. The first one I will pose in your direction, Jack and it's on how can I be used to transform industries and how is where we currently are different from previous hype cycles. Yeah, great question. Big question as well as a lot. We could get into all manner of details there, depending on the industry or speaking from of course. I think ultimately of course, look any any KPI that you're thinking around thinking about whether it's efficiency cost savings, innovation, whatever it might be like these are all areas that I can have an influence. The biggest thing like my thoughts on this question ultimately it's like what's what's the real tangible thing that we can take away from this and I think actually the key thing to the second part of the question is don't over hype like we the way to adopt this technology and the way to actually prove real value with it is to start simple. Solve a day to day problem that is impacting the operators on the ground start and scale from there. So if we look at some examples that I've had personal experience with so look at healthcare perhaps I have course we've all heard that AI could assist in early disease detection discovering you drugs to cure. What prevents things like cancer more personalized treatment plans robotic surgery like there's all manner of really exciting kind of innovative things we could do in the future some of which already being explored today from my experience start with the operational problem of the ground so for example the handoff of a patient from one nurse or one clinician to another it involves a ton of note taking a ton of historical context. If that is not communicated effectively and the relevant parties aren't informed in a timely manner that can be a dangerous dangerous situation for the patient it can also mean time is lost in repeating tests or repetitively going retrieving information so what if for example a large language model could assist with extracting the relevant details from the hours and days worth of clinical notes that have been gathered around a patient. Summarize those in a way that it retains the key details and that's based on the prompting that the industry in that case or the governing body of that AI has provided with the areas like we know exit the LM will know exactly the areas of those clinical notes that are a high criticality. Basically you can retain those details and it can also then be provided the tools to go and assign and notify different clinicians and different parts of the clinical team based on the details of those notes so you've gone from a static document or even notes on a note pad or a whiteboard into something that is digitized in something that is clear summarized and it's actionable as well the relevant parties are all alerted and that data is all stored in a secure and true. So that's just one example in a healthcare setting but it's the same in manufacturing it's the same in finance think of any industry start with the operational problem of ground and scale from there. The final thing I'll say on the hype side of things like yes we've there is a lot of hype around particularly generative AI right now and just AI in general this obviously all this talk of always are going to take my job or is it going to enable this incredible thing again I think we've got to start with where is the technology today and what we're going to do is we're going to do this. What is the problem that we can solve today but what does set this hype cycle apart in my opinion is the fact that a lot of the kind of contributing factors are required to make a lot of these ambitions and these deployments real they're in a far better position than ever before to support these kinds of investments. So for example data availability the exponential growth of data available coupled with improved data storage and kind of macro data management capabilities as well businesses and different companies are becoming far far more advanced in the way that they manage and collect data and with that technology advancement means that they're in a far better shape to actually deploy AI. The same can be said for things like computational power algorithmic improvements and in general just the ability to collaborate in an open source way across these models these are all contributing factors to making this wave of AI the one that will actually deploy in an operational context. Thank you very much Jack and staying on the theme of AI for transformation Greg. We've got a question on whether you could give some examples of this specific to the water industry and also how would the use of AI evolve over the following years. Yeah, first thing I'll say Nana is I think I've been living with an AI for a number of years now because my partner has perfect recall as well and can tell you just about anything I've done in the past five years. I like the way Jack was describing it there I those of us on the panel and those of us in the audience of a certain vintage. We've kind of lived through this disruption before. You know those of us that were kind of at school or graduating or outside of college in the 90s we kind of lived through the internet revolution we lived through Napster we lived through line wire we lived through you know the the disruption to the music industry the disruption to the travel industry how we booked restaurants the move into smartphones the move into social media. We as a collective is our society we've adapted to that pretty quickly within a short timeframe. The AI is Jack describes it has come along very quickly and now you know it is most of people know technology follows about a sign on curve and none of us kind of really know where we are with AI with chat GPT with some of the you know some of the generative AI that's coming. So vice to the audience listening here is think about it on three levels think about it from yourself how is a tool like this make me more efficient by and large most of us are remunerated in relation to the problems we can solve or the value we can create. See this is a way that how do I become more efficient how can I take on bigger tasks how can I get access to a hundred brains without having to talk to a hundred people. So the first elementations AI has less limitations but use it to help you become a better reasoning and deductive person it allows you to take on more challenges. The second level is how does it help me work in my team how do we begin to communicate and how do we begin to take advantage of the data computing power that the Jack described can we like what Jen and her team have done at well mean to can we begin to think about scenarios can we begin to think about the things that we don't know. The biggest impact on me in the last in the last year my colleague John is on the panel here. John showed me the performance at one of our plants for the last couple of years and then we applied intelligent one end where we thought we were already one of the world's best plants in John and his team found another 20% efficiency we were blown away and it was because the ML and the AI model just thought about things a slightly different way we didn't connect the blower to the temperature to the wind. All these things that we didn't think about it unlocked new possibilities but it took the combination of John's teams the main experience with that computing power to unlock those no scenarios. The third bit and this is the bit that I'm quite uncomfortable with Nana is the water industry is heavily regulated quite rightly we protect public health. We cannot take risks but we also cannot stay in the dark ages we have to be efficient there is a cost of living crisis out there we have to find a way of driving down the cost of delivering our services to the public we have to onboard this technology we have to find out how it's going to drive the network costs we have to find out how it's going to protect the environment it's no longer acceptable for the water industry to wait 25 years to adopt technology we have to get on board we are on the front of every newspaper in the UK. Every two days now we need to find we need to find a way back to show how we can use this technology to actually deliver the services our customers want and we think done properly whether it's in partnership or whether it's whether it's your self as a company you just have to start using it as Jack described and to be honest I don't know where we're going but I'm excited but I also want to understand let's put it within the regularity constraints so we keep delivering that perfect product that drinkable water that will be okay and about. Thank you very much Greg and on your point of onboarding new technologies and this perhaps a question for Suzanne with technology moving so quickly could you please speak on how we ensure we get the balance rights between providing the current service versus taking risks on new technologies to in the water industry we can't just say okay we're not supplying water today because we want to test this new take out how do we get that balance right Suzanne. First of all I just want to point out I didn't know it made you an AI if you have perfect recall in your marriage I'm going to have to go back and chat with my husband tonight about that thank you Greg for pointing that out so how do we how do we get this balance when we're and I'm going to go back to what Jennifer has shown you from the awkward DNA standpoint because my background is collection system operations so when she showed that I get pulled in to see let's see what we're going to do. So what's happening in that pipe and why is it why is it going to overflow and what's happening there so when we look at what we're faced within the industry today and Greg talked about this a little bit he talked about how in the UK they're on the newspaper you know just about every day about CSOs and how do they operate their system we've been living that here in America for what 3040 years my entire career I've been working on this. We have to we have to make our systems work well and and Jen talked to you about all the data that is coming in where you're trying to make decisions in real time so we've got the answer the mail we've got to keep our systems running well. The opportunity then with new tech to do this in a way that connects our collection systems with our treatment works and we see what's happening in places where we don't have sensors and that's what she showed you is that the new AI is able to do that for us so we have to bring this data in we have to make sure that the data gives us the information that we need that we believe that data and it's actionable data and then. We supplant that with what where we need to have information and so that's the balance there the balance is making sure that we're using all the data that we have in a way that gives us the answers that we need but also that we're open to the changes because this is changing rapidly we're open to the changes in this industry. Thanks thanks very much Suzanne and on you mentioned using the data to get the answers we need and also going back to a point Greg raised about the work or MFS and John has been been doing that space John are direct this your way what is something that we're doing today that perhaps we won't be doing in 10 years due to AI so we use the data we have to get set an answers and that completely changes the way we do things currently. Yeah great great question and it really does fit in with whatever everybody's been talking about we're doing things now or starting to do things now just just in the general world to Greg's point earlier about how the Internet revolution has really changed things one of my favorite analogies on this entire topic Nana is maps GPS in your car and paper maps so 20 years ago where you're using paper maps and then we started having a lot of things that we're using. You know Google Earth Google maps that you could do on your desktop now it's on your mobile device and now it's giving you driving directions how to avoid the traffic jam that you can't see that's two kilometers down the road you know the most efficient way to get to grandma's house. You know well the carbon footprint improvements that makes the time improvement that makes the gas cost improvement that provides that's the kind of things we're seeing now in the own and business stuff that we used to have to do manually that was time consuming and complicated and somewhat repetitive we're able to get the AI systems and the data science systems to sift through that or overworked operators to give them the recommendations. So some examples very complicated at times to get chemical dosage right at a treatment plan there's a lot of variables a lot of inputs to really get that number just right. What we're doing at a lot of sites today is what we would call set it and forget it. You put the chemical dose high to make sure it's very very conservative but it's wasteful but because people don't have the time or the ability to sift through the data to get the right answer they're going to rely on set it and forget it which is very inefficient. What we're starting to do now is provide that recommendation that GPS driving direction of what exit to get off hey guys this is the recommendation in fact you've done it before at this level we know it works but you don't remember because you have tens of thousands of days you've been doing this. We'll give you that answer and then here's a key on acceptance this is a different topic we could talk about all day allowing the operator to get the right answer. The next step is to accept or decline the recommendation is a really key feature to accepting these models just like when you're the driver you can accept or decline what the map recommendation is telling you. If there's a problem on that exit you're not going to take it you're still the driver just like our operators are still the operators so the more we can help. Remove barriers to jacks point early in the presentation the more we can remove those barriers and those problems and allow people to be more efficient that's really worth things are going to accelerate and change. Thank you very much on and we've got a number of questions here related to the point you've just raised about operators either accepting or rejecting a suggestion in. I'll throw this your way Greg and it's on how do we get the balance right in the partnership between it could be between Jacobs and Palantin but also between Jacobs and its clients using new tech where there isn't an over reliance on this new AI are you still allowing how are you enabling operators to contribute back to your to your body of knowledge. It's a really important point Nana because for those of us you know a lot of us on this call you know we've worked in the water industry for a long time and one of the key things that makes the water industry work is accountability and flow of accountability and it's understanding you can hold people responsible you build a process is we build a workflow we put our controls in place we have our risk management we've got strict guidelines all of that stuff comes together to ensure we both deliver our product. Protect public health and do it in an efficient manner. When we bring new technology into that obviously like most industries that most companies we start with a small trial we see how it works we we we take it through. And there's a joke that Susan and I have that you know that there's more pilots in the water industry than there is in British airways because we're forever we're forever piloting things but it's the right way to go because of the risk the risk that we have to manage. If I put my what if I put my water exec hat on for a minute. I am rightly nervous about bringing in new technology that overtakes any of my processes or takes deductive and human reasoning out of my processes I want to know. Is my operator still an ultimate charge and I think that's what we need to get across here and I like the way that Gabby put it talking about AI agents this is about the assist this is about removing mundane task this is about increasing efficiency and this is a bit allowing us to run scenarios that previously might have taken six days we can actually run in a number of minutes. Where we need to be kind of nervous and where we need to tread lightly is when we're moving new technology into the heart of a water companies architecture. A water company already uses third parties it's fully relying on third parties to deliver a service we need to look at AI is just another set of resources that can be controlled that can be used that can be that can actually deliver a service it's not there to replace the plan or actually become the new nervous system in a water company you need to allow your current users to use it. And if I can steal a line that I've seen on a scene on a TED talk recently. AI is not going to take anyone's job but another human a another human using AI is going to take another human job if they are not using it that's what we need to think about it's the power of the assist it's the power of the efficiency gain here it's not about deploy technology and new data connectivity inside the water company it's about using this new technology within your current workflow to evolve. Thank you very much Greg. On your point and pilots and using this new technology and Susan I'm probably directing this one your way what strategies have been effective in deploying AI solutions and what does this road map look like Greg mentioned start small but could you expand them out a bit in terms of what the road map looks like. Well i'm going to agree with Greg that's surprising here and it is about starting small and it's about showing that what you're doing is working. We when we are operating sewer systems or operating plants the operators need to be in control they are responsible for what's happening I mean legally responsible for what's happening so we have to make sure that what we're doing is something that we can show them is working. And that's something from Jacob's standpoint that we're proud of first of all we have the OM at best team and john is a member of that and we're operating the plants ourselves we also have what we call market solutions was our subject matter experts so we're checking that so we're we're showing what could happen is john talked about he said you know. You offer that you're also showing that here is what they I was come up with and we're showing you it's working and then we're working to build that trust with the operators the trust is key if you can't get that trust i'm I don't think you're going to be able to deploy it. Thank you very much Suzanne and as you were speaking a number of questions came up with regards to this roadmap this roadmap and how to prepare for that now I just want your wage on and it's about how much pre work is required to begin like when when starting you identify your first use case how much do I need to actually begin. You can start I love the graphic earlier in the presentation about we're all on this journey you can start anywhere and we do tell our clients and our own staff you don't need perfect data small data for example is a great resource like excel sheets oh my gosh for decades we've been using excel to run these treatment plants right so you don't need. Terabytes of perfect databases everything perfectly scrubbed you know 100 you know perfectly calibrated meters throughout your plant you don't need any of that it's great if you have it but you don't have to start there we can meet you wherever you're at with this it may not be the most precise recommendation you could ultimately get but you can do really well with what you have. So so there's really no limitation on where you begin I think the important thing is to begin to Greg's point you know this is where things are going in the water business we firmly believe that we started our journey in the old division five years ago on this and we just started where we were at so. And we run you know close to 300 plants and are all different every one of them is designed differently different data streams different types of Keta systems different control systems and if we're able to tackle that much variety i'm sure we can help any of our clients do the same. Thank you very much on and we've got so many questions but in the interest of time i'm going to give a last one and. A quick 30 second answer from all everyone on the panel and it's on how can individuals in utility companies in engineering solutions companies encourage faster AI adoption in the water industry 30 seconds. i'll start Nana yeah similarly when John just said there AI is now available to you at your home whether it's talking to your TV whether it's using chat GPT and your own home computer just start just start using it start getting comfortable with it and then begin to have the conversation in your company about how could this type of technology benefit us start having those conversations in your in your actual workplace. i'll go next. That I think what you should do is listen to your team they're the ones who are closest to the action they're the ones are seeing what they are up against one of the things that palimps here did I really was impressed with is aggregated all the data at the first plant that we worked with them. On and having all those data streams together and being able to see what was really happening in that plant was very powerful so I think that's how you should start. Thank you season. i'll jump in on one follow the money so at some of our sites we're going after problems that have big financial impacts but are still hard to control like chemical dosage like power usage like maintenance management so if you go after something that's causing a lot of financial pain you know that's a great place to start you'll get a lot of literally get a lot of body in. Thank you very much on and thank you very much for everyone for joining we didn't manage to get through the questions but I hope everyone found it as informative as I did will be in touch after us to see if you have any more questions but if you do have any urgent questions please reach out to Audrey am I sharing my screen her emails should be on the screen. Now and thank you again take care everyone and enjoy the rest of your week.