================================================================================
METADATA
================================================================================
Title: Palantir CEO Alex Karp | Sedona Forum 2023
URL: https://www.youtube.com/watch?v=oHGRDWgLYs8
Published: 2023-05-07
View Count: 35,442
Duration: 2577 seconds
Score: 45.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Hello everyone and congratulations Kelvin you earned that award and we have to find out where we get socks like yours and really cute children like yours. I have the distinct pleasure and honor of welcoming our featured lunch and speaker and his moderator questioner. Dr. Alex Carp, we met over 10 years ago. He is now the co-founder and CEO of Palantir. When we met 10 years ago he was also the co-founder and CEO of Palantir. But what's important to know about Alex is that he represents the second wave of Silicon Valley pioneers, the first wave being Andy Grove and the people who really brought us out of the field of computing. But Alex is in a really special class of people who took all of that to the next level if you will. He is really a huge patriot. I will give you a little bit more about his resume before I get into what a patriot he is. But he has also an educational pedigree, having attended Harvard, sorry, Harvard College, Stanford Law, and he got his PhD at the Johann Wolfgang Gutte University in Frankfurt, Germany. He speaks fluent German. You can try it. I've tried it. He speaks excellent German. Great accent too. He's brought the power of Palantir to help DOD tackle some of the greatest threats and challenges that we in America have faced, including, of course, terrorism and now Russia's attack on Ukraine. He was the first CEO to travel to Ukraine in the last year during this horrendous time for the Ukrainian people. And he really has put his patriotism front and center before a lot of other CEOs even thought about it, even before this latest attack on Ukraine. He understood that it's in a sense a responsibility of the private sector to appreciate the security, the rule of law, the, frankly, the safe space that our country, that our government provides for our private sector. And in exchange, he has given so much to the American government, to the Ukrainian government, to the peoples of America and Ukraine. And so we really are honored to have him here. He's also a very generous, his company is a generous sponsor of the Sedona Forum. His company is also a member of the Ukraine Business Alliance, which, frankly, his colleague Wendy Anderson was kind of the brain godmother of this alliance where we work with defense tech companies and tech companies to help our government help the Ukrainian government win the war, start the reconstruction and get accountability for Ukraine. So I really can't say more to applaud the efforts of this man in corporate America on behalf of America writ large. He will be joined on the stage here by another great American, former U.S. Congressman Will Heard, he represented Texas' 23rd District for many, many years. He, prior to that, was also a national security expert. He was specialized in cybersecurity and he was an undercover CIA officer, very exciting. He's currently the managing director of Allen & Company. He also happens to be a board member of OpenAI, CHUB and Palantir. And I'm not sure whether I'd want one of my board members questioning me in public, especially right before earnings, but Alex is brave. Will has also recently, in the last year or so, written a book called American Reboot, Colin, an idealist guide to getting things done, which sounds also very mecanish. And also kind of like the type of book you would write if you were maybe thinking of running for higher office. Anyway, we are really, really happy and honored to have these two gentlemen here for our keynote luncheon event. Please, without further ado, help me welcome them to the stage. Dr. Carp and Will Heard. Well, Sedona, as Dr. Farcus said, I spend about a decade as an undercover officer in the CIA. And one of the things you learn in the agency is PT Buff, put the benefits up front. And when I'm hoping we accomplish in this next, I don't know if it's 61, but I'm hoping I don't know if it's 61 minutes or 38 minutes, I've been giving conflicting reports, but what we're going to do, and I hope that you'll take away from this, is that software is a new hardware. And if we don't understand that at every level of government, if we don't understand that at every level of society, we could potentially be as a country, the United Kingdom, of the 21st century. And we're going to explore this topic by understanding and learning about Palantir's journey, where they've been, where they currently are, and where they plan to go. And we're going to open this up. We made a decision walking in here. We're going to open this up to Q&A. So have some questions ready with such an august body here. I'm sure you have good questions. If you don't have questions, don't make me resort to chat GPT to ask questions. But I will. Alex, when August of 2001, I had been about nine months in the CIA. I was a young trainee. I was working in the Counterterrorism Center in the CIA. And people were sleeping in their cars. They were not going home because there was a feeling that something was going to happen, and that we knew something was going to happen, but we couldn't put the dots together. And then a month later, when the second plane flew into the World Trade Center, we all knew what wasn't put together was that what Al Qaeda was trying to do to our country. And that intelligence failure, being able to put those dots together, played an integral role in the founding of Palantir, where you all helped put all those disparate pieces of information together. Why was that Jell's value proposition? Why is that a problem that you tried to solve? Well, thank you. I'm very happy to be here and honored. And honestly, I hope someone plays that introduction at home. I could use some plus points. It's at least to my colleagues here. We recorded that. We'll play it when you come into the office every day. It's true, it was said. Yeah, you know, so it was, I kind of, after I was at Stanford, I went abroad to become an academic. And then I came back and I reconnected with my buddy, Peter. And there was a methodology they had developed at PayPal, which was basically the human mind was good at recognizing patterns in a way, computers at the time weren't. Which is interesting because some of the basic methodology things we built now work very well for AI. But basically was to help, we thought we could find anomalies in large data sets. And then I had an idea that you would have to focus on the architecture of data protection because it was more philosophical than in interacting with the agency and other parts of the US intelligence community we discovered. The actual problem was how to unify the data sets. And then I was passionate about how you not unify them so that how you could protect data so that if you look at one person in an anti-terror context, you don't, that data doesn't inherently get exfiltrated to maybe outside the building or to a police context. And building that architecture basically meant you could, in a highly scaled way, you could begin to run at the time primitive algorithms and use technical experts to find terrorists in accordance with Western norms. And I think the bigger philosophical thing was we believed from the beginning that the West is a noble place. Sure we have warts but it's nothing like the huge warts our adversaries have. And that the US at the time we already believed and it's clearly proven to be true, we have a software advantage over our adversaries at least an enterprise software. And we thought by bringing together the best people in the world to build this for the agency. Also these issues are really boring but the end use case and the people using it are kind of sexy. So you can really motivate people to do, I was the IT procurement guy in Congress. That's not a sexy topic. Nobody ever held a parade for IT procurement. I'm riveted right now. But if you go it. But then if you kind of fast forward the ability to just slightly more technically the ability to take data from any data source, reduce it to the data that's useful in accordance with the ideas, norms of your institution and make it useful on the battlefield or in your business is, you know, 20 years ago when I, I mean no one in Silicon Valley went to invest, they were like the government will never buy your product. Data is worthless. You'll never get paid and you're a freak. Get out of the office. This is a literally Sand Hill road was littered with people that were like, oh yeah, but cockroach.com is, we get kicked out of the every meeting because like, someone is like cockroach.com. Oh you know, why don't you change your business? You could be cockroach.com type number two. And because these things were worthless and then what has played out is the architectural decisions we were made and the things we were focused on became very, very valuable. You know, for example, Europe just to take a neutral example for this audience. Without the products, obviously the people using them are very, very talented. But this product that's a small part of our business did change the course of European history because without it they would have had massive terror attacks and Europe, I spent half my life in Germany, would be run by the far right. There are some Europeans here. They may disagree with this. I just view it as a fact. And so these products really can change the course of a country, of affect political movements. So is it fair to say, is it fair to say, in those early days, it's the proverbial needle in a haystack and the way you find the needle is taken to haystack and organizing the haystack in such a way that it can be looked and searched for the needle that you're looking for. Yeah. And while you're looking at the needle, let's just take an actual use case. You're looking at the needle. You're in domestic intelligence. They're looking at the needle. They're in external intelligence. And the police department is looking for the needle. And it turns out the person next to the needle is an asset. But obviously the police department isn't allowed to know that. It's not even clear internal intelligence is allowed to know that. So how do you look at, and then you have, those issues are exactly the same as, I'm looking for this needle. On Tuesday, that needle was supposed to be a doctor's appointment, but actually they're having a cheese steak. And cheese steaks are not allowed in this person's home. I'm making it somewhat PG. But how do you make sure you can look for the needle without exposing someone's personal life, every aspect of their life to people who shouldn't be able to see it? And that's not just a moral issue. It's actually an issue of it will not be adopted. And if it could be, you create a counter lobby. One of the beautiful things about software is you can actually get, for example, to syllable libertarian and the intel person have exactly the same worries. What's going to happen to the data? Who sees the data? Does a person, does a person, does the answer require you to know everything about the person? Civil libertarians want that and you want that because in your former role, you know, you're undercover. You know, it's really important that somebody who's making a targeting decision who maybe or that they don't inherently know that you're undercover. You're talking about when I was in the CIA, not Congress, right? Yeah. So help us go from solving that challenge from an intelligent perspective to the fusion of a number of different intelligence projects, intelligence products on the battlefield for the Ukrainian military to be able to use tools that are antiquated and old to defend against a superior adversary. How did that happen and how did this, the way it happened is, you know, Russia was just not spending on these things. We were very lucky. We, in our budget, we don't spend obviously maybe as much as we should, but we have this vibrant text scene. So in fact, you targeting, I mean, there are people or, if you say, I'm not supposed to use the T-word, but say you were trying to find somebody on the, or a thing on the battlefield and you had access to satellite data and say you're not the US of A. So the satellite data you have is commercial. You have access to censored data. So off of laptops, off of cars, off of phones, it is very hard to then what you'd want to do is say I want to acquire the targets much quicker than my adversary. So without software, you could acquire these targets, but you're doing it 50 or 100x slower. And so if you take one side, the Russian side's been spending $65 billion. That's, I mean, by American standards, maybe not a lot, but by international standards that's, I think, the third largest spend in the world on military. And I do think that they're quite good at certain things, but target acquisition done by hand is 50 to 100x slower. And you can't find targets that are abfuscated. So if you, in this so, in fact, if you use algorithms, you can find targets that a human can't find and you can find it at 50 or 100x faster than your adversary, which means a small country of brave people could fight off a much larger, stronger country on the battlefield. So it actually ends up being determinative. Now there is not a direct link between the products we built for the agency and this product, but the architectural understanding of what it means to take data at large scale, reduce it to a scale that can actually be used in a constitutional context. Because also if you're doing this on the battlefield as people here know, you're not acquiring the targets and automatically then going after them. They have to be vetted. Is the target next to a hospital? Now far away is it from the hospital. Is there an asset in the car that belongs to us? Is the person in the car have a phone we've broken into and we don't want to lose that information? Before you actually pull that trigger, you have to know all these things and that requires a handoff function between gathering the data, algorithmic, algorithmmatic ability to reduce it to a form that means you have something to work with and then a handoff function to, okay, yes, we're going to do it. No, we're not going to do it. But how does, you know, the software is enabling our ally to defend against a superior adversary that has better hardware? How does that same technology then be used also by the Ukrainians to prove a war crimes in a tribunal? Well, they have. But also how is that same technology being used in a clinic to provide better outcomes for their patients and how does a shipping entity better improve their product in a thunderstorm, right? Like how can one thing, I think it's what's powerful of people, how can one thing... Well, I'll explain to you technically, but the real answer is we were so blindly interested in building these things that worked. We didn't build things that, normally you build software, it's like it turns the wrench. That's how you make money. If you want to make a lot of money, you build a piece of software, it like turns, it does one wrench turn. And that actually can make you a lot of money in your business. It won't turn the wrench on a ship, but it will turn the wrench in the car, it won't turn it on a rig. We were so blindly interested, quite frankly, on taking it to our enemies, that we built this large infrastructure of software. And that software does architectural things on the back end that will then allow you to build things on top of it that are the way you interact with it. So for us, we are completely agnostic to whether you're drilling for oil and gas, you're doing admissions, you're de facto the work we do to acquire adversaries on the battlefield. There are things built on top of that engine, but we spent five, six years building this engine that's basically universally applicable. So now, even when we're working with large language models, we have... The precursor work has been built over the last five years. To the end user, it's like, yeah, how could this possibly work? It worked because we didn't have a purely capitalist interest in what we built, actually. We had to be philosophical, we had to normative interest, we're like, if you want to win, and then also we're outsider. So I always thought, who's going to buy from me? That thing better work. And so, and this is like the positive... This conversion of being patriotic and believing you're unpopular is really, really helped our business. So Alex, I can attest the first time we met, it was my first year in Congress, and I came out to San Francisco to meet with you, and you had this nice lobby, and there was not many people there, but my chief of staff and I were like, wow, this is a proper San Francisco company, and there's a homeless person in the lobby, and that homeless person is doing Tai Chi or something. And it was like, that's nice of them to allow that to happen, and somebody comes and gets me, and we go up to this room, and my chief of staff elbows me, and was like, that homeless guy's coming up the stairs. And I'm like, well, you know, it's California, right? We're from Texas, it's California, and that's how they do it. And that homeless person was Dr. Alex Cart. So I was like, is this who my, my former organization is buying software from? Why? Hey, I wouldn't be an academic, I just wanted to keep going. So your, Palantir is a software prime, right? If you were appointed Secretary of Defense, how would you change the way, let's start with DOD, would operate to make sure that we're prepared for a future where our adversaries appear? Well, first of all, I'd probably be going, Mr. President. If it is me, I don't know if you get approved by the Senate, but let's assume that. So I would say with permission, day one, 1% of all spend goes to software, software and neighborhood weaponry, where the software has been proven on the battlefield, 1% of total budget, and every six months, it goes up by a percent until you get to 10%. Because it's like in business, you win where you're winning. And we have, it's interesting because I kind of grew up, first I spent a lot of time abroad and part of the reason why I kind of became even more patriotic was this that time abroad. But we underestimate our software advantage because we're just naturally as a culture good at it. Like almost all valuable software products in the enterprise context nowadays come from a one part of the USA of A. And so we just don't understand, well, actually no one really understands why we're so good at it, but I have lots of answers. But we shouldn't really worry about why we're so good at it, we should be heavily investing. And the software context, software is only valuable if it's been proven to be valuable. We would be 1% of purchases are going to military software that where it's been proven on the battlefield IE. And every six months that goes to it's 10% of our spends is basically scare our adversary's fund with things they're bad at. So it's like, and then second thing I would do is I would go to Congress and say, I need your help. Every bit of software that's produced in this country will be used in the, will be usable in the context of national security. IE, no American company will ever produce software again and not sell it to the US government. Because this is just a structural and deadly advantage we have. I heard a few claps out there. You can do that. It's a clap, y'all. It's allowed. To produce software in this country and not sell it to our war fighters should just never be allowed. And if we can't get that done in Congress, everyone who doesn't want to sell it should have to go on TV once a week and explain to people while you're not selling the software to the US government. And maybe they have reasons. I don't think most Americans would agree with it. And then, you know, but that should just, this is not a, this is like the single most valuable thing we produce. Purely from a market cap, it is a single differentiator between us and our adversaries. And it can't be the case. By the way, I don't think there's any other country in the world where you could produce something of this differentiated value and not sell it to your own government without ending up in a weird orange-colored suit. And so that would be number two. And then, you know, I've kind of built a business. We only have 4,000 people, but I would then have for senior leaders at the top and the bottom, like a once a week thing where you can come and you can complain and nothing that happens to you. Because in large organizations, it's very, very hard for the truth to actually disseminate. And then last, not least, I would increase the pay because I don't think war fighters and others do this for pay, but I think it should be higher. And yeah, those are the things I would do. We've been talking a week in here at the Sedota Forum about deterrence, right? And how can we do things to ensure that China wakes up and says, hey, I don't want to start a war? And what is software's role in deterrence? And is there also a role in escalation? I live my personal opinion is too many people think escalation. We think rationally. We think of this concept that if we do something, the other side is going to be a little bit more aggressive. It turned out to be wrong when it came to the most recent invasion of Russia and the Ukraine. But when other countries do thing that's more aggressive, we don't escalate our posture is, does what role does software play in saying, hey, this is a deterrent because we have the best software that's going to enable us to do something that you don't want us to do to you. The use of large language models and AI is something where America is so far ahead that I think, and interestingly, I view myself kind of as a pacifist. I want our military to be so strong that no one would ever think of fighting with us. And where we're differentiated is on rolling out AI-empowered software-empowered decision-making and weapons. And I think the way to avoid miscalculations of our adversaries is to really, really lean into this. And again, I think one of the things, one of the dangers I see is we just move too slowly on this because quite frankly, also on a lot of these algorithmatic things, they're not that many people who've been involved in it. So it's not like everyone can participate and maybe then we get into the slowness machine. But I think I'm more passionate, I'm probably actually a little bit more pacifist than you. And I would like to get to a point where escalation isn't necessary because we're very focused on our central advantage and focusing on making sure our institutions adopt it. And then I would advise you, if I were working for you, maybe you should expose to the other side. And then on the other issues, I view that more as their policy issues. But I don't believe if Russia had understood the availability of some of this stuff. I think they would have fought a little longer. Are we doing enough right now in Ukraine? You know, look, prior to February last year, a lot of the interactions between the Russians and the Ukrainians, we were testing a number of electronic warfare actions in response. Are we pushing some of our best technology to use this as an opportunity to perfect and improve our new tools? Look, obviously we could do more in people in this room, not just us, or involved in that. I think one of the most important things we can do for Ukraine is just expose to the American public what actually has happened there because the American public has to support this. And while most people in this room are pretty engaged in these issues and well informed, most people have a life where they're focused on other things. And the counter narrative is quite strong. And so I think the most important thing we can do, and this is why I'm happy we're supplying our products to document war crimes. But if you keep the support of the American people, you're very likely to do well to where you lose the support. And that requires an ongoing educational effort. We got to explain it because right now if something would happen in Taiwan, the American public would say, why are we potentially spending resources, blood or treasure in that particular conflict? Who is the competitor to Palantir that you're concerned about whether it's a Russian company, a Chinese company, a Iranian company, and what does the future of battlefield intelligence and the fusion of artificial intelligence? You know what I'm really worried about is just mostly when you're dealing with technological developments, people are roughly similar. So therefore there's a strong bias that everyone pushes to adopt the technology because maybe this person's rocket is better in this context. What I'm worried about is there really only a couple people in this space commercially and in government that have been involved in this long enough to supply products. Now you would think that we would adopt quicker and I think America will adopt quicker commercially. We've been seeing this last year, even before we were supplying these kind of AI products, our commercial US grew at almost 70%. But where you could easily have a situation where we end up in the debate club. Well maybe we could adopt this in two years, maybe we can adopt it in 15 days and that's not the place we want to be. You know because yes it's unfortunate that not a lot of people invested in this but it is fortunate that people who did are in this country. And that's like we do not want to debate club. That doesn't mean we don't go through the architectural issues and they're really difficult. You can't take a large language model and just put it on your classified network that no one's going to do that. But how do you train these models? How do you have a handoff function? To your classified non-classified? How do you have a civilian decision? To be in these decisions? These are really valuable, really valuable, necessary discussions and things that have to be mandated. But simultaneously we can't wait for everyone to have a product while our adversaries are not waiting. And the outcomes here both commercially and government are going to be hugely variable. So just a neutral example, company adopts these kind of technologies correctly and maybe they don't have as good a they will win. So it's like the ability to adopt and implement technology is the deciding variable. And just because we're very far ahead does not mean we stay ahead. I mean both Russia and China have very, very strong engineering cultures and a political apparatus that is very influenced or run by engineers. And so we don't stay ahead just because you're ahead. In fact that sometimes can be a disadvantage because it's like, oh, we have, so that's my main worry. It's like, well, yes, the ability to supply products here is uneven. That's our blessing though because it's also uneven that they're here. We cannot wait. And that by the way is going to take a lot of leadership from people in this room because there's just going to be, you know, like, it's just, like these things are dangerous. So I'm very open to, no one knows where they're going to go. But it seems like there's like 500 reasons now for why we have to delay implementation. And we want to avoid that as a culture because our adversaries are not going to wait. And it is not a question of money. So it's like, maybe we have a money image. Is the question of how you use the money? The first thing I would hope that Congress would do is say, guess what artificial intelligence needs to follow the law. We have a lot of laws already on the books on how to protect civil liberties and how to protect civil rights. The algorithms have to follow that themselves, right? If I cannot steal your credit card and your identity because that's a crime. And so if I steal your face and do something with it, it should be a crime as well too. We shouldn't carve these new technologies out of the existing laws to force everybody to double down. But what are those barriers? What are the technical barriers that y'all are trying to solve in order to get the next evolution of products? Well, again, it's like how do you train a large, like how do you change the large language model to be more reliable? How do you, while you're training it, how do you make sure you can get the value into your enterprise while not allowing your enterprise to be hallucinated into making bad decisions on the battlefield or in your enterprise? How do you reduce, it's very similar to algorithmatic warfare, how do you reduce the amount of data into a middle thing so you can get used wisdom against the data? How do you make sure the accuracy of the result is actually accurate enough to implement? How do you expose people to this in a way that they begin using it? How do you navigate politically? The fact that this is very disruptive. So, by the way, I love this. For those who are, yeah, say we have, may the force be with you, Alex. So let's open it up. I think we have some, we got a hand right here who, Fran, go ahead and introduce yourself, ask your question. And let's make these in the form of a question on a comment. I know that's not going to be a problem for you, Fran. Next, my name is Fran Townsend. I was president Bush's Homeland Security and Counterterrorism Advisor immediately, post 9-11. Two things I'd just like to put in context for people in the room who were not living through it at the time we were. One, you showed incredible courage at a time when your colleagues in Silicon Valley would not work with the US government. So people should know that and thank you. Thank you. Second, there should be no doubt anybody's mind here that as a result of that partnership, working with the US government, you helped to save American lives. So thank you for that. Thank you. Positive comments are approved as well. Thank you. Thank you. Frances Najarafi from Phoenix, Arizona. So we in the US have had the highest number of capital formation, for venture capital for the past few decades. And unfortunately most of it had gone to software. I appreciate your software centric approach to everything. But that in part has been our challenge because nobody has been wanting to really invest in hardware because it's considered to be capital intensive, little margin. We essentially also are citizens in China. The challenge is that part of the sensors are hardware and the basis of AI. And there are the ones that actually manufacturing. And now we found ourselves after 20 years of doing software. So the question is, you know, you emphasize on software, I appreciate that. I don't disagree, but what about our hardware problem? By the way, thank you for saying that. I appreciate it. I really do. Well again, obviously I'm software centric. There are ways in which we're seeing this in our commercial business where a large Japanese and Korean companies are named when they build in America and we can take the way they build and implement it in America where maybe we haven't. We don't have the same view of how you build and so we can take the advantages of manufacturing and systematize them. So I do think, you know, again, back to my software centric view, I think the reason, again, I don't somewhat against my political pedigree. I think the reason why dollars flow to software is because that's where we're good. So it's like, you know, and that's, so I even think on the hardware problem, you know, which is an issue in America, the issue is going to be to increase the level of software competence to make up for the fact that other countries have a hardware advantage. And then I, just, and again, it's a little bit, I'm on my little diatribe, but you really want to compete where you have an advantage. So, and here, you know, in national security, we have an advantage here, but I think in both cases you're going to find the accentuation of software actually helps to solve the hardware problem. And some of the political decisions we've made have made it super advantageous to build manufacturing in America. So I'm a little more optimistic, but in the end, there's a reason the dollars flow to software. But, Alex, do you feel, is the government in your experience getting better at purchasing software or is it still difficult? We know how to wrap our head around an airplane or a battle carrier, but the, the, the, look, the part of the reason why the US government, to this point, spend so little on software is that here and before, it wasn't clear that it was that valuable. So what has happened now is we now know it is valuable, but software that has not been proven on the battlefield should not be installed. So the, the US government, just like every enterprise, I would say the same thing to any enterprise, we have like hundreds of clients now. I tell them the same thing. You know, they're like, what's the difference between your software and this, honestly, like often a PowerPoint, like what? Talk to someone who's used it, see if it's been used on, in an enterprise. And so, so by the way, the US government has gotten much better at this compared to other governments. So we sell our software all over the world, and the US government has moved from, you know, large, only buying things from large procurement documents, which is just not the way software works. It's just, it just doesn't, hardware can work that way. Software does not work that way. So what the US government needs, in my view, needs to do is now that we know it works, spend more under the condition that you can prove the software works. So a lot more money, but only for software products that are demonstrated to work under very harsh conditions. And that's the solution. We are going to get to that solution, but we need to get there really quickly because our competition adversaries are going to work very hard on this. And as the former IT procurement guy in Congress, buy, don't build. Take advantage of that expertise we have. We have time for one more, yes, sir. We have a microphone coming to you. Introduce yourself to the group and stage your question. Andrikudowski, CEO of the Kudowski Group. Now I have one question. If we look at from a different perspective by looking at the value chain in order to be as efficient as possible, for example, military action, what would be the portions that you consider as the right one for software versus hardware? Because at the end, that's a value chain that must be optimized rather than each individual element. Yeah. Well, I mean, it's obvious like you ask a doctor. But I just, yes, there are kinetic action software by and large isn't going to do that. There's organizing. There are people on the ground. Software doesn't do that. Those are the most important people. But the placement of those people bringing them out safely, the support function of figuring out what assets you deploy and how you deploy them. Then also, by the way, I think there's going to be a collapsing of the command chain in operations where there's more touch points from top to bottom. That's all software. I want to end on a positive note, but I don't think this question may elicit that. What happens if our adversaries get as good as us in developing software? Well, you know, I have this ongoing debate with my people I know in my family and academics where they believe the rule of law would have, if so, fact, automatically developed in the absence of the US's military superiority, especially superiority guaranteed with nuclear weapons. And I think that's just, you know, that is a viewpoint and it's super interesting to discuss in grad school, but it's pretty bereft of how these things work in the world. We have a very special culture where I think actually Americans might agree among ourselves to a rule of law if we were left alone. That's one of the things that makes this country so special. I don't think almost any other place in the world people would do that. And our adversaries are certainly, you know, I mean, you know, I actually have a very high opinion of our adversaries. Like they're very honest. Like they don't believe in this world view. They only agree to it because we have a lot of force, both economic and military. And if we lose either or both, they will set up a different world order that actually conforms to their view of the world. And we will not be happy with that. And this is why, like, you know, I think, you know, like we need to be very focused on these issues and maybe, you know, it's like all these things that we fight about in this country, we really get to fight about them because we have a world order where we're guaranteed our right to fight about it. Largely, no one else cares about these issues besides us. And if we don't, if we're not in a superior position, both economically and militarily, basic tenants of the world order will shift. And I, in again, so when the interesting thing is about these debates is there really are a lot of people who disagree with that. And I, you know, I believe in dialogue, but I don't think that's a bridgeable disagreement. Because if you believe that, you know, we as humans in a kind of Kantian way will automatically across cultures, unmute a world order that involves rights of privacy and rule of law, then you don't really need all the things that, you know, like military might and economic might. And, but I think that's just obviously historically wrong. And there's no evidence for it. And quite frankly, that's a theological view. And I, I think I'm interested in theology, but not on the battlefield. Well, that's why we're here at the Sedona Forum debating these timeless principles that all of our friends, Senator John McCain, as spouse, when he was in government. Ladies and gentlemen, Dr. Alex Park. Thank you. Thank you. Thank you. Thank you. Thank you. It was not too. It was not too.