================================================================================
METADATA
================================================================================
Title: Introducing AIP Pipeline Outage Scheduling | Kinder Morgan + Palantir
URL: https://www.youtube.com/watch?v=MOxGftk2gHw
Published: 2024-08-22
View Count: 4,133
Duration: 3017 seconds
Score: 70.0/100
Rank: A (Active - 高参考价值)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Thanks everyone for joining today. We're here to talk about pipeline outage scheduling. My name is Matt Babin. I lead our energy work at Palantigar. I'm joined here by Mark Hughes at Kinder Morgan. The plan for today, I'll give a very, very brief introduction and then we'll get to the much more interesting part of what this work is looked like in practice here at Kinder Morgan and then jump into a demonstration of what AIP for pipeline outage scheduling actually looks like. We'll leave time at the end for questions. Please, if you have any questions along the way, just throw them into the chat Q&A field. We'll be collecting those and collating those as we go through. So if you have them along the way, it's great if you can put them in because then we can bundle them together and hit as many of your questions as we can at the time at the end. We'll also end with some closing actions and things you can take away from today. Great. So as a brief introduction to Palantigar and what it is we do here, I think most of you who are joining today have heard of us before. A quick introduction to those of you who haven't and a quick refresher for those of you who have given that new things are happening in this space all the time. So we do just one thing. We build software to help the institutions that we think are most important in the world, build software to make decisions in the government context, in the commercial context. So in a highly regulated environment, in a safety focused operating environment where outcomes really matter, there's a big gap between what a four billion parameter model and a chatbot look like and someone in the field who a human who asked to make a hard decision with trade-offs in an organization. And so we see some people in this space looking at, you know, gender of AI and large language models, like which large language model should I choose the same way people are thinking of which hyper-scaler should I work with before. And that makes sense because it's the same players in the same space. We think that's the wrong question to ask. And the right question to ask is what problem do I want to solve first. And then the second question is why would I only want to use one model to solve that problem. These problems are really complex. Your ability to use more than one model should be easy, which is what you'll see today. Moving on to another entry point in this space right now is that people are thinking of AI often as a sort of like how can I chat with this PDF or how can I, you know, enable this workflow to go faster with a co-pilot. Everyone does this. We do this too. You know, I don't think that anyone is going to book a room without using a co-pilot. In the future, I don't think anyone who writes code is going to write code without a co-pilot helping them through that work. But I think that the real value and the real gain for your organization isn't a chat interface or a co-pilot. But the ability of a system to guide your operators through a decision and ultimately to suggest to them a course of a decision or an action. So what operators need isn't the ability to directly interface with a large language model that has no context about their business or their space. What they need is a way that they can interoperate and integrate AI into the workflow of their day-to-day work and to build an application that will allow a human and a machine to jointly act and process these decisions, which is what we'll talk about today. So AIP for us is the product suite that can integrate with all of those existing investments that you have, whether those are models or other pieces of infrastructure, and provide this capability for human and computer decision making. So it's the infrastructure that integrates that large language model with the rest of your ecosystem in a secure and governed way. We do this through what we call the ontology. And those of you who've you know interfaced with us before, you've heard this phrase a lot. So that's the critical part of the platform that really unifies, you know, your data, your logic, and your systems of action into one place. And just one level deeper down on that, right? So you can think of the ontology as the digital representation of your physical world. So it's the nouns and verbs of your business, the things you own, the things you schedule, the customers you have, the contracts you negotiate with them. So the ontology contains all the data and information about, you know, your compressor stations and how your nominations are created and the states of your maintenance activity, all the relevant data and the data model for your world. It's also all the business logic. So whether those are machine learning models or physics based models or other models that you already have in place, right? Large language models aren't great at quantitative questions, but they're really, really good at using tools. And so the connection of the ontology to logic is what gives us the ability to enable those large language models to call those systems of logic. And then most importantly, right, you need an interface for that operator to evaluate those actions and to actually make a decision. So AIP models those actions that can be taken in downstream systems, whether that's SAP or Salesforce or work order, right, and enables secure right back governed under your enterprise rules back to those systems. Because that's what we're really after is those decisions that really matter to the business. So that's what we build and why we build it. Increasingly, we're building more and more things like you'll see today, which are modules that sit on top of the platform that you can just download with a click. Onto your existing stack that you can configure onto your ontology and then you're up and running on a workflow. We're about 4,000 people. We're based in Denver. We've been in energy for a decade. Across the value chain, companies of various sizes, those companies vary a lot. We think, you know, we want to work with companies that want to be unique in what they do. What's the same about the work we do is that it's focused on problems that matter, solutions delivered at pace that really matter for the business. And so with that, I'll hand it over to Mark to talk about what that's looked like at Kinder Morgan, how we got started and what we're doing now. All right, thanks, Matt. So yeah, I think if you get to, so I'm Mark, using the CIO at Kinder Morgan, have been here for quite a while. So a pretty good idea of our business and how we operate through all the different acquisitions and things that we've done over the years and all the new builds. Not dissimilar from a lot of companies in this space, certainly the midstream space in terms of how we've grown and how some of our data is fairly disparate because of that growth through acquisitions and such. And so we've got about 11,000 folks in the company and we're always looking for really good tech solutions if we can find them. So just to go into a little bit about our relationship with Palantir and how that's evolved over time, a really nice, pretty slide that there's no way I could ever put together on my own. But basically our relationship goes back to 2021. About the summer of 2021, we were first approached by Palantir and like many folks I suspect on this webinar, there's lots of folks that knock on our door every single day. And so the challenge that we always have is, you know, how can we find if there's value in a particular service or software or company or whatever pretty quickly because we don't have a ton of time to go through these things and figure out what works for us. So Palantir was great to sit down and work with to come up with an idea of the short piece proof of concepts or POCs that we could put together to figure out pretty quickly, you know, where do we have ROI, where do we have good solutions that maybe we'll work for the enterprise. And can we put that in front of the folks that matter very, very quickly to get their buy-in. And so right out of the box, they were very good about coming up with that plan. I think they probably already used it in many places before. So it's not a new problem set that they're trying software, but certainly three critical things stood out for us as we started down this journey with them. One was we needed to make sure that we had a business leader, a very senior business leader that was willing to put skin in the game. If we could come up with a solution that works, we need to show a true ROI on it and we need those folks to stand behind it and either budget for it or plan for it in their financial plans. So that was one. The two was to really have a flag bearer from the business. Someone on the business side that can carry these things forward and is really passionate about the problem that they're trying to solve and they're passionate about using technology to solve it. And then the other was, and we kind of talked about it, was a short POC that the proof of concepts needed to be very short and very quick so that we could prove value quickly and move on to something else if it didn't work out. So those are three really, really important factors that we took into account early on as we started looking for solutions. And the first one we did was around optimization and that was really around natural gas storage and mostly some of our midstream unregulated assets where we use that, but we've expanded that to be further than that now. And it's looking to see how can we how can we optimize the space that we have? Like many folks, it's hard to build new infrastructure in the US. So you've got to be able to get as much as you can out of the assets that you already own. And so this was this was one of our first steps into that. And then that was very successful. And so it was very successful quickly. And so there was a lot of enthusiasm across the organization around looking for other options and other solutions that or other opportunities where we could where we could potentially build a solution around. And so that led to expanding our relationship. And so when we looked at ways to try and come up with various ideas, we started doing things like participating in FoundryCon and AIPCon so that we could not only share information around what we've done, but also get information from others, right? Those are very, very good avenues to see what others are able to do. Even outside of our industry and outside of our space, but they can resonate with folks. And so generally the business and IT would go to those and have been going to those with very good results and take the ways that we get as part of it. So one of the things that we stumbled into, if you want to call it that, was you know, we decided as the SEC was coming up with rules, although those aren't out yet, for public-be-traded companies around emissions tracking that we needed to have a single carbon ledger across the company that we could use for all of our emissions reporting and our sustainability reporting. And so in 22, we ventured down that path and built a full-blown emissions tracking solution on Palantir and we integrated all of our disparate systems to pull that information in. And we're also doing some work around pipeline integrity monitoring, a little bit around power optimization on some of our products pipelines and pump optimization as well. And then the one thing that you're going to see and that we're very happy about and excited about the solution that's been developed is pipeline outage scheduling. That was a result of a conversation that one of our business unit heads and I had back in late 23 and we set that I set with Matt in team and talked a little bit about what we were after and they were able to go build a solution that's kind of a plug-and-play box that you can download and do a quick start on. And so very excited that we've been able to work with them to build that. So very good relationship. You know, if I were to tell you really quickly what makes it successful and then I'll get to the part that everybody's here to see is, you know, look, there's a handful of reasons why this relationship has been successful and why it's expanded. One is the software. We view this as world-class software, Foundry and AIP. Both have great, well Foundry itself has very, very solid integration capabilities. Frankly, we think they're state of the art and that's really what we view as their secret sauce. That's their single biggest benefit that we saw right out of the box was that we could get things up and integrate it very, very quickly and not have to spend a bunch of time on the plumbing, if you will. The second's the people and I can't really say enough about this but every person that we've dealt with from Palantir, be it Matt, be it the folks that do the technical work with us, their top notch. Look, these guys know what they're doing. They're great to work with. You really never have to explain something more than once, which is awesome and they're usually a little bit ahead of us in trying to figure out what the next question is going to be. And so in my world, and I suspect in many of you guys' worlds, that's really, really important. You don't want to waste time things on things that you re-explaining things. You want folks to pick it up and move on and let's get a solution in place. And so top notch folks, great people, beside the technical aspects of it, just really, really good people to work with. And then finally, I guess the key is finding good use cases. We have a pretty strong culture of having ROI around most of our software deals that we do and also some of the development, a lot of the development we do as well. So being able to establish that with the business is really important. I know there's some folks probably on here that the challenge is how do you hold them accountable for that? Well, that's a different problem, but certainly we do a good job of finding where the opportunities are at and putting things in front of people that work for them and provide a benefit to the enterprise, the organization. And so all of that is meshed together to really help us expand this relationship and be successful at it. And so that leads us to where we're at today, which is basically the outage scheduling solution that we've put together with them with Palantir. And so probably the first place to start is defining the solution to the problems faced. So I'm not sure if other folks are like this, but one of the challenges we have and a lot of this has to do with the fact that we've grown through various paths in our history. And so while you do a lot to do integration work on acquisitions, you don't always get it right. And so you end up with data in various places. And so trying to understand all of our pipeline outages in one space has been a challenge. And we've got a pretty vast network. We've got about 85,000 miles of pipeline across the US and of gas pipeline specifically. And trying to get a lens into there across all of the assets from a customer perspective is very, very difficult. So what we were able to put together and what Palantir built as a module was something that pulled in all this data from different data sources sits on top of our ontology, which we built out and worked with them to get all the right data in for this particular solution. And put it in a way that in our case is customer centric so that we can understand impacts to our customer base across all of our assets, all of our natural gas assets specifically. And then give us an indication of where we have blind spots. So how would this show itself in the past in terms of some of the issues that we had? Let's say we had three or four pipelines that had various outages that just so happened to have a particular customer that was affected by all of those outages. In the past we maybe wouldn't have a way to see that. And so where does this show up? Well, when it happens and then the customer's not very happy. And so not what we wanted to have happen. And so a couple times we stepped on that rake and we decided it's something we need to solve. And so this helps us do that. It also gave us a way to do some what if planning. There's a little bit of stickiness with the what if planning because as you get into regulated assets, you've got to be very careful with how you look at not affecting one person more than another person. As a customer, it's got to be equitable and it's got to follow the regulatory guidelines that we have around how we look at our assets and what's public and what's not public. So very important component of this is the regulatory compliance piece. And with with the lens that we're trying to minimize as much as much disruption as we can for our customers. So that was the problem. And that's what they went off and built. And so the solution really I've hit on it a couple of different ways definitely gives us visibility into upcoming outages not just by customer but also by asset in asset region. So we're able to see what's going on visually, which is which is very important. There's several audiences that this is going to be pushed towards commercials one. Some of our technology areas in the pipeline space is another the control rooms things of that nature all will have visibility into this particular product. And the bottom line is it improves planning and improves predictability around what's going to happen on our assets. So very important for us a very important step in a journey with our with our pipeline group. I can tell you we showed them the solution I believe it was last week I think that in a tremendous amount of enthusiasm at the very senior level of that organization around what we were going to put in their hands. It's built out as a solution. We were finishing up the the data integration on our end. We expect this to be in their hands the next couple of weeks as a production grade system soup to nuts to get our taking the solution that that Palantir developed doing our integration work around it expanding the the ontology as we needed to and then getting it in the user's hands is probably going to be about a five to seven week effort. So very very short time frame to get this thing up and running and in production production ready. And so with that it's probably perfect timing to throw it over the fence and do the demo. Awesome. Thank you Mark. I think that that sets it up great for me to hand it over to Michelle to talk about what we're going to see. Michelle over to you. Great. Thanks Matt and Mark. Hi everyone. I'm Michelle Dickey. I'm a deployment solid strategist here at Palantir. I'm going to be walking you guys through our AIP now pipeline outage scheduling module. So kind of the module you'll see we'll go through different facets. One looking at an impact analysis to understand how how outages impact both the business and our customers. How you can dynamically manage your schedule. See how AIP can bring recommendations and facilitate the planning and execution process. Look at how you can continuously monitor monitor how you're performing on outages, etc. Before I jump into the actual demo I wanted to mention that it's notional. This is not kind of Morgan's data. This is exactly what you'll get out of the box if you download this outage scheduling module. So what you're looking at here is our outage scheduling module. Kind of like what Mark said, if you're going to schedule an outage now you probably face a lot of the challenges that he talked about with data being in disparate systems, having to talk to different teams, having limited visibility across your assets and testing out different scenarios. So this module we hope to address kind of those different challenges and take it a step further with AIP. So the module itself has three main tabs which we'll go through. The first is the outage schedule. So this should give you an idea of outages that have happened, outages that are planned to happen and let you kind of dive a little bit deeper into some of the impacts around them. The second tab that we'll go through is a planner. So this is an AIP assisted planner to help you more effectively plan and schedule your outages and the last tab that we'll go through is an analytics tab which lets you see analytics on your past performance on how you've been doing with outages in the past. So you can make more informed decisions about how you plan and schedule in the future. The main page that you're looking at here at the top has high level metrics about outages that are scheduled in the next 90 days. You can see that we have 76 scheduled outages which average a little bit more than two days in time and happen across different assets and these can be customized and configured depending on what metrics you want to see. The main section of the page here is actually our outage schedule. This is using a dynamic scheduling widget and foundry backed by the ontology what Matt talked about earlier where the y-axis here is where the outages are happening. I'm in this case it's compressor stations. The x-axis here is across time and each one of these boxes represents an outage colored by the type of outage. It's dynamic so I can as a planner go and move things around make some changes and test the changes as I go. You'll see that on the left hand side here I can see all of the changes that I've made and want some happy with my changes I can review the changes. You'll notice it says something here 34 soft violations. With scheduling and foundry we can add rules and constraints to our schedule to kind of alert our planners or kind of enforce different constraints about our schedule. In this case here we have a staffing constraint where two engineers project manager and operations manager needs to be assigned to an outage and if they're not you'll get this little warning saying outage event staffing check. This can help schedulers be alerted about potential violations in their schedule and again these can be configured and customized depending on what you're looking to do and they get evaluated as you move. Directly from the outage schedule we can pull up more details about an outage so I just clicked on this schedule of maintenance outage happening at compressor station 150. If I go into view details it's going to pull up all of the relevant information about the outage which has been integrated in the ontology across your different sources so at the top I can see who has been assigned to work on this outage what the impact of this outage is so in this case we're looking at the total volume that's been impacted and how much is going to cost. These cost models can be configured down to a location level and can be backed by different ways of measuring impact depending on what you're looking to do. We can also look at our time series data so I'm just going to zoom in here to our outage window so you can see kind of what happens to the time series during this outage so this orange box here represents the outage event and we can see kind of a drop in our flow during this period. I'm also able to see all of the contracts which have been impacted by this outage. These are from downstream delivery points from the compressor station. I can see a maintenance history so all of the past work that's been done at this station and also see where this outage has occurred on my pipeline. I'm also able to start doing, I'm also able to start doing some scenario analysis so for example if I wanted to kind of see what would happen if this outage actually took like a few days longer then we had initially planned how would that impact the total volume, how would that impact my dollar amount, what happens if the price changed to start some to start doing some planning that way as well. In Fandry you're not limited to one type of schedule we can also see different types of schedules so in this case we're looking at a staff schedule so like I mentioned earlier you can assign staff to work on outages so this can also help with your people management knowing who's scheduled to do what and when and you get the same functionality as you do on the outage schedule. Like Mark mentioned earlier you can see the same set of outages on a different kind of access where instead of looking at outages across your assets you can see the same outages as they affect your customers so now the why access is customer, x-axis is time each one of these pucks still represents an outage and now they're colored by where they're occurring. So for example if I click into the scheduled maintenance event which is a slotted impact volunteer utilities I similarly can pull up details about this particular outage to understand what the impact to my customer is I can see how often they've been impacted so in the last 90 days there are six impacts to them 14 scheduled in the next 90 days I can see kind of a slim down view of the schedule of outages which is going to affect the contracts we have with them and then see the actual contracts themselves. So I think this first page is great for enabling planners, schedulers to make manual changes dynamically and get more information all of the information they need to make their schedule updates and changes and go through their planning process but we can actually take it a step further and have AIP agents or AI agents help us in facilitating and accelerating the planning and execution strategy here so this should help accelerate kind of that process for us. So the AIP agents are going to walk through a similar process that a human might go through and kind of help accelerate the process and also provide them with like maybe more information than they would have gotten kind of on their own. So I'm going to start off by looking at scheduling a particular maintenance event for a compressor station or at compressor station 325. This is just going to be a regular type of maintenance event and kind of the first step in our planning process is to estimate the duration of the outage. So this will help us to figure out when it should be scheduled. So as I clicked this button estimate duration it triggered a function in the background and AIP logic function which is going to leverage generative AI or LLLMs and conjunction with your ontology and some other tools like a calculator tool and a date and to help us estimate the duration of the outage. So basically we give it a prompt to saying you're a natural gas planer, your job is to estimate the duration. These are the set of tools that you have and basically it's going to look at historical maintenance events and similar outages that your company has had in the past to make a more informed decision about how long this particular outage is going to take. So you can see here the logic function has estimated that it will take about 14 and a half hours as a user if I disagree with this for whatever reason. I have the ability to override this and give in my own perspective. The next step in our planning process is actually to schedule the outage. So this like the first function is running another logic function in the background. The results of this logic function is a proposal inbox. So an AI agent will propose different windows and time when it thinks is the best time to schedule the outage. It'll provide comments about why it thinks it's the best time when they are and you can choose to approve or reject them or even add your own. I'm just going to jump in to show you the actual logic function behind the scenes. So this is a tool in Foundry called AIP logic. It's a tool which enables you to build reusable scalable pieces of logic which leverage both deterministic logic, generative AI or LLMs with your ontology. So in this case we understand that outage scheduling is a cross-functional exercise which requires data from different places and probably inputs from different teams. So we've used AIP logic in this case to kind of walk through the path that someone might go through in terms of like talking to different teams, pulling up different information, etc. So in this case we're taking the outage that we're going to schedule. This routine maintenance event at Compressor Station 325. And the first step in our process is to find a windows and time where you have access capacity in the pipeline and also have the right staff available to work on the outage. It's also going to take into consideration the urgency of the outage. So if you have like an equipment failure maybe that needs to be handled right away versus routine maintenance that six months a year or two years out. This is going to use GPT-40 in conjunction with a tool. So this is bringing in deterministic logic in conjunction with an LLM here. So this is going to recommend kind of an initial set of windows. We're going to go through other similar steps where you're assessing the impact of those windows by dollar amount. It'll look at other maintenance events that are supposed to happen at this station or at similar times and same with outages to know if there's anything you can do an aggregate or if that helps inform your planning decisions going forward. And then like I mentioned the result of this is a right back to your ontology of these proposals of suggested times of when to schedule this outage. So as a user I can see these proposals. I can choose to accept or reject them. I can add comments about why I'm choosing to accept or reject them. And this we can eventually feed back to the logic so it can make more informed recommendations going forward. Like I mentioned you can always add your own if you don't agree with any of these particular windows. Once an outage is approved it'll get put onto the calendar. And the next step is to assign personnel to go work on this outage. So this next step here lets you choose people who are available to work on this outage and you can filter by the title where they're located etc. The last step is to communicate about this outage. So you'll likely need to inform both your customers and your internal team about the outage that's slated to happen. Like the previous steps above we have logic functions which help draft these communications enriched with data from your ontology. So in this case here you can see the first few examples are communications written to our customers with some pleasantries saying like apologies for the inconvenience and letting them know when this outage is going to take place what to expect, how much volume that we think will be impacted. And we also can draft similar communications to our internal team letting them know what to expect if there's anything in the past maintenance history that would help them when working on the outage etc. You can send these notes directly from Foundry which will send an in-platform notification or an email and it can go to different types of devices depending on what you need. And again all of these are you're able to edit them or draft your own. While going through this process I'm also able to pull up all of the relevant information about this outage like the previous maintenance history, previous outage history which contracts are impacted any of the relevant sensor data and my impact calculator. So I can use this as I'm walking through the process either to kind of look at what the the AIP agents have suggested do this planning process myself. The last tab I'll talk about is our analytics tab. So this tab helps us get a better understanding about how we're performing when taking care of our outages. We've come up with a scorecard methodology which scores outages on five different scores. The financial impact maintenance history compliance duration the safety risk and the outage frequency. Each one of these scores is one to five where one is the worst. Five means you're performing the best. In this case you can see maybe we do really well at minimizing our financial impact but have room to grow on how long we're taking care of these outages. The outages are actually scored automatically by an AIP agent. So every time a new outage hits the system it'll get scored through an AIP logic function and all of the scores are in these scorecards so you can kind of get a deeper dive and understand like why a score has been assigned and add scorecards manually at a scorecard if you disagree but a logic function is going around in the background. And we can see all of these scores and aggregate to understand like do we perform better on certain types of outages like maybe we do better at tackling scheduled maintenance versus control system issues or unexpected failures. Maybe we do differently on types of priority of outages so if we handle lower priorities better than higher and we can see how we're changing over time to know are we actually getting better at planning and executing our outages as we as we go through time and this can help us understand how we're doing and if there's anything that we could be doing better. So I think that's everything that I wanted to cover in terms of the demos. I think we can open the floor to any questions that you guys have. Yeah thank you. Great thank you Michelle. As we mentioned at the beginning if you have questions please just throw them in the Q&A box those will come right to us. There's been a few sent in while we were going through what we've done so far so we'll start with those but welcome welcome more. So the first one that I'll tackle this one I think it's a great question. You know what data foundations you need built before you could do something like this. And my answer to this is a little bit that's like saying like when is the right time for me to start going to the gym or eating healthier like today or tomorrow. So you can do a version of everything we talked through or the workflows that Mark mentioned on where we got started with data you have now. You know again I'd flip this around and say this is oriented around what are the decisions that you want to make in the platform. You're making those decisions now. There's certainly some data foundation on which those decisions are being made. And so we've designed the platform in a way that let's start with what you have and then move forward from there. You know I think for a while we've seen people sort of saying I'm going to engage on a master data management project. I want to get all my data clean then I'll do something like this and as Mark mentioned if you well I don't know if you want to add into this too but you know if you acquire something that doesn't fit your data foundation you've then spent all that time cleaning things in a world that that you then create that's messy or if your problems change. So I would encourage everyone to think here of you could start on this with your data as it exists like we designed the platform to anticipate messy missing gross data. That's the point because that's the world we live in. I don't know if you have. Yeah, look at. No, I would say that in that spot on I mean I think that the speed of getting things up and going allows you a couple of opportunities. One is the integration is so fast if you believe you make a mistake it's pretty quick to fix it for one thing. So you don't really have to step back and do you know a multi-month you know master data management design process and well that's important I think to have a vision of where you want to go. I don't know that the way this thing lets you build out your data and your ontology that that's necessarily your requirement. I think if you have the big blocks figured out then that's how you can start to figure out how to how to put this in the ontology and then just fill in the buckets as you have it and I can tell you without it out that's what we did on outage and so we had to we had a few different things that were pretty straightforward and we had some things we had to clean up but again most of it was pretty quick and we were able to move through it pretty quickly but yeah that's I would agree with which said great Michelle there's a question here that's that's on the kind of down in the weeds but we'll go from from big small and then then back up again. Curious if the application can help us also schedule in a way that minimizes pressure cycling. Sure happy to try and take this. I think pressure cycling you're probably trying to like minimize the impact or the integrity on your pipeline so I'm guessing like big outages disrupt or hurt your pipeline in some way. I think I like the first step to tackling pressure cycling and including it is probably coming up with some way of estimating the impact your or the integrity of your pipelines and then you can start to think about how you schedule outages in a way and where you're minimizing like huge disruption so I think if you want to tackle pressure cycling it's definitely possible in the application but probably the first place you'd want to start is kind of assessing the integrity or coming up with a way of measuring that. Great and then one more I think Michelle to you again sort of on specific so what are the timelines how close to real time are these are these results so I think that's around sort of like latency of the system and then latency of sort of processing in actions from users. Sure the users interact with it you saw as I clicked buttons it's almost like a immediate so we can write back to our ontology right away you can stream data and foundry so for example like the sensor series maybe you have high sensor series those you can have I think like millisecond latency so it depends on like what you're asking in terms of like how quickly you want to see it but for example we can pull from SAP if you have you outages there at whatever frequency makes sense it could be every hour every minute like time series data maybe you want a stream so it really is variable. Great thanks there's two here that are sort of related more specific to I think the harder part actually the human side rather than the technology side so Mark I'll route these to you so how long did it take before Kinder you know builders users stakeholders to fully trust the output or is that still in process and then also related I think you know when you've implemented this have you used all the out-of-the-box features or what were the major sort of customization or configuration pieces that that you felt you needed or that users felt you needed. Yeah I mean on the on the first side of it about getting comfortable with the output I mean certainly the AI piece is something that takes a little bit of time you have to see the proof in the in the in the output right so you don't blindly trust it we don't blindly trust it we do look at what it comes up with to try and determine is that what we expect would have come out of it and is it reasonable and so there's a reason what is check on the impacts to our customers whether it's capacity or financial that's fairly easy for us to work through so we generally model that somewhere off you know manually to make sure that we're getting the right calculations through there and things of that nature just to validate the the data that's there so I would tell you with any solution we're going to layer AI on it you've got to you've got to validate what you see you can't blindly trust it but your confidence level goes up over time and that's essentially what we're seeing with this solution and as I think the other question was around any major customizations and things we took out of the box well we were in a lucky position with this one because we we kind of helped Palantir understand what the problem space was and they built that based on the input that we gave them now they built a lot more than what we really needed right out of the box initially and so there's some things that Michelle showed you today that we we will ultimately implement but we're going to not implement necessarily day one and but but I can tell you we had very little customization because essentially what they did is they they tailored the outage module to a lot of what we do but they made a generic so it could work for anyone else and so a good example of that I think Michelle brought up about how you could push emails to customers and regulate its space you know we really we really have to post them to an ebb and so we're going to be very cautious with how we go down that path in our world what we'll do is that particular step what we'll do is we'll we'll do an integration into our ebb system and our normal process that we use for all of electronic bulletin board postings for outages and that'll flow through our regulatory group and everyone else and so now with with some cases where you don't have the same regulatory constraints around how you communicate with your customers then then that's obviously a great way to just directly give information out to them if you're able to do that so so good flexibility on their part I think it works for for different companies depending on which your environment is but we didn't have a ton of customization out of the box I'll just leave it at that great um the other thing I think this interesting on the on the customization and configuration side is is again you you can remember that this this sits on top of the ontology and that's going to be configured bespoke for every user of the platform so yes you you can say that pipelines are pipelines but again to the degree to which the ontology is the nouns and verbs of your business you're going to have different ways of running your business and so some of that configuration actually has already happened for people who then want to put this module module on top um there's a specific question here about connectivity to SAP for PMs that require outages yes we have a connector to SAP right out of the box so that's a that's a one word answer yes Michelle there's two questions here that I think are interesting on the on the workflow bit of sort of how humans interact with AIP agents so one in terms of how often are AIP agents suggestions rejected or replaced which I think is interesting just in terms of the workflow and how well it's working but then related sort of I'm going to bundle this question into it how do you train the AI on scoring of those different categories over time is that in the hands of the end user is that IT is that the system um let there's a second question of that question but we'll get with that later because I think those those two are bundled of sort of like how do you use it and how do you make sure it's useful yeah um on how you interact with it so the logic that I was showing you like in the AIP logic configuration is where you're defining your logic and you kind of save it as a function um and users can interact with it in different ways in the platform um so what I was showing is in the user interface you could click a button something runs and you get an output um but you can also continuously develop it there you can have it um run and what we call automate so it's automatically giving you these suggestions so um I guess it's it's hard to answer because there's many ways you can interact with AI um in the platform for us how we know if what you're getting is good or not um one of the fields that we had is like who generated the recommendation um so was this coming from AIP logic or was this human recommended and we also capture if it's rejected or accepted um and I and again we add the ability for people to add comments as to why some things been approved or rejected um I think over time you'll get to see how often things are approved or not um like I once it's in production and more people are using I think we can give a better answer there but we have the capacity to check it and like uh mark mentioned earlier we wouldn't expect anyone to use it without proper testing and validation um so it's kind of like a multifacet problem um sorry what was the second question um on on how can you train that the sort of scoring model and who in whose hands is that scoring or that that tuning of the agent or recommendations for the agent yeah um so how we designed the scoring out of box was one figuring out what what metrics we wanted to assess how we're doing or how we're performing on um these were like things like frequency safety maintenance history compliance um so I think like the first step is figuring out what you actually want to score against um in this case we're using logic so we gave it some parameters think things to look at when making the score but you could also replace this with deterministic logic so with like uh impact for example like if it's you're like making or having a customer experience ten-ounce outages a quarter and that's an acceptable bar um you can configure it to be that way as well so um how we did it is one to find what it is you actually want to score to what are the parameters that like make up that score like what's your scaling system um and then three figuring out how to implement it great um we'll we'll probably take two more questions or so and then wrap um we'll we'll follow up with folks whose questions we we don't get to um as well let me just scroll through here to make sure um so there's a second question on sort of workflow and and it's related to that first one on data um michelle this one also for you uh let me go back so you know you you have events that are unplanned could you add items in the past to get the data of prior impacts on the schedule um I think that's also related to you know could can the module support plan versions that could be compared period over period yes uh yes to both those questions um so for example if you keep your outages in SAP and we have an SAP integration um you'll get out of the all of the outages out of the box and it's when you configure your ontology the data kind of flows through automatically so you would see all of the outages that you've had in your system appear kind of on the schedule um all of the tooling that you saw is like generic to the type of thing that you're looking at so all of the analysis you get is the same per outage so you would be able to see the impacts of previous outages the customers the contracts that were impacted the staff who are assigned to it if you set up that relationship um uh as well um and you also can set up a way to look at plans of schedules or how things have changed over time so if you're capturing uh things that have happened and where things have planned you can do look back to prior versions um depending on how you're reading in and integrating and saving the data so i'm definitely possible to include an ability to kind of compare schedules over time and michelle on that question around sort of comparing or or multiple versions or schedules uh a question about you know if you have if you have multiple users as requesters who are all entering their own outages with then a smaller set of coordinators who are then taking those like how can you see all of those changes that are being made and control the overall plan and the version conflicts between them yeah for sure um how i've seen this down in the past is um i think when i was showing the schedule you might have noticed you just reviewed changes and hit submit and then it automatically updates in the schedule um if you have multiple planners working on the same schedule you can set it up in a way where um the stages get like um the changes almost get staged as proposals or changes the schedule um and then you can maybe have like a team meeting or a single planner look at all of the proposals um to decide kind of like what what changes make the most sense but um you don't have to have it save automatically so people are overriding the schedule if they they shouldn't have the ability to do so um so that's kind of how i've seen it done in practice is make it more of like a proposal workflow um versus like everyone saves their own changes to the master schedule great thanks um and then last question mark uh i'll throw it to you um the the specifics here is you know is is pound here a platform to assist data scientists and data engineers to deliver things to business users or is it a solution that pound here professionals configure their their product i think i'll generalize that to who uses it and how and when and what have you seen yeah i mean it's so far it's a combination i would tell you that if you have a specific solution that you want to build that's going to be standardized across your organization we'll use technologists to do that type of work right and we'll work with with folks that are data scientists or data engineers to get the data where we need it to to provide the solution then once we have that particular thing on place uh and we have the ontology in place then yes you can expose all of that to your data engineers and your data scientists that may be more integrated in the business side and less on the it side and we and we have a couple of those already that we uh that we haven't practiced today where we've got provide a better word i'll call them yeah their data scientists power users or whatever and they've got the tools in their hand through either pound here or potentially other other uh UI solutions that this thing that can can appear in the ontology and they can do some of their own analytics around that and deliver that to the business again single source of truth on the data which is where we put a tremendous amount of focus and control around so that uh we know that whatever those folks are delivering is the consistent message that we would deliver in any solution we would have um so we hadn't really hit on that that's a really important topic uh and uh one of the ones we've struggled with in the past but with locking the ontology down the way we do letting the data scientists do the work they do uh we know that everyone's coming off the single source of truth which is super important great thanks um and thanks everyone for all of the questions um so just in in close and being conscious of of time um you know if if you found this interesting um and you're in your curious of what it would like to to get started um um we'll again again we'll we'll send this out to everyone as well um but you can scan this QR code um that'll get you access to um the material from today to more about the module um that'll take you to places that you can you can um pull it down um and and and start experimenting with the platform that we can schedule more time to to follow up um and get started uh i know there's a couple of groups there watching this together um where we're currently doing boot camps um that's great you know i think we we used to do pilots mark talked about these proof of concepts uh those would be four to six to eight weeks uh that's a lot to ask for people who have full-time jobs already who are managing outages or dealing with with regulated industries uh you can think of a bootcamp as a pilot in two days uh and deploying this module and getting started and building out a first version of ontology is it is a great way to do uh uh two-day bootcamp and see what the platform is like so with that i believe that's the end um we'll we'll hold it there again we didn't get to everyone's question if we didn't get to your question we'll follow up with you um directly with the answer to to what you asked we'll send to everyone who registered this this deck and collateral this recording will be made available if you have colleagues who were unable to join today um and again i really appreciate everyone's everyone's time marks hospitalian in hosting me in the office here anything no great uh happy to participate in the event uh i thought it went great and uh appreciate all the questions it's it's always good to share information Michelle anything else nope that's it for me thank you everyone great thank you all for attending and hope to speak to you soon thanks everyone