================================================================================
METADATA
================================================================================
Title: The Future of AI and Work
URL: https://www.youtube.com/watch?v=8qXIoUxisxk
Published: 2026-01-29
View Count: 12,269
Duration: 1212 seconds
Score: 58.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: youtube

================================================================================
TRANSCRIPT
================================================================================

Actually excited to be here with you today. We are going to talk about the future of AI and the workforce and the connection between humans and artificial intelligence, which is obviously a topic of a lot of conversation over the last week and the last several months. Actually, it's chief architect at Palantir and has been on the front line of these issues for many years now and really excited to talk to you a lot about how Palantir sees the world in this way. We hear a lot from different artificial intelligence companies on this question of what is AI going to do to the workforce and really what is it going to do to the human search for purpose and meaning in the world and how do we make AI systems better, how do we team them. There's all sorts of nomenclature around this, humans in the loop, humans in the behind and lead and the front and back. And I think we started riffing on this just in private a little while ago and I thought it would be really important for you to get some of these views out into the world because I don't think that we're hearing them very often and I think you have a unique perspective. So thank you for joining us today. We've been talking a lot at Palantir about how we see the deployment of artificial intelligence enhancing humans rather than eliminating them or eroding them. And we've talked a lot about that in terms of our website called Working Intelligence where we featured some of our customers showing how they've implemented AI in a way that has actually enhanced their workers and opened them up to new opportunities and really drawn the most out of their creativity in ways that they might not have done before. But what I'm really interested in getting into today is talking about from a technical perspective, what does that look like on the ground and how do you design a software system and an implementation of artificial intelligence in an enterprise context that can actually bring the best out of humans. And how do you think about the relationship between AI and humans in that context? Yeah, I think that's a great prompt. And first and foremost, thank you for having me, Jordan. I'm excited to kind of dive into these issues with you, these topics. And I agree with you, there's a lot of interesting substance to go into. And I think authentically we're learning so much every day in the field that I think like I have to catch myself on saying whether or not something is still current or whether or not my understanding is almost day by day. So it's a very exciting time. I've been a palenter for about 13 years. And I think the rate of change, the rate of being able to make an impact in these core domains has never felt higher than it is right now. I think maybe one thing I would start by saying is like, you know, since day one at Palantir, you know, in much more humble circumstances, it was always about trying to augment and enable decision makers. In that case, it was a handful of decision makers do, you know, counterterrorism analysts and soldiers downrange a very specific set of missions. But I think that spirit has carried with us to the modern day. So now we work across 50 plus verticals from everything from, you know, making airplanes to flight operations, to electric grid controls to a lot of work across allied defense. But we still think a lot about what does it mean to actually empower the people making decisions and affect those missions. And I think what's really interesting now in the context of generative AI is, you know, what is AI maximally? Can it be a source of labor? Can it be something that spans the spectrum from augmentation to full automation? And I think as you know, and as you hinted at in your opening, it's like, we do see it pushing out the frontier of what's possible for humans to do in most of these specialized contexts. I think it's true. We can get into this about the idea that AI is going to display some labor or is going to make some things not have to be human driven. But I think we see a very, very much an expanding pie of work and impact that humans can make with these tools and with these models in different forms and functions. And that's, I think that's an important point because it sounds like what you're saying is that actually to get the most out of the AI, you actually have to have the humans involved and AI without humans involved and the kind of harnessing of AI and human expertise, you're actually getting the worst of both worlds because you're not empowering the humans and you're also not empowering the AI. Can you talk a little bit about that and how we actually put that into practice from a technical perspective? For sure. And I think a lot of it comes down to, it's interesting. When you talk with people who would consider themselves to be non-technical, who are often people who are technical in their own way, right? They are technicians, they are nurse schedulers, they are someone who's doing a job that involves some expertise. They, I think intuitively understand what I'm about to say, which is, you know, AI is the result of training over a lot of in the case of the modern generative AI models, public corpses of data out there on the internet and in other kind of large repositories. And so therefore, the knowledge it has is interesting and the reasoning capabilities are quite impressive, but it's quite generic in most circumstances as a result. And so if you want it to be useful in the context of your specific clinical care operations, it has to understand like any employee or like any member of your team, how you do your decision making processes, why you choose to use one set of information over another, and essentially how you flow through the actions of the day. And so I think it intuitively makes sense. Again, that you need to have some system or some harness. If you're going to level up AI, we actually had a Japanese customer that used this term, deshi, which means intern. It's like an intern can be very capable, but they know nothing about your context when they first join. So the question is, how do you embed them into your context and give them more and more permission or allowable scope of work incrementally, um, and do so securely? Yeah. And so I think there's a lot of technical dimensions to that. And when you have a really good intern, they up your game also, right? As a brainstorming partner and somebody who's giving you creative and fresh ideas. And I assume that's where AI could go if it's kind of the maximum partner that you're sketching out right here. Exactly. And I think like just to build a little bit on what I was saying before, it's like, if we think about that generic but impressive reasoning core that AI has, the question is, how do you, how do you have that connect with the world of decision making you exist in? And there's kind of classical dimensions of like, how do you make decisions at all? So well, we think about kind of like the stoichiometry of a decision making process. There's like the information you use when thinking about how to act. There's the actual set of possibilities that you examine on what you might do. Then there's the actual action that you pull, right? Whether it's a fine grain orchestration or just flipping a bit of some sort. So there's data, there's some logic or reasoning, and there's action as well. And humans are doing this almost automatically in a lot of context, sometimes more deliberately. And so you need to literally connect the AI systems or the AI models or the agents, however you're encapsulating them with a common model of decision making, the same data, the same logic, the same action that humans are using today. And then as the humans are making implicit choices, as they're using tribal knowledge, not encoded anywhere, you have to be able to learn from that and translate that to the AI. But it's very much a process of running alongside the human operators to get to that point. And I assume that's not what happens in most AI deployments because you can't really do that through a typical chatbot or sort of chat interface. Is that correct? I think so. I think like, you know, I'm always a fan of trying to steal man things wherever I can. But I think the limitations of a traditional chatbot paradigm or something where it's essentially acting like a genie, right? It's like an I'm feeling lucky button when you asked one of these agents a question. Is that it's not really true. It's not embedded in the process with you and able to learn inductively over time along with as decisions are made, as consequences are reaped and so on and so forth, right? Like it's kind of everything is sort of like this ephemeral interaction, right? I ask it, it gives me an answer that's maybe good or bad, kind of bounce off of it, maybe I use it less, but I have a lot of work to do. As opposed to, can I be surgical about us both operating on a common plane of decision making again? We call this the ontology system, right? Where it's like, I've actually modeled the suppliers, the interactions, the inbound emails, the orchestrations or ERP systems. And there's one specific step maybe to start where the AI can help me. And that's what the triage step of understanding how to sort through all these inbounds and figure out what to work on first. And then I can slowly, like a smooth turning of the knob say, well, maybe it can then help me with the next step, which is being able to choose from the amount of options that we've done in the past, you know, prior resolutions, prior strategies for dealing with these issues. And so it's augmenting me to begin with before I try to automate anything fully. And what we tend to see is when you do it kind of in this path dependent way, it frees up the human to do more interesting and more ambitious work. And it allows the AI to function like a higher order toolset that's helping them do things that were often very manually cumbersome to do. Yeah, it sounds like what you're describing here is almost like a move from the back end to the front end that you're liberating people. When we think about the computer revolution, we think about Steve Jobs bicycle from the mind. But what actually ended up happening over the course of the next 30 years was people just got inundated with data and dreams and dreams of spreadsheets and emails. And it became almost too much for the human mind to handle on its own because you're spending hours and hours and hours in the back office dealing with all of the administrative burden that has cropped up around the worker in almost any industry, right? At hospitals, we know quite well how much doctors and nurses have to cope with paperwork in manufacturing plants. And so what this is doing in a sense is liberating them so that they can focus on higher order human creativity. I think that's exactly right. And I think, you know, whether it's in network planning or it's in a wildfire response or it's in military operations or it's in nurse scheduling, there's kind of two common bottlenecks. We see a starting points for how do you introduce AI into these contexts? The first is what I call as a context bottleneck. So as a human operator who's maybe dealing with inbound support issues in a supply chain, like you said, there's so much data now that could pertain to what's going wrong that I can't really read through all of it myself, right? There's manuals that pertain to the machines. There's prior issues and support resolution strategies. There's up there's information about that supplier or that customer in particular. There's interconnected information across our logistics network. So you have some understanding as a human operator, typically how to navigate some subset of information, but it's typically lossy. You just accept that you can't make use of all of it. So the context bottleneck, I think what's exciting is AI can help you oftentimes, again, when embedded and anchored properly, bring more context, bring the right context to you at the right points in the process. The second bottleneck then is a capacity bottleneck. So sometimes I just can't work through all the issues. I have to work through on a daily basis, right? So it's like I need to make this amount of schedules by the end of day and deal with this amount of outstanding issues before we close shop at the end of the day. And I just can't work through this many because to go through the workflow manually for every single one, it just, you know, I run out of time where I have competing priorities. So can AI actually help me deal with more things and bring more, I think the bicycle for the mind thing, what comes to mind is do you want to give people more leverage to deal with their problems, right? I think it's always like the Iron Manor Iron Woman suit analogy, right? But it's so exciting. Yeah. So I think, relatedly, there's a fear that AI lowers the skill floor and commoditizes expertise because if I'm putting what's in my brain into the system, does that make me expendable? But I think you can easily make the case that augmentation does the opposite that it raises the skill ceiling. And if the past 30 years were a race to the lowest common denominator in terms of the global labor market, you could see the opposite happening with AI where the workers with the most expertise actually get prized the most. And we're not talking necessarily about expertise as a white collar workers, but as you were saying, it's really the people who know exactly how many times to turn the wrench on a different, on a system. And they might be one of three people in the world who know how to do that. So I'm wondering if you could share your thoughts a little bit about that. And like, are we about to flip the paradigm on the lowest common denominator is AI capable of doing that if it's deployed in the right way? No, I think it's a really good point. And it's interesting because like the kind of fears, and I don't want to say like this that pejoratively, right? It's like the the concerns about how technology displaces labor go back as you know to the industrial revolution even before that. But even in the information processing paradigms, you know, in the original cybernetics kind of distillations post-World War II, there was kind of the axiom of like from like whether it was Norbert Winer or Vannevar Bush, anything that can be encoded can eventually probably be automated. Like if the job is just in bit space, it's just an information space. Well, they're like, yeah, logically, it's going to be able to probably be automated in some form by a sophisticated enough machine or whatever term they use at the time, right? Some sort of touring or von Neumann compliant algorithm. I think that is what we're seeing kind of at the low end, right? Where you're saying, okay, like in it's funny, ironically everyone's had learned a code. And now it's like, it turns out those sort of symbolic representations are the first things on the chopping block for lower end sophistication of that work. But like you said, like there's so much work that exists in the context of the world. And there's so much work that is not encoded so explicitly in that way. And I think any enterprise that exists, okay, it's like, and so I think when people talk about that kind of heat death of labor, right? Like it's sort of like everything's going to just eventually go to a fine mist. It's like I think it assumes a vacuum where there's no competitive pressures and there's no frontier that humans are working against. It's like if you ask somebody in the enterprise, like is this person's job? Is her job actually just to sift through these mundane issues every day? They'd be like obviously not capable of way more than that, but she has to. And so I feel like what you're really seeing is the amplification of human potential to be able to deal with higher order things as you start to eat away at that bottom set of things that are often not always drudgery, but sometimes, you know, things that don't require that person's expertise. I think the somewhat daunting thing that invites, and this is where I think we see a bifurcation in organizations are those see that as an exciting opportunity to go back to go to their workforce and work with their people and say this actually opens up the door to like reinvent how you do shipbuilding or reinvent how you do construction to transformers or is it like, oh geez, now I have to think about these things and I don't want to have to reimagine people's roles. To me, that's a sure that's a kind of a surefire sign that you're going to be at a competitive disadvantage. Yeah. What's an example from from one of our customers that you can talk about where you've seen this in action where we've taken working with our customers, somebody has gone from having to deal with some of these things on a day-to-day basis to being liberated and really unleashed in terms of the creativity and thinking about higher order issues. Yeah, I think that, you know, all the clinical examples are really compelling. I think I referenced them earlier. So one that comes to mind is the work with PG&E that they shared a couple AIP cons ago where they have a really interesting mandate, right, which is they have to provide power at the best rates to Northern California, but then they also have to deal with wildfire issues and a lot of safety concerns. And so when you're trying to deal with when to de-energize parts of the grid, which is to say they call these PSPS events, so public safety power shutoffs because there's sparks or risk factors or even precursors to potential risk factors where you want to proactively, you know, maybe shut off part of the grid or deal with basically a load spike and be able to reduce the risk profile over time. Now, you don't want to do that incessantly because people need access to the grid and you don't want to cause unnecessary power shutoffs. And if you watch the people who do this sort of work, like the people who work in electric ops is a site to behold, like they're just really in, it's almost like they're an extension of the network, right? It's like their ability to understand the grid, the circumstances, the factors that affect load, the factors that affect customers. It's almost like you're like dealing with some sort of like a mystical whisper of hardware and software systems. And seeing them able to get much more sophisticated through use of AIP and foundry where they can now bring a lot more information to bear against those de-energized proposals, de-energization proposals, and how they might choose to like pursue them or not, or how they might choose to more intelligently cluster those activities. Has been amazing to see. And, you know, we're of course just one part in their overall process, but they've been able to significantly reduce wildfire and kind of like precursor occurrences in the past several years off the back of this work. And a lot of that was just in liberating the genius of these workers. Now, where do you see when you talk about, I think that's a great example of liberating the genius of the workers. I think we at Palantir really believe in that human frontier that we shouldn't have a failure of imagination. And that can go both ways, but in this case, the positive direction that when you when you there may be some job elimination or some role elimination, but that doesn't mean that we're going to eliminate our workers, at least the companies that are smart won't then therefore just eliminate workers. They'll figure out how to use them in smarter ways and actually probably in the ways that they should have been used in the first place, how they not had to deal with many of the things that they had to deal with. What does that look like to you as far as the frontiers of human creativity in a world where AI can help shoulder the load? Is it more of the PG&E examples of there are other things that you've thought about in your dreams? Yeah, this would be really cool if I had time or people who we work with had time to think about these things. What would they be doing? Yeah, I think organizationally it's a good point. And I think, you know, it could be the case that in some industries you have, quote, unquote, like within the industry itself, net displacement of work and of labor. But I think what that opens up and what I would assume will be a positive some counterweight that will actually outgrow it over time is like the ability for entrepreneurs and people who are building net new companies to be able to do so way more productively with smaller groups of people. But you get more of these companies because you don't need masses of people doing undifferentiated work. And so it's like the barrier to entry for being able to build a next generation power provider or a next generation logistics company. It was always so high for a lot of legitimate reasons when it comes to, you know, there's a complexity of the work. But a lot of it was just like there's a lot of drudgery you have to do across all the core functions to even get to the starting line. And so I think there's a lot of opportunity for like a rejuvenation of industry and almost like a creative destruction to occur where there are these incumbents that might be shying away from this through smaller, more Spartan forces of people. And I think it might actually end up, you know, the term democratizes so overused, democratizing some of these industries that have been very resistant to change at an organizational kind of competitive level for a long time. What's maybe to wrap up? Yeah. What's one thing that the public should know about where artificial intelligence is headed that they don't know from the prevailing conversation about AI, especially on this, on the relationship with humans and AI. If you could pinpoint one thing, I'm looking at the national conversation or the, or the news headlines about where AI and the workforce is headed, what's missing from that conversation? I think the thing that is missing is where the intelligence lies. So I think there's a lot of intelligence in the models themselves, but most of the intelligence is in the working functions and the human beings conducting work today. The thing is that information is not typically captured. Right? Like I kind of joke like everyone's, it's very sci-fi to think about AI, it's very cybernetic, but it's almost like current human work is almost telepathic. It's like when you see people working on a production line who are really in the groove or working on a shipyard, it's like it's kind of amazing to think about how much specific structural contextual knowledge they're using all the time. And so I think the opportunity to like get the knowledge from these folks encoded, not to replace them, but to give them more leverage is really the untapped iceberg. Like there is the generic knowledge of the model itself, but I think when we think about fine-tuning, building domain specific models, like being able to have a, as Sean says, a menagerie of models that are all specific to specific use cases, that I think flows from the lived reality of these people actually doing the work. And I think that's an untapped asset in large parts. So like everyone's like, well, and I'm waiting, I think there's kind of this, this feeling of like I'm waiting for on high to give me more knowledge leverage to do my work. And it's like actually if you look around you, that's where most of it is probably trapped. Yeah. Well, here's to finding out where those places are and unlocking them. So actually, thank you so much for joining us and I really appreciate your perspective. Thank you, Jordan.