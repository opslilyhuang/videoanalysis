================================================================================
METADATA
================================================================================
Title: Foundry Tech Playlist | Data Integration Series [Part 4]
URL: https://www.youtube.com/watch?v=wuaQkWHJqb0
Published: 2022-04-28
View Count: 8,335
Duration: 290 seconds
Score: 55.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 

================================================================================
TRANSCRIPT
================================================================================

Foundry's Data Integration Capabilities span across data connection and engineering to create a unified data asset, the ontology, which you've heard of several times in this video. You can use the ontology to build key work closing insights on top of it. What we've seen in this series so far is some of the core functionality that Foundry has to offer, but it's certainly not the exhaustive set. Foundry also provides an easy interface to configure other things that you might need along the way. We've seen Foundry's Data Lineage tool several times in this video series. While it serves as a compass to help us navigate our pipelines and a graphical interface, it does a lot more than that. Namely, it answers questions about proven and static lengths. How a data set came to be at the state that it's in. It shows the relationship between data sets and their ancestors which were used to compute them. On the fly, Data Lineage shows a preview of the data set. It's build history so you can get a sense of how fresh the data is. We can also zoom in on the exact code that transforms the data sets as we saw earlier. Where other similar tools end, Data Lineage can also help you track downstream applications of your data assets so you can get a bird's eye view of where your data is being used. These views are totally dynamic as Foundry natively keeps a record of all these relations. In addition to building our pipelines, we often need to orchestrate our pipeline builds. Foundry lets us configure schedules on our pipelines to ensure that they're running at the right cadence. These schedules can be configured using either time or event-based conditions. For instance, we see here that this data set is configured to run once an hour at nine minutes past the hour. Now, we've set up the schedules but what happens if something goes wrong with the build? To really make sure that our pipeline is robust, we need to add some monitoring capabilities to ensure where or where if anything goes wrong. Foundry lets us configure data health checks that run every time a data set builds. With data health checks, we can configure alerts for build failures, build duration, data quality, and many more things. Data Lineage can also reveal interesting metadata at a glance about the data sets in our view. We can color code data sets by things like data freshness, project, type of transform, and many more dimensions. This becomes extremely useful when we're trying to understand some fundamental properties about our pipelines. Perhaps one of the most interesting ones is permissions. If I color code data sets based on my access level to them, you can see from the legend that the blue data sets are all the ones I have access to. This is again a dynamic view, which reflects the dynamic enforcement of security throughout the platform. Security is baked right into every resource in Foundry as a mutable metadata. What we see here is that Jason doesn't have access to most of this data. This is a consequence of the fact that permissions flow with data in Foundry. Meaning that when I lock down the source data with certain policies, those policies propagate all the way down to the objects and also into applications and any third party access. We can implement roll-based security policies here, which sync with an organization's existing Active Directory. You can also layer on classification-based and purpose-based access controls well. With a plethora of scaffolding around the core data integration tooling, Foundry helps you secure the quality and integrity of your data pipelines. To recap, we've explored the Foundry Data Integration journey and have seen how we can go from connecting our various data source systems all the way to creating our ontological objects. We've explored the Foundry Data Integration journey and have seen how we can go from connecting our various data source systems all the way to creating our ontological objects. We've taken our raw data sets, cleaned, transformed and combined them to build semantic assets that represent the digital twin of our organization. Along the way, we've leveraged Foundry's build orchestration system to ensure that the status updating in a regular kidds, set up health checks to validate data quality, and applied access policies that will ensure that only the relevant people have access to the state. Now, with a running data pipeline, backing our ontology, we can build any number of new applications using the same data foundation with minimal effort. Foundry abstracts the complexity of managing your data infrastructure to a couple of clicks and brings an unrivaled solution to do the most with the least amount of resources. Congratulations! You've made it to the end of the video series. Thank you.