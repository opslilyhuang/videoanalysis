================================================================================
METADATA
================================================================================
Title: Building Resilience in Times of Crisis | Palantir at Enlit Europe
URL: https://www.youtube.com/watch?v=Fy6FkMYaZ28
Published: 2023-02-06
View Count: 4,714
Duration: 957 seconds
Score: 55.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

I'm Emily Wynn, head of industrialist at Palantir Technologies and it's a privilege to be here with you today and to have the opportunity to exchange ideas with so many industry leaders here at NLIT. I started at Palantir coming up on 10 years ago. The joke is my hair was all black when I first started. That has since changed and during this time I've gotten the opportunity to work with many clients across the energy sector, everything from oil and gas producers to midstream refineries, to utilities focused on transmission and distribution. There are probably a few things that you might be wondering right now, maybe first and foremost, who is Palantir, what do they do, why have I never heard of them, and probably most importantly, why should I care what they're doing? These are all fair questions. We've certainly been quieter than a lot of software companies. Part of the reason behind this is that we've been very heads down and focused on working on the toughest problems that our customers and partners face. In working with them to tackle the hardest problems across industries, this is everything from cancer research to supply chain disruption management to the energy transition. Now, in solving these hard challenges with our partners, a few key patterns have emerged and I'd like to share with you those today. The first pattern that we see is that, first of all, while technology is advancing broadly at an astonishing pace, many of our most important institutions, especially in industrials and utilities, feel left behind. Enterprise software falls short of its promise of transformation because it is either too narrow or too rigid to address the most critical problems. And more often than not, the operating models of these enterprise software companies don't incentivize anything different. And the second point related to this, which should have us concerned, is that effective technology is paramount to the future competitiveness and security of the list. Technology should take accountability for more of the outcome and develop technology and things that support decision makers in full rather than leaving the job half done. Said a different way, we need to innovate differently. I can talk about Palantir's approach to this through something we call the ontology, but first, what informs this sort of pessimistic opinion? And I say that let's start by looking at the world over the past 10 years and how this has impacted the energy sector. In the 2010s, there was sort of this geopolitical consensus that the world would get more peaceful, more stable, more predictable, more reliable. We were trending towards globalization and maybe with the exception of a few perya states, we would be more connected. Very often during this era, I heard customers talking almost singularly about planning and prediction. The problem in request was, can you give me a better forecast? If I just had a better forecast, my operations would have a long. But then in 2020, the world broke and every forecast along with it. Arguably the cracks were there all along, but the pandemic showed us just how fragile the world order really was. We saw strains on our healthcare system, and healthcare workers, massive supply chain disruptions, unprecedented travel restrictions, and a lot of questioning around the basic assumptions of trade and connectivity. Very often during this time, I even heard it in a session prior, can we just get back to normal? Can we just get back to where we once were? But in the following years and months, what we've seen is sort of a new normal. That includes the war in Ukraine, an energy crisis in Europe, inflation, rising tensions in the Pacific, and increases in extreme weather. This point's so world that is more dynamic, shifting and unpredictable. This world order favors adaptability of operations, embracing of complexity rather than hoping for simplification. There's a quote from Darwin who says, it's not the strongest of the species that survive nor the most intelligent, but the one that is most adaptive to change. The world of energy hasn't been spared by this disruptive forces. In fact, maybe they've been more impacted than anyone. There's an old adage. Your energy can either be reliable, sustainable, or affordable. Choose to. In Texas, in 2021, we saw the grid fail spectacularly, given unexpectedly cold weather, that exposed vulnerabilities in kind of the distribution system. In Europe, at the end of this summer, we saw skyrocketing prices related to over-reliance on Russian gas and attacks on energy infrastructure. Recently, it's felt more like, choose one. But to service energy needs into the future, we're going to need to change that ore to an ant. Energy needs to be reliable and sustainable and affordable and a lot more. The grid itself must do more. It must be become fully digitized and multi-directional in order to support distributed generation and become a marketplace for energy. We need to incubate tasks and scale new storage technologies that can provide stability to the grid on the path that is zero. We need to make energy generation as efficient as possible. Our most critical infrastructure should run with precision. And we need to think about energy security at a country or even a continent level, how diversified our energy sources, how fault tolerant, what's the contingency plan? These are complex challenges that require robust solutions that offer resiliency in the midst of an uncertain future. Now technology should help us adapt, but looking at what most enterprise platforms offer today, the reality is quite different. The primacy seems to be placed on standardization rather than resiliency. Traditional enterprise software asks institutions to change, to fit the software, often with three to five year roll-out plans, rather than changing the software to fit the institution. This is because traditional enterprise software benefits from standardization, making one organization as much as like as the other organizations. Or they benefit from solving very narrow problems. Consider the data lake, for example. So often I hear clients say, I did it. I did the thing that you're supposed to do. I spent the money, I spent the time. I got all my data into one place, but my business is the same. Data aggregation is such a small sliver of the journey, and it is not accountable to the transformation that it purports to support. So it can't be an end in itself. In a highly volatile world, these paradigms around enterprise software make it hard for institutions to find utility in the technology, much less wheeled it as competitive advantage. It's like they say on the west wing, more and more, we've come to expect less and less in this case from enterprise software. Is this just the nature of the beast? Is there another way? So I think this idea of doing both of changing the or to an end is integral to our founding story at Palantir. Our CEO, Alex Kopp, Harp, often reminds us of kind of this founding principle that we have, which is that we should be focused on problems that are both, quote, critically valuable to society and inherently unsolvable. Many of you probably know our founding story. We started out in the post 9-11 world, focused on the problem of counterterrorism. And we were presented with this dichotomy of, you know, privacy or security. You could have one, but not the other. But rather than accept that, we worked with the US government to develop software that could do both. This required technology to support things like purpose-based access controls, secure collaboration across agencies, smart encryption and other robust security entrances. We innovated until we could have both. Wouldn't it be better if software were accountable to the outcome and not just wrote installation? Wouldn't it be better if incentives were shared across vendors and their clients? My belief is such accountability is not just nice and theory. Oh, couldn't we all be sweet to each other? But this actually forces much needed innovation. Take on the important problems, not just the easy ones. This builds resiliency. When we started our commercial business at Palantir, you know, we had, you know, kind of the basics of open source technology and we sort of developed these linear flows. Like, you know, first you connect to a data system, then you aggregate it, you create a golden table, maybe you do some analysis, and then you create a dashboard. And you know, that solves some problems, but it's not short of solving the big problems. So your data is in one place. So what? Maybe you found an interesting insight from the analysis. You know, who uses it? How quickly does it decay? Is it actionable or is it just interesting? Many projects have died in the valley of what is interesting. You know, you have a dashboard that tells you something new. Can you ignore it or does it become part of your job? How do you learn from it? And these realizations and these challenges motivated the creation of Foundry's ontology which I would say is the key differentiator to our software platform. The ontology is an abstraction layer that integrates many sources of critical information into a common operating picture. Organizations can then use to understand what is true and from there make data driven decisions. So in kind of developing this ontology, there are a lot of core beliefs that motivated it. And I believe these should be true for really any data strategy, any data asset. But you know, kind of the first idea is that the ontology synthesizes any type of data. Structure data, unstructured data, geospatial data, high-scale sensor data. Increasingly in the energy sector, we're seeing demand for drone aerial footage or commercial satellite data. The ontology should be agnostic to where the data comes from or what format it is and it should be able to handle that and synthesize it into kind of a common frame. The second idea is that the ontology should organize the data into human centric objects. So in the utilities world, you can think about a transformer, a substation, a field crew, a customer. And you know, this should make the data accessible to non-technical users. You should need to know how to code or write SQL. You're curious to use the data effectively and your kind of daily decision making. And you know, the kind of third idea is that the ontology should fuel collaboration across groups. To cooperate effectively, you need a shared view of the truth. Not everyone needs to see everything and with smart access controls, they don't have to. But there shouldn't be multiple versions of, say, a customer kind of drifting between billing and maintenance. There should be a common view that services multiple workflows. And it's not just about the data or the objects in the ontology. Data, models, and actions are treated as co-equal primitives. Data's and models are only valuable if they lead to actions. Those taken should be captured to inform data and models into the future. These ingredients are connected, but modular to make it easy for them to stay up to date. All three taken together drive transformation. And in prioritizing actions, this also means that the ontology does not live with its own wild garden. It must read from and write to other source systems around the organization. Whether that's a new ERP system, a GIS system, a modeling suite, or even firmware on the grid itself. Actions don't happen in a vacuum. Already across the world, foundry's ontology is helping energy companies adapt their operations. For example, it's used to drive emergency wildfire response at California utilities like PG&E. CEO Patty Pope said that if they had been using the foundry ontology in years before, about 96% of structures that were destroyed by wildfires could have been saved. At Trafigura, they're using the ontology to underpin the carbon data consortium to help complex supply chains model out their scope three emissions. Currently in their ontology, they have over 7 million pathways modeled, and that number is only going to grow. BP has leveraged the ontology to shift their whole strategy from producing as many barrels as possible to balancing that with their net zero ambitions and to do so profitably. Sanidics, who's here today, uses the ontology to optimize their operations and produce solar power at scale. Hyundai oil bank uses the ontology in key decisions like crude oil selection and in everyday tasks to operate their refinery at days on even given changing crude inputs. All of these outcomes have been powered by a combination of data models and actions, working in a connected frame. Taking together, we aim to make the kind of western energy more resilient and adaptive to the changes of the future. Of course, the outcomes described don't happen simply because the technology exists. Transformation requires both technical and human components. This comes from the top. Executives and leaders within the company should assert strategies that allow their companies to not only adapt to the new world order, but emerge stronger in it. They should be emboldened to expect more. This also comes from the bottom. Employees at every level should be incentivized and enabled to work in new ways to meet the needs of the day. Employees should be emboldened to do more. And the right technology should enable both top and bottom. In fact, it should connect them so that strategy and operations stay in lockstep. In the 1930s, there was an economist, John Maynard Keynes, that hypothesized that in the future, due to increases in technology, we'd be working 15 hours a week. That obviously didn't happen. Technology has not automated away our efforts. But it has allowed us to increase the ambition to become a society of and not or. And as we face the kind of very daunting challenges in the energy landscape ahead of us, we should expect more out of technology to propel us into the future where energy is reliable and renewable and affordable and cyber secure and a lot more. Thank you so much. Thank you. Thank you. Just listening to you there, my goodness, so much should take on board. Data. Data is only as good as the person who knows what bit of data to look at. Right? I just wonder, when industries start to look at the data that they have, how many times do they realize things which they'd always thought were true and they'd always relied on, absolutely, not the case at all. And actually, the rethinking that is needed to sort of like to reprogram the whole way of thinking. Absolutely. And I think that kind of right technology should surface that truth. But I think one of the things that we kind of talk about is what we call digital transformation backwards. Exactly as you say, it can be very daunting to say, wow, I have so much data, I'm not sure about its quality, how do I even begin, how do I, like, am I not ready for digital transformation? Do I need to do, so go away for five years and create a program to get my data in order? And I think that our kind of philosophy around this is really progress over perfection. Choose a problem that matters. How do I schedule my work orders and how do I manage my procurement amid supply chain disruptions? And if you focus on that and you focus the data that you need to support that problem, you can then put data in action and that fuels data quality and gets you to an outcome a lot faster. I'd love to ask you what you think of the skills shortage in people who actually have the ability to deal with data like this, but I have a feeling that might be another 15 minutes or but it is a challenge isn't it? Yeah, definitely, but I think that good technology should lower the barrier to entry. At Airbus, for example, we have 30,000 users, many of them are people, blue collar workers working on the assembly line and they can use data to inform their operations, maybe they're not authoring the code, but I think that there is an aspect where if you have one programmer, they can empower hundreds. And so by levering up the people that can read the code, you can get degree at outcomes at scale. And it's also a case of working with the right people, having the right people in the rooms when the programs are written, they actually seem to make sense and they do what is needed rather than the top down approach to looking at the data. Emily, it's been really fascinating listening to you. Thank you so much for joining us on the Inspire Space. Thank you.