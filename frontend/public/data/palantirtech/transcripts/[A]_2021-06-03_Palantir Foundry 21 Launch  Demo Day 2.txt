================================================================================
METADATA
================================================================================
Title: Palantir Foundry 21 Launch | Demo Day
URL: https://www.youtube.com/watch?v=h4R1cOlJJ7o
Published: 2021-06-03
View Count: 131,047
Duration: 1869 seconds
Score: 79.0/100
Rank: A (Active - 高参考价值)
Transcript: Available
Category: 

================================================================================
TRANSCRIPT
================================================================================

Today, we're excited to share some highlights of our product as part of our Foundry 21 launch. We will take you through a modular and interoperable suite of products that enable organizations to transform their business by breaking out of inflexible software and disconnected functions. First, we'll present the Foundry Ontology and Simulation Engine. These technologies enable our customers to build and operate connected companies that can make the best decisions possible based on a deep understanding of their business, built on a foundation of data and models. Second, we'll share how our software radically accelerates critical business outcomes for our customers. With software-defined data integration and our use case catalog, you can achieve what used to take months or years now in a matter of hours. Let's start with a simple question. What is Foundry? Foundry is a first-class data integration and management platform, a comprehensive suite of analytical tools, and an operational platform of applications for business users. But at its core, we believe Foundry is the central decision support infrastructure for any organization. We built a software framework that translates data and models into knowledge that human operators can use to make better decisions. The Foundry Ontology and Simulation Engine we are demoing today represent this connective tissue between assets in the digital world and actual decisions in the real world. Let's look at what this means for a large supply chain. As we built Foundry, we quickly learned that the amount of data in any organization is constantly increasing, creating a massive amount of entropy. For example, in a single supply chain project, like the one you see in front of you, you might need to ingest thousands of tables from a single ERP system alone. And in data from other systems like operations, customer demand, and finance, and you quickly realize that it's extremely difficult to understand or discover anything from the data, even with all of it in one place. This is why companies spend years on data projects without any clear business outcomes. We determined pretty quickly that we needed to take a different approach. Palantir Foundry's Ontology and Simulation Engine Technology is our unique solution to this challenge. It preserves granular data governance and security while mapping all data into a shared, easily understood framework specific to the organization. This Ontology, the representation, or the digital twin of an organization, provides a common interface for all downstream workflows, from search and analysis to operational applications like supply chain optimization. It is also a two-way interface between an organization's digital assets and its real world operations, allowing teams to feed their unique insights back into a common understanding of the business. Let's take a manufacturing plant as a first example. To create a 360 degree view of the plant, we are joining massive amounts of data, like sensor data from plant operations, or logistics data from distribution centers, or financial data from ERP systems to create the plant object. As we continue to integrate data to support more and more use cases, our Ontology continues to grow. We also link the plant to key entities like distribution centers, customers, and raw materials, which are backed by even more data sources. The result of this data integration and mapping work is immediate transparency into the business objects that plant for business users across the organization. As a supply chain manager, a logistics officer, or a plant operations manager, I can see all the data that has been integrated to develop that plant object. And for any single plant, I can quickly see the most relevant KPIs to understand customers and distribution centers by city, as well as any demand alerts, and the demand in production over time. Importantly, this Ontology's dynamic and it changes over time, expanding as digital transformation starts to include more parts of an organization, and changing as the organizations themselves evolve. Traditional ERP systems and inflexible data models cannot handle these inevitable changes. This Ontology goes beyond integrated 360 degree views. It's the foundation for all decision making through search, analysis, reporting, and applications. This approach is transformative for several reasons. Instead of reinventing data foundations for every new project, you now have a compounding framework for new data to automatically flow into business applications. This radically decreases the time to build new workflows and provides a built-in shared language for collaboration across functions. What's most exciting is that this framework is bi-directional. All user insights and decisions are recorded in the Ontology where they become immediately available as data for others to build on. This enables unparalleled cross-functional collaboration. For example, imagine a supply chain analyst discovers excess inventory of a particular raw material that will expire in a few months. They can flag this as an opportunity, notify a customer account manager, and from their identified potential sales opportunities for those finished goods. Let's dive into how an operational application can be created using the Ontology. This is the supply chain control tower. A supply chain analyst uses this app to get an overview of their network and high-level KPIs and then drill down into specific areas of concern. The data shown here is coming from disparate global sources that previously required users to use several pieces of disconnected software. The map here shows customers, distribution centers, and plants. Let's quickly jump into edit mode to show how the Ontology makes this type of complex application easy to build and maintain with no code. So now let's say I want to quickly see a more detailed view of the customer. It's not hard to do. First, I can quickly add all the information I have about customers. From the map, I want to add a widget to the left to display properties for all customers. We can search for the customer object from the Ontology and add all the properties. Next, I can add information in an additional widget below about link distribution centers. Instead of a property, we're going to add an object list. And this requires all of that mapping between objects in the Ontology we've already created. So in under a minute, I've added information to this view from dozens of data sources to enrich my decision-making ability. Importantly, these applications lead directly to real actions and form complex, multi-step cross-functional business processes. For example, when a supply chain analyst identifies a demand gap, access inventory, or other issues, they can immediately take corrective action, such as partially fulfilling an order or reallocating some of that stock. From there, a colleague in the distribution center can immediately see this new information and act on it. On the surface, this looks relatively simple. But under the hood, actions are a powerful building block. Every action represents a decision made by a user and is written back into the shared ontology. For example, a fulfill order action will subtract items from an inventory object, add those items to the order and change the order status from open to fill. Actions can also have complex validations and security conditions, making them a powerful building block for multi-step business processes. This doesn't even require every user to be in-foundry. Actions taken in-foundry applications can write directly back to legacy systems, they can interact with business systems like email, or even talk to machine control systems, allowing applications to seamlessly integrate into existing operations. This same layer powers not only operational applications, but also advanced search capabilities and powerful analytical in-reporting tools. So far, we focused a lot on data and how data is mapped into the ontology to generate a dynamic model of the organization that powers decision-making downstream. In order to make even better decisions, your team needs more than just data. Oftentimes, operators rely on models to help them understand the potential impacts of decisions before they make them. These models can be as complex as deep learning and artificial intelligence or as simple as logic like adherence to standards often used by executives. Once again, Foundry's ontology is the connective tissue. By mapping models to that ontology, we create a system-wide simulation engine that powers what if analyses that were previously impossible. Users at every level of the organization, from strategic to operational, can understand the potential outcomes and side effects of a decision before they execute on that decision. What this creates is an extremely powerful infrastructure that enables organizations to treat their operations like code. Changes can be staged and tested before they are applied. For example, in our supply chain control tower, production and pricing models leverage data from raw materials and plant capacity. It puts out production volume and customer demand estimates based on price changes. This type of model is often used by a supply chain manager to decide how much of a given refined product to make from a bath of raw materials. We can then chain a model like this with a seasonal demand model to dynamically optimize the product catalog and increase revenue. It is notoriously difficult to understand cause and effect in a supply chain. When automation fails, due to disruptions or simply because status quo has changed, companies have a very difficult time adapting. As a result, delayed orders or lost opportunities like excess inventory are commonplace. In Foundry, all models, regardless of the environment they are built in, are managed in a unified framework. For example, here we are looking at a library of all this organization's models. They are closely coupled with their ultimate business objective, like maximizing production or minimizing cost with COGS models or balancing the inflow and outflow of inventory from a distribution center. And we can identify if they are being used in production. In the catalog, I can quickly scroll down to find seasonal demand models and production models among others. I can see how many deployments are currently active, the overall model health and more. More importantly, all model inputs and outputs are mapped and bound to their representation in the real world. For example, I can hover over the customer demand model and see that the objects associated with the inputs are raw material order and material and the objects associated with the outputs are raw material order, plant and material. By clicking this model, I can not only see the business context around the project in the form of a prediction goal that you see at the top, but also how the models inputs and outputs are mapped to the real world. Here we can see the specific properties for the inputs are cost and price and the outputs are demand, capacity and inventory. I can monitor model performance, manage changes to this model over time, and manage how this model is deployed into the application layer. The most valuable aspect of this product is not managing individual models, but instead enabling the models to relate to each other through a simulation engine powered again by the ontology. So let's take a quick look at the second model. This model contains the production recipes for converting all raw materials into finished goods. What I can see pretty quickly is that one of these model inputs, material inventory, matches the output of my previous model. That means that these models can be chained together. To see chained modeling in more detail, we can go to our simulation interface, vertex. With the seasonal demand model and the production model, we can quickly traverse a complex value chain and ask questions like, if a supplier delivers only 50% of raw material, what is the impact on my on-time delivery of finished goods, which of my customers are most impacted? Because the models are chained together through real-world mapping, I can easily understand the complexities of my entire supply chain from upstream suppliers to downstream customers and everything in between, including the plants and the distribution center nodes. As a result, everyone can understand and anticipate the side effects of their decisions, allowing for unprecedented collaboration and universally optimal decision making. By moving the slider, we can simulate the interactions of all of the models and the impact on the supply chain into the future. We can see some of the nodes turn red, the plants and distribution centers you see on the map, alerting us to potential problems in our supply chain, such as low inventory or an increase on unexpected demand or anything else. Here we're looking at the detailed system view, but this simulation engine can also be deployed into any application to inform decisions at every level of the organization. So let's quickly go back to our supply chain control tower. We enrich the alert response workflow, so users can run simulations of potential remediation action. In this, we have an unexpected excess of raw materials. Once I look at the overview, I can click into the planning response tab. So I can see the current raw material excess inventory, the expected demand, and the percent of production capacity. From there, I can evaluate potential actions. Other applications like product planning and pricing can easily be built on top of the same simulation layer, ensuring consistent assumptions and enabling collaboration across functions. The connective tissue of the platform allows efficient iteration and decision making across any layer of an organization, from the COO to the supply chain manager, all the way to the logistics analyst creating the simulations. So far, we've really focused on how the ontology and simulation engine provides an unprecedented infrastructure for decision making. To close this demo, we want to talk about how we are scaling this technology and making it easier for customers to leverage it through software-defined data integration and our use case catalog, making it easier for customers to leverage their data, the ontology, and the simulation engine. First, let's understand where the data exists with the customer and how we can quickly connect to those data sources. Palantir Foundry provides point and click connection, integration, and transformation of data. For legacy ERP systems, the product goes even further, taking raw data, joining it, and deriving new features that can be leveraged in downstream workflows. Data projects that previously took years are done in hours. So how do we accelerate the time to value for our customers through software-defined data integration? It unlocks business value in unprecedented time, not seen in other software. Instead of spending months and years parsing complex backend systems, our SDDI technology automatically connects the business readable format with the backend table names, and infers the relationships between data tables, including any user defined tables. Our SDDI technology also leverages the online shopping experience where users can add the necessary data to the cart, which can then be synced. When users are ready, they can select sync, which automatically creates the ontology from the data source through the transformation layer, all the way to those objects that we saw previously, the plant and the distribution center and the customer. At the beginning of this talk, I mentioned that Foundry now ships with a catalog of comprehensive out-of-the-box products that accelerate its time to value. We've created these using our 15 years of experience across industries and sectors, maximizing their universal utility. We achieve this automation by solving the most difficult pieces first, like complex data integrations, developing the infrastructure for chaining simulations, and developing the connective tissue through an ontology. Every client's challenges manifest themselves differently. Organizations that may look the same, banks or energy companies or transportation companies, can actually have significant divergence across use cases. We maintain our customers' uniqueness by building the framework to automate the complexity of the data integration in SETO, to allow for maximum creativity and flexibility in the solution and the decision space. We don't simplify the solution so that it will scale. We automate the complexity so our solutions can accelerate. This was exceptionally relevant in 2020 during COVID. Our customers across both government and commercial needed help now, which required the ability to build applications faster than previously seen in software technologies. I'll show you how archetypes the use case catalog allows clients to traverse the entire Foundry platform with no code to achieve specific outcomes and deliver business-facing workflows in hours. We can automatically build the supply chain control tower I showed you using the use case library in our installation wizard. So we can see some of the use cases on the right that have been valuable so far and one in particular focused on supply chain. Once we deploy this use case, we can easily navigate through the installation wizard. We can first see the auto-generated object types for the specific workflows we want to deploy and ties directly to the software to find data integration we mentioned at the very beginning. We can see the demand forecast to be deployed as a function, along with any other model or forecast. We can set the specific actions we want users to take. So the cancel and order or fulfill an order, partially fulfill an order in our example. And lastly, we can deploy various workflows based on these inputs. So in our example, like the supply chain control tower, in just a few clicks, I can deploy the framework that we use to create the supply chain control tower. So again, we haven't simplified the solution so it will scale. We've automated the complexity so our solutions can accelerate while maintaining the flexibility our customers demand. This speed to value has been vital to our clients in the past year, as the world landscape has shifted due to the pandemic and the need for digital transformation has grown exponentially. This software to find data integration coupled with archetypes is massively accelerating our customer's ability to deliver on their digital transformation. But it is also providing a robust foundation for them to extend their own offerings and build their own SaaS products. By removing the barrier of bespoke data integration, they can build net new products that scale across their own markets. As you saw today, Foundry provides a software solution for better decision making, enabling businesses to actually turn their data and models into transformative change. This is especially clear from the business and institutional outcomes Foundry has enabled across the world. We want to share a few of those with you today. Some of our partners are using software where software really hasn't played a role previously. For example, a law firm is leveraging the technology to provide sanction screening to their clients removing the need for manual review. Infinancial services, customers are extending their offerings to be much more tailored to the client's reality to create customized solutions. A bank is building new cash management capabilities that integrate directly with their client ERP systems to solve a ubiquitous challenge for treasuries. Another bank is investing in using the software to build resilient trade financing solutions that are highly responsive to dynamic supply chains. One insurance company is providing a shared foundation for risk management with primary insurers. Another insurance company is deploying an elder care operating system across Japan to address a systemic societal issue of inefficient resource allocation. In manufacturing, companies are breaking down silos to make their valued chains work much more efficiently together. Automotive OEMs are deploying the software to their suppliers to enable seamless quality investigations and supply chain coordination. Performance materials manufacturers are collaborating with semiconductor manufacturers. And our channel partners that you heard about in our last investor call are using the software to build their own go-to-market motions that allow them to scale their unique expertise through software. A management consulting firm is taking a working capital reduction offering to market for industrials in Germany. That allows them for the first time to unlock their unique business understanding through software in a scalable manner. Another management consulting firm is leveraging SDI and the Foundry Ontology to accelerate their M&A activities both during the diligence phase and post M&A during the digital transformation. Systems integrators are productizing SAP migration modules that accelerate the time and robustness of their offerings. In each of these cases, the software product pattern is the same. Provide software to automate heterogeneous data integration so that our partners can leverage their unique capabilities to build sustainable, competitive advantage for themselves. Hi everyone, I hope you all enjoyed John's demo. I want to talk a little bit about the future of Foundry and how we're going to increase Foundry's impact. We think about doing that in three ways. First, reaching more customers through our use case catalog and modular deployment options. Second, reaching more users that Foundry can power every critical decision made in and across institutions. In this means getting Foundry into the hands of every user who needs it through things like a new mobile offering and enabling users across organizations to collaborate so that they can work together to solve hard problems that can't be solved alone, like the ongoing pandemic and climate change. And third, we're going to build on what you saw in the demo and innovate in our approach to how AI is applied to operations. We imagine a world where every decision made is informed by the best data possible and decision makers leverage simulation to fully understand the wanted and unwanted consequences of their actions within complex connected systems. Our customers' missions don't stop during a digital transformation. As Sean mentioned earlier, modular deployment of Foundry's capabilities allows us to deliver value faster within existing digital landscapes. And one way of doing this is Foundry's use case catalog. And what I want to emphasize with this is that it's much deeper than just some nice looking application templates. For example, let's dig into an offering we're developing around carbon accounting and management. To reduce carbon footprint, one of the hardest problems actually building a data foundation to understand it at the granular level. Companies have to integrate detailed data from across their global operations, raw materials, manufacturing, logistics, distribution and transport, and overlay all of that data with a carbon equivalent calculation. And then incorporate that cost into workflows across the business. From there, they can start to actually evaluate the impact of everything from daily decisions at what speed should this shift travel to long-term ones, like what ships should I prioritize to replace with more fuel-efficient ones. Foundry's solution solves this complexity, building the knowledge asset and simulation capability first, and enables customization and specific workflows and applications built on top of that. This is really just one example though. And we see a potential for a marketplace where industry leaders can encode their unique knowledge into products that accelerate innovation across their industry. As John shared earlier, we believe non-tech businesses like law firms and banks can leverage Foundry to distribute software solutions to their customers or partners. For others, modularity centers on the interoperability of Foundry with other digital platforms. For example, we are partnering to create a joint offering with a third-party infrastructure and data management tool complemented by our ontology and operational platform to drive business decision-making. In another configuration, customers use our data platform, but operate third-party or custom application platforms on top of that. Over the past few years, we've seen Foundry extend from the offices of data engineers to every operational edge imaginable, from the shop floor of the final semi-line to maintenance trucks, service and global infrastructure, to military bases, and more. Our upcoming mobile offering enables customers to build, deploy, and manage purpose-built applications for mobile using the same point-and-click tools that they use for desktop. For example, a maintenance technician can use their phone to guide and prioritize their daily work using a triaging application powered by multiple data sources and meaningful models. From there, they can identify and investigate maintenance issues on site and use the app to quickly capture back additional data on the fly that then becomes available to their colleagues. Even more important than reaching more users is connecting those users to each other. We're seeing the customers want to collaborate at a truly unprecedented rate. Health agencies with hospitals, manufacturers with suppliers, and in Foundry, we treat this as fundamentally the same problem, whether you're working across organizations or working across functions within one. Effectively, industries are just another large-solid organization with a few additional constraints. And because of that, Foundry's approach is really unique, and it can be compared to surface-level collaboration tools like shared folders or chat. It's more joint operation than just collaboration. And the way it works is that Foundry sets granular security controls at the data source level and provides a shared operational language, the ontology, as the parameters for engagement. And these parameters then flow seamlessly into all downstream business tools, freeing up users to focus on the problem at hand, and effectively within the boundaries of Foundry work as one team. Equally important, the system is dynamic because security stances are constantly changing. Shared spaces can be used for ongoing collaborations like between suppliers and manufacturers, or they can be purpose-built, time-limited shared spaces that meet strict privacy requirements between organizations collaborating in this way for the first time. We see the potential impact of Foundry shared spaces, primarily as resiliency and adaptability to change, rather than just efficiency in the status quo. Challenges like electrification of cars, or prevention of the next pandemic require rapid evolution of how organizations securely share knowledge and change together. Our customers are accumulating sensor and computer vision data, but encounter significant problems in moving the models that interpret that data from science project to live operations. Foundry's approach to AI addresses these roadblocks by tightly coupling model development with the operational problem that are named to solve. We're not building just another code notebook or modeling library for data scientists, but rather the DevOps for all of an organization's models, providing a software framework to get from idea to ongoing impacts. I won't get into the details of every step of that today, but let's look at model training and monitoring as an example. Imagine an analyst at a telecoms company builds a model to identify damaged infrastructure through satellite imagery in order to prioritize and then dispatch maintenance crews. She will find it crucial to understand whether the model performs equally well on all types of damage. Some damage requires urgent repairs, so in the business application, even slightly worse performance of the model on this subset of data would be a major concern. Foundry's intuitive pointing quick experience makes it easy to interrogate model performance on meaningful subsets of data and to view the results in an operational sandbox similar to when an end user would see downstream. And this nuance is really critical in using a model practically, but is often lost in traditional AI model development tools. Through the ontology, Foundry provides all the relevant context available to explore and anticipate how the model will perform in different situations. And importantly, this is an ongoing process. Built in monitoring and retraining ensures the evolution of AI projects for the long haul. Another crucial part of connecting models to outcomes is Foundry's simulation engine. We introduced this in John's demo earlier. The simulation engine changed models to each other through the ontology, enabling users to ask what if questions and understand the potential impact of their actions on the entire system. This year, we want to take that one step further by democratizing optimization. So in the supply chain example, this means instead of manually comparing a few scenarios, a supply chain manager could trivially find the precise price point that optimizes revenue without going under inventory limits. That might sound pretty simple, but a lot actually happens under the hood. Within an optimization, we evaluate thousands of scenarios with each scenario representing a different set of possible actions. Within each scenario, a simulation changed together several models. Finally, the simulation engine returns a ranked list of scenarios and the operator can compare them and make a final decision on which action to take. Fundamentally, though, this isn't about any specific optimization algorithm, but about how Foundry connects optimization with actual operations. We believe that by combining the software's ability to fully explore a decision space with the human operator's ability to understand unmodeled constraints and information, we enable organizations to rapidly adapt to changing environments and consistently be adjusting towards optimal in every decision that they make. This can mean anything from identifying the optimal price to sell inventory, identifying wind turbines positioning to maximize electricity generation or plotting shipping groups that will maximize revenue over the course of years.