================================================================================
METADATA
================================================================================
Title: Palantir CEO Alex Karp on AI for Security and Stability | FII Priority 2024
URL: https://www.youtube.com/watch?v=gTnbzjSZj5c
Published: 2024-02-23
View Count: 28,836
Duration: 1173 seconds
Score: 54.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

We're hearing from Dr. Alex Carp, the co-founder and CEO of Palantir Technologies, and absolutely delighted now to welcome our wonderful moderator to the stage Cecilia Atyes, the Senior Vice President of Public Affairs for Richard Atyes and Associates and Founder and President of Cecilia Atyes' Foundation for Women. Cecilia. I'm very happy to be here and I'm very honored to welcome you, Cher-Alexandre. Thank you. Your French is perfect. I know that my English is not perfect, but your French is so good. So maybe we can do the interview in French. So, dear Alex, you have a very interesting and diverse background coming from philosophy, sociology, and a German university. I don't speak German. And going to one of the most influential tech companies in the world, it's fascinating how someone who is such a background in social sciences transitioned to successfully into tech industry. How do you explain that? Well, so I wrote a page. I was born into an academic family and there was basically one choice, being an academic or be a failure. And I didn't, my family, we really, business was not viewed as an option. So I ended in academia the way most people end up doing things, because it's what I knew. And I was reasonably good at it, although it turned out I worked for some of the best people in the world and what I discovered was I was better. I should go build things. And the other thing that I really remember vividly thinking was, in the past you shaped the world through ideas and words. And obviously at the time this was pre-the software revolution, but I really came to believe that and believe now that the world would be shaped through the embodiment of ideas and words in software platforms. And that these platforms are so levered that in fact they will shape our life in a way that words used to. But you know the time, the weird thing about German academia, at least at the time was unlike what one might experience at an elite school in America now, people were very, very serious about academic rigor. So the rigor and the kind of depth at which you had to understand ideas, not just their caricature form of the idea, played a very big role. And then one of the major things I've been thinking a lot about, and some of these ideas are in our platforms. I don't want to like, there is kind of a German phenomenological version of Foundry PG, these products we built. But I think the thing that has been influencing you the most currently is that we have these amazingly successful products. But I think they're successful because we built them outside the norm of any playbook. If you have, if you go deep enough into philosophy, you see that these playbooks or authors or schools at some point they break. So, you know, and so, and then- So the thing that you're background helped you to be out of the box? Well, I mean the primary thing that helped me be out of the box is I'm pretty far out of the box. But I felt a lot of, I felt, I felt, I did feel a lot of kinship with, I mean I could give you lists and lists and lists of important, especially German to some extent French philosophers and thinkers. But one of my critiques of most of them is they're actually more poetry than they look in that they explain a time period. So like for example, you can't translate a dono into English really because it's a time period of a time period of a time period. And what we're experiencing now across the West is that the playbooks, financial playbooks, the people who understand them, hardware playbooks, the people understand hardware, political playbooks, left right center, ways in which to deal with issues, wars, crime, education, raising GDP. The old expertise is really are not as helpful as you would think. And so one of the reasons why America's leaping forward is we have a much greater community of non-playbook players than any of place in the world. And so for example, if you've built a great hardware company that's probably not very where you want to be when you evaluate software. If you have a deep rigor of the political dynamics of a culture, you probably are getting massively manipulated by people who know a lot less. So what's super interesting about the AI revolution is almost none of the playbook rules make sense. L-lems by themselves aren't that valuable. So it's confusing people. It's like yes, there's poetry and videos. But you can't make your, you can't get better margins, you can't rebuild your manufacturing. But actually you can if they're processed. So then it's confusing. It seems to all come from America. But then the countries that are adopting them and doing the most with them, I think you're going to find are in America and also in the Middle East. And why is that? Because it's another thing that's very unfair. This is a highly inequitable revolution. So the rich people get much richer. The poorer people in America, I do think we'll have GDP growth. But it's, the delta is going to be very large. Then you have places that are known for innovation over hundreds of years Europe is not participating. And you have also L-lems algorithms, software, these are very different things. The ability to build a software platform that could be useful and the ability to work with L-lems, build L-lems, work with algorithms is also completely different. The assumptions are different. For example, in hardware, basically the value is having a community of people who are all very good. In software, the value is having the one right person. Now it seems like a small difference. But I'm almost all the ability, the attempts to build these American Silicon Valley similar ecosystems of tech largely fall apart because the people building them are not software natives. And then you see Saudi Arabia, Emirates, other places embracing these technologies in a way that I wish other places in the West Europe would, but they're not. So it's very, very, very counterintuitive. And then there's this thing. But simultaneously, of course, just to riff on this last thing, you can't invest in things you don't know. But this is something you have to know. So that drives me to my next question, which is kind of a tricky question. Which also concerns me and concerns a lot of people here. If we think about privacy, ethics on one side and grows on the other side, it would be a controversy here. I would like to understand how volunteer navigates the challenges posed by those opposing priorities and fines balance. Palantir starts 20 years ago. So there's different phases. The core Intel product deals with privacy issues by removing the contradiction by exposing authorities and only authorities to the data they're allowed to see without seeing the other data that they're not allowed to see in that. But what's crazy interesting is that architecture is actually the cornerstone. We did it for the right reasons, meaning we thought expanding liberty, meant fighting terrorism and fighting terrorists. So you don't get the left right divide that like, you know, one side, one's terrorist, the other side doesn't care or once take away your civil liberties. So the interesting thing about going deep into that problem was, and if you do that, you need an architecture that sits on every bit of data that has branching, that is a security model that's granular, those are the precursors to being able to work with large language models or algorithms in a way that's not just ethical, but quite frankly, that works. Because for example, if you're sitting just, this is a completely commercial example, but it is exactly mirrors at an architectural level, the example you would have if you were sitting at an Intel service. You're sitting running a large agricultural company and that involves all sorts of things. We cows, whatever, and you have to model your supply chain and your export of your product and you have to task, you have to, that's influenced by weather. So you, in any enterprise you're sitting in, you're going to have a security model. You can't just outsource that tasking to any random person. You have micro-tasting. This person has the ability to ABCD. How do you interact with the large language model to find the satellite, to task the satellite, to task the satellite that can look for this kind of weather conditions that's cheaper and another kind of weather conditions that are more expensive without outsourcing the logic of your enterprise. Outsourcing enough of the logic of the enterprise so the LLM understands the use case without exporting so much of it that the LLM owns your use case and your business. And how do you control who sees what and when and when this tasking happens? Those are exactly the same kind of issues you have if you're running an Intel service. Who gets to see who gets to see this crime network. Because in that crime network you probably have assets, you have people, meaning they work for you, you have people that you're protecting because they're an idiot, you have somebody you're trying to undermine because they're smart. These are architectural cornerstone issues that are vital to every enterprise in the world. And if you don't think they're vital, you will not be able to interact with the enterprises. It's currently conceived, meaning the people managing it without paying attention to these issues is basically a non-starter. So the overarching thing I would also say is I'm very pro-civil liberties but you do, you have to both augment civil liberties and augment GDP and they're not in contradiction. And what you will find is that often people who are allergic to technical issues are actually the adversaries of the Enlightenment because if your enterprise doesn't work, your country doesn't work and nothing can work and mostly because you're so lazy you're not willing to take the time to go figure out how these issues are solved technically or you're so arrogant that you don't believe you have to understand these issues. You are actually the person yelling at me, you should be yelling at yourself. We're on the side of enlightenment. You're not on the laziness is not, laziness and aptitude and watching your society go over the edge is not the friend of your enterprise, your country, the betterment of human rights. And so being like choosing to be a lute for one-ever reason because your country is not producing the tech people or because you used to investing always work this way or honestly most importantly because you don't like hanging out with a person who has the knowledge or you're threatened by him, her. That's actually what stops the development and completely backfires and I'm very proud that that is the line between Germanic PhD level professional education and what is happening across America with my product and presumably in other contexts and then on the battlefield. Absolutely. So I would like to have for the people here to have a clear understanding of the contribution of Palantir and the role in Palantir in the world. If you could name one thing that you would be proud of one just simple thing that would make a positive impact in the world, what would it be? Well I'm very proud that there have been a numeral terror attacks that have been stopped in Palantir in Europe and I would say in all honesty if they were not stopped you would have a very different political reality in the West. And that's just a fact. I love when I'm getting yelled at in cities in Europe and like keep yelling at me the only reason why someone's not goose stepping between me and you is my product. Say thank you. So thank you. Thank you. We'll be accepted. We'll be accepted. Look the fundamental reason for America's outperformance right now is tech. Palantir plays an enormous role on the commercial side. On the fighting war fighting side we've entered a phase where real battles and war wars happen in very complicated electronic suppressed environments. You can't use old hardware in those environments anymore. You have to engage in software war and almost all useful hardware things going forward will be software enabled software controlled with human handoff functions. Palantir is indisputably been at the lead of that and I think we're at the way, way beginning. I would say from a technical perspective the thing I am most proud and in all of is we built these products that looked like kind of marginal luxury products built in part by Palantir, their madman leader and outside the norm IQ people people didn't want to hang out with and lo and behold they're exactly the products everyone needs now and you know we don't we never had high sales we were not we are not in conformity with whatever you've been taught you're supposed to say that you don't believe that you have to say we've never done that and we're winning and winning by the way again something I wish we would teach more to our elite schools it's very important this like I lose and I lose and therefore I have a higher value and therefore people respect me is BS and we don't stand for that panel here at all. So tell me we live in very and a very difficult time of wars conflict everywhere. Palantir operates all the while and handles critically sensitive data. Could you tell us how tech companies like yours are affected by geopolitical conflict? Particular when it comes to that ownership and that that privacy. By the way, neglect to say I'm very honored to be on stage with you. Yes, people don't mean that but like when you have a question you need a wise answer you're one of the first places people in the know call and I'm very honored to be here. Thank you. Look the core issue that companies have in the environment we're in is companies were built in a world for a world and the tech that they've employed have by and large been built for a world that is global and peaceful and where every day there's less violence and bigotry and your supply chain is never disrupted and your primary task is to tax optimize in a rationally a rational environment that every day gets more rational. That playbook is out the door. So your products have to work in an environment where you can understand your supply chain even as it's disrupted predict potentially disruptions. Treat your company and all of its latent assets as a portfolio under the condition that the portfolio will be very different tomorrow than it is today. And that and the stress that is placed upon it does presuppose robust software in your commercial environment and at war and that your primary duty as a leader now is to adapt for that environment and what does that mean? It means going to the front line and seeing does do my products work. We do these boot camps where we tell everybody take everything you've done an AI prepare to all the power points that you have people doing and then compare it to what we can do live in 10 hours. Now of course it's self-serving because it's not 10 hours it's being right about architectural decisions over 20 years and then being expressed in 10 hours. But the reason it works and the reason is valuable for people in this room to consider doing that is you must know the state of play and you have to look at it directly and it is your responsibility to go look at this because if you don't look at it people around you aren't going to look at it and I'll tell you something else half the world is aligned around some idea that this stuff can't work that's because they don't have any valuable products. You got to go look at yourself. Of course half the people are telling you this can't work it has to be a power point that can't work or if that yes I can tell you at least in this country down the road they're employing a product that does work and you have to look at it yourself and anyone is telling you it's not valuable it's not going to be valuable or it's only a power point probably doesn't have anything to sell just trust them go look at it yourself. Okay we're running out of time but just one little question the last one if we're in a science fiction movie how do you see the future of AI? It's it's undecided it could go either way but I would say in the near term the most important thing to make sure let me give you another counter intuitive riff there in many developments technological developments the the innovation is taking place five years out this is a place where the innovation ramp is so great that the most important thing really is what do you do in the next 18 months? Yeah so like the most important battlefield for this is in the military and what will be decided is can America and its allies get to a point of decisive dominance and then impose regulation on the rest of the world from that perspective of dominance that would be the best outcome. Thank you so much so it's great having you. Thank you.