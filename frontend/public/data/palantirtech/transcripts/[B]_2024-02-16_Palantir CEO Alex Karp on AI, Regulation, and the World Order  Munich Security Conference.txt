================================================================================
METADATA
================================================================================
Title: Palantir CEO Alex Karp on AI, Regulation, and the World Order | Munich Security Conference
URL: https://www.youtube.com/watch?v=Jb2oh0kAKCA
Published: 2024-02-16
View Count: 36,196
Duration: 2679 seconds
Score: 54.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Good afternoon everybody. Thank you very much for joining us this late afternoon. At this very special conference, we are very fortunate to have an esteemed group of individuals here to share their thoughts. I will start at my far right with South Raquettes, the chief executive officer and chief financial officer of Oracle, Kurt Sievers, the president and chief executive officer of NXP, semi conductors, Alex, Carl, the chief executive officer of Palantir and Margaret Stayer, the executive vice president of the European Commission. And I will start, we're going to have a conversation. These foresting leaders, I am the designated official to watch the clock because we want to leave plenty of time for your questions and thoughts that hopefully our conversation will provoke. And I will start with the subject that I tackled earlier this morning at the Munich Cybersecurity Conference and that is the following. There is a difference of views when it comes to technological advancement in the cyber security space, but increasingly of course with the advent of generative artificial intelligence, a disagreement of views with respect to the role of government vis-a-vis the private sector. There are those who believe that the past 30 years of a more laissez-faire approach has led to an ecosystem that is not sufficiently secure and that government needs to play a far greater role in regulating technological development. There are others who believe that really we must abide by a voluntary framework that industry must be left to self-regulate itself that the market plays as a driver of responsibility and that the rather labyrinthian and cumbersome architecture of the regulators suppresses innovation and the West leads in innovation and it will cause us to lag behind. And sometimes that is a very polarized discussion, sometimes it is a hybrid model and I pose that framework to the four of you and leave it to one of you to jump in first. I can give it a try, at least. I think it is really interesting what happens happening with AI these years because all of a sudden everybody was aware with the emergence of chat DVD, it was not everybody's phone. And of course AI had been around for quite some time, we had been working on the European AI Act for I think two and a half years at the time it had been tabled already. So obviously AI was not a new thing but it was there and all of a sudden much more powerful with an exponential development ahead of us. And we have different systems, we have different legislative opportunities, we have different approaches. But I think since there was this global momentum, it was I think quite obvious that we could do something unprecedented. And already at the first trade and technology council back in 2021, we agreed on the approach to artificial intelligence between the EU and the US that it should be risk based. So don't try to regulate technology, regulate the uses of it because there are so many use cases and some of them are absolutely fabulous and some of them are absolutely not in any way threatening or dangerous or whatsoever go go go. Also we would not regulate innovation or research because then it's not put into use yet. And that has I think brought a very fertile ground for a mutual understanding between us as to how to approach this. What you see in our AI Act is somewhat also merit in the presidential order. Both the US and the EU have pushed within G7 to have the G7 code of conduct under the leadership of Japanese friends who manage this very efficiently. So I think the point is to say that you can have a code of conduct, you can have a presidential order, you can have an AI Act that comes into effect. The point is that we need action now because it's now perceptions are being you know set in stone, it's now behaviors they begin to form. And this is why if democracy wants to have a chance and not just having what is a technology let business let big tech let approach to this then we need to act now. I think it's a bit it's good that something is happening here with the Munich Tech Accord. I think it's it's will be interesting to see if it will actually live up to what was signed up to in the presidential order. What has been signed up to in the G7 code of conduct because it's really really important that tech companies also take the responsibility when when infants is is being so much more enhanced by the large language models and generative AI. Well you know I think someone would think that I'm an industry that I would disagree with with the executive vice president Vestergar. I actually couldn't agree more with her because the reality is a risk-based approach is absolutely critical because it will it will make sure that either the tech companies or even the utility companies and infrastructure provide a better way to do it. And I think that if you look at the numbers actually do what needs to be done these are dangerous times and cyber and AI are weapon systems it can be and it's very important that we protect our infrastructure from cyber that it's very clear that they must secure those systems. We're built decades ago they were not expected to be on the internet many of them have code that is often older than some of the people in this room. And the reality is that these kind of things and then with the onset of AI which of course we've been talking about machine learning and AI for a long time. But just even two years ago we weren't talking about generative AI and information operations and all of these things. So some level of regulation is always necessary because otherwise you have free riders and you have monopoly holders that close out actually close out innovation. So even though we're a tech company and you know we're all about innovation we're also about security and we're also about making sure that innovation continues and that there is a code of conduct and that innovation can flourish. So I have to agree with you 100% and I also want to point out the time is now every minute is like a decade right now the way technology is and you can't undo some of these things often. So I agree with you completely. Yeah so a bit boring I also agree but a few shades of gray maybe. First of all when it comes to critical infrastructures I think we can only agree they have to be secured since AI is used unfortunately both for offense and defense and the offense side is the problem in that context. Where I would actually put this into a different light is that regulation sounds like a negative thing but I believe that every consumer every user of AI wants to have a certain level of trustworthiness which is about transparency safety and security. I think we can make in that sense regulation actually a positive brand because if the user knows this is a trustworthy system which is not faking or else it is a positive and I think it's actually a differentiator a competitive differentiator against other systems. However I do believe we needed that across the western world so I know the title of this is something like transatlantic and here the issue starts in my view because the power of AI comes and goes with the availability of data and it's I mean I would love to say it's the silicon but the silicon is just the hammer which is using it I mean the real thing underneath is the availability of data. Unfortunately at least from our view there are very different data security systems in the US versus Europe I mean the GDPR is just different to the correspondent system in the US so I think there is a lot of urgent need to try and align these systems over the Atlantic in order to provide access to data from both sides into a much more powerful system. So I'm Alex and thoughts yeah I don't want to say I disagree but I think firstly I have to disambiguate between cyber and a weapon system so I think what would concern most people in the Munich Security Conference I would imagine would be how do we find hidden adversaries in a complicated war environment like we have with Russia where you can actually only field our weapons with enhanced AI. I'm not in favor of regulation in the environment at all except for to restrict the technology is going to our adversaries so I don't think that's so like just so military technology restricting use my version of that would be yes we should restrict Western companies from selling to adversarial countries. I think we agree on that but then in that context I'm not in favor of restrictions because basically you're restricting our ability to build it while of course Russia China and Iran are definitively not going to restrict and I think we probably agree on that but I think you have to be very very clear that then the more nuanced areas if you say in the cyber context restriction is very hard because de facto it's not what we build but if we were to build cyber attacking the cyber attack. So I think that if you have a lot of devices and you restrict our ability to build them certainly Russia China Iran which are North Korea which are very very good at building these systems would have an advantage or they have a disadvantage. Then you get to the consumer internet version and I mean restrictions work very well for my product as long as they're fairly applied and I do think if you ask people in America there's a intact there's a somewhat of a concern that these will not be fairly applied because I think that's a good example. I think that's a good example of how we build a cyber attack because the US tech scene is the dominant in the world and that's less my worry but if we're being honest about it that is a concern and I think it's one that people worry about a lot I worry about that less. So one worry is somebody who spent a lot of time in Europe my dissertation was written in Europe in Germany I think of myself in some ways as partially part of the European project and we'd like to see Europe succeed in economics or something called a paradox of thrift which is a country that saves too much ends up being poor. It's actually we classic progressives love this theory because it's one of the reasons we want to spend more. I really worry that the idea not your idea but an idea of this legislation is that restrictions will help the European tech scene catch up which I want. I worry all backfire because America is currently not it's just so far ahead 84% of tech of the top 50 tech companies in the world are American. I would imagine it will be 95% in five years and if this actually is about protecting consumers I'm roughly in favor of it but if it's about protecting the European tech scene I'm very worried it will backfire and Europe doesn't have a great GDP growth story right now and I think that is a very big risk and one of the ways American Europe are very different and as somebody who wants Europe to win. I worry about that. I just want to say I think that when we say regulate you hear restrict and I don't think that's at all what we mean. In fact some of these regulations actually enhance and they don't restrict they open instead of things like clouds which are closed now they open them. They cause more so I know you're hearing and I totally understand how when our enemies have no rules on them and no compunction about privacy or anything that can be scary when it's a weapon system but I have to tell you that every water company and utility in my view should be required to protect themselves from a cyber system. I think that's from a cyber security attack. Absolutely agree but there is mission creep here and I don't mean primarily in Europe by the way. In America our central military advantage is that we have all the best software players basically and I want to make sure that mission creep does not happen there but in these areas which I presume what we're talking about is consumer and other of course we should regulate it and there are dangers and the risk model that you've outlined with very high moderate risk model. I don't have a huge issue with that but I would say that I'm nervous about mission creep into weapons of war. No that's clear but again I think it was really meant to do something which drives consumer attractiveness because you are dealing with a trustworthy technology. Why agree with you but every legislation starts off with I mean okay you're taxes where did they I mean like I of course agree with you but it's and who's going to apply these what I mean again I agree but like how many technical people are in government does I mean what is a large language model. We have a big task here. Now the other side of this in my view is that we are at the very early innings of this whole AI cycle anyway which is everybody talks about generative AI now. I believe the way forward is at least 50% H AI which is a which is a different concept there actually the data and the device is much more local with you so the big data center stuff which by the way is from a sustainability perspective horrendous in terms of energy consumption and the privacy protection because you let your data go away and come back is handled very differently in H AI. I believe by the way when you say the US is far ahead now my company we are just 50 50 in between but I think Europe inherently has an advantage for H AI so I think there is a complementary case to be made between the cloud and the edge systems between the US and Europe which again speaks about this transatlantic collaboration. And if I may just add to this because the only way to get ahead of the game is by competition and the legislation passed in Europe these days is opening the market it is pro competitive it is pro innovation because what we have seen over the last decade is a market that becomes increasingly closed. You know what I have seen not in one not into but in three final Google cases and another one to come a Facebook case to Apple cases a Microsoft case and a couple of Amazon cases is businesses who are so big that they seem to think that the rules do not really apply and that means that it becomes increasingly difficult for all the innovators to scale their businesses to be out there to challenge and it's by challenge you become better it's not by allowing market power to be on the market. And the point is I think this is also a very actually a common concept that with power comes responsibility and that is what is happening in Europe right now and the second thing is actually today the last part of the inter service that comes into effect and that means that as a service provider you need to realize what can my services do can they be hijacked to be a risk to democracy because if so I should mitigate those risks. Can my services be used to undermine individuals well then I need a system not some regulator to come and say that expression is fine that one is bad no but you need to be aware about what is the role that you're playing in society because then we can have an open marketplace then we can have the best innovators to work we have a lot of work to do in Europe for instance because our capital market is not sufficient interesting but it's just to say that if one thinks that you are not going to be able to do that. I can protect a market and have progress I think one is against the entirety of economic history because what we have seen is that you need competition as the fundamental driver in what you do but what we have seen in Europe is that that has become increasingly difficult because of entrenchment and the last thing would be to say you say there are no tech people in government but it's legitimate for citizens to choose their representatives. What is the legitimate for those representatives to pass legislation? I'm probably the most prominent critic of Silicon Valley in tech. I completely agree with your criticisms of the consumer internet world I think they're a cancerous on our society. I wish we had regulation on them in America. I think TikTok should be banned in America. I think their air addition and corrosion of our cognitive capacities are largely the result of these I could go on and on. I agree with you and bring your legislation to America I'll support you but I just I and I do know that there are very technical people in government. I have a very successful business in Denmark and all over Europe and they're very technical people but it is an issue for all Western democracies that the technical specificity of large language modules especially exceeds the capacities of all but the most technical people and that is a problem we all are going to face in every context and there's that's I I and and then on the I think and so what I think we we and obviously in the competitive combative context we have to find ways to actually share data and share software and share all these things. And the last thing is just a lagging concern that I think all of us who care about Europe have that there is a tech scene issue I would love to believe that AI at the edge which we also believe in will be more important and I that but right now there is this issue that is a unspoken issue between America and Europe where we have lots of issues at home everyone's aware of them. But we don't have a GDP growth issue and the reason we don't is because we have incredible and incredible tech scene and and I do think it would be who of us to find ways including regulatory to work better together. Let me if I can just say something well first of all I should say agree agree disagree agree and disagree agree. With respect to regulation I want to turn to something that Kurt said but with respect to regulation of course it depends on what we regulate and how we regulate but with respect to the reputation of regulation and and software drawing the distinction between regulation and restriction which is so vitally important. What I posited this morning is the following that for technology for the technology sector and the rapidity of development and advancement it is most unfortunate and I think unworkable to actually apply an antiquated regulatory architecture to a fast moving fast evolving and dynamic landscape. What we as a government must do is actually build a new way to regulate so that we can meet Margaret the point you made the imperative is now how can we meet the now and how can we as regulators be equally nimble to meet the evolution in technological development because the reputation of the regulatory architecture is that it is. Slow ponderous suffocating labor in the end and we need to design something for the technology sector that is different than a regulatory environment for perhaps oil and gas that is less fast moving etc. You know it's funny you said that because I was on the national security commission on AI I think I was appointed probably five years ago and our report came out more than two years ago did not have one word about generative AI in it okay imagine 800 pages not a large language model inside so your point is technology moves quickly I would argue that often you would have a lot of time to do that. You have to pair the risk and the responsibility on the folks who can in fact do it you know and burden sharing exactly and then you see because otherwise you end up with sort of a free writing or market power thing that it's even stuns me sometimes when I run into it and I'll give you an example I was. Meeting with a government intelligence agency very very famous and they had a contract with one of my competitors I'm perfectly fine with that but in their contract with the with my competitor it actually says that they are not allowed to speak to their company that the intelligence agency cannot speak to their company. The other companies competitive companies about this topic I mean I was truly stunned and the reason it's I find this really disturbing is because you always want the customer to have the best and the newest technology maybe the best it may not be but the idea that a customer once they have a contract with a powerful vendor cannot even speak. About the the competitive product like these kind of things those things in danger are planted in my view so I I think I agree and I I'm more power to it let's open it up we clearly can continue our conversation but want to give people an opportunity to share thoughts both questions. Anyone want to give it a give it a go. Well until someone assembled the courage maybe just one more thought on on sort of this regulation versus voluntary commitment actually we had two versions of voluntary commitment on on the sort of the security of services of social media services before we realized that only putting this into law. Well actually give us the result that we would want which would be the burden sharing that the broader shoulders actually do carry part of the load. And it comes from the same place to say well if if if you can have results you should do that with the least possible burden on the business community obviously. So it's just to say I think we have the same approach and now in in in part of our legislation we use what we call sandboxing so instead of setting everything in stone leaving some wiggle room for authorities and the businesses were to comply to figure out how actually to do that. And I think also sort of modern innovative ways of legislating is something that needs some attention because it's real development to make sure that it actually works as you wish for. Margaret thank you. Yes please. Yes, Mikaela Kripta from Deutschewelle my questions to Mr. Carb since you are so aligned with Mrs. Westagger on the question of regulation I wonder whether you as entrepreneur would then also see you in a responsibility to make water tight regulations that would prevent anything like Cambridge Analytica to happen again or for future election interference with the use of AI. I think that's 100% and the Cambridge Analytica thing is is completely BS and but I'd be very happy to read look I'm in favor regulation that gets enforced but since the Rekondysach of Deutsch completely forgishobens in a few argument that I can mark in Germany to pretend that the arguments that the law is actually always applied fairly and evenly like in Denmark in Germany is swachs in and it is complex it is all the sudden every product can only be the product built in your local country and so glad that this need pass it is all do mistaken for the showman argument and you feel the first mention we miss the age the age of desire to zero for the whole part of the title and so of course we need transparency of course we need these rules but you know then they have to be implied you know it's the thing that I love to believe you're falling a rule is not to follow a rule you want the rules I'm in favor of them I'll defend them in America with my 50 million followers but they have to actually be applied for real and they're not always applied for real and if you want a great example of what we're going to do is try and take advantage of the rules You want a great example of a place that applies them for real. Go to Denmark, watch how they do procurement. You have the Danish in charge of this. I'll be your biggest ally and so will tech. And that's my real worry. And all these fake election interference, I'm happy to fight election interference all day and help you do it. But you then, the rule has to be the rule. But are you actively doing that and are you offering advice to the politicians because as you rightly pointed out and I would include myself, it is a question of people actually being educated and having the technical understanding. I'm happy to help. You see you have people, look, will help. You have great politicians and incredible tech leaders and will help. Well, listen, there is examples for this. I mean, we did the same in cybersecurity earlier. There is something like a charter of trust, which was actually brought up by all the big industrial players in Europe. It's spilling over into the US now because it became a trademark that if you have a certification on the charter of trust, then the system is actually more secure, which is a consumer advantage, which is a competitive advantage. Consumers want that in the end. You don't have to understand how it works, but there is a promise that you get a product which is more secure. Now for AI, I think there is a big, big consumer desire already now in the very early days where people are not much educated about it, but there is already a desire to have something which is trustworthy. And that is for me a competitive advantage, at least in the Western world. I can't judge how Chinese consumers think about this currently, but I know in the Western world, including the US, that there is a big desire for trustworthy use of AI. So in my view, regulation, and by the way, we should speak about innovation in a second, not just about regulation. In my view, regulation is to be applied for the benefit of consumers, which is less than what probably you think, which is more about the competitors. You do acknowledge that sometimes it's not fairly applied. Absolutely. And that's corrosive for the European project. I couldn't agree more, but only because we've got it wrong in the past doesn't mean we shouldn't try again for the future. Absolutely, 100% agree. So by the way, if fair application of law must be assured before a needed law is promulgated, we're in a lot of trouble across a wide spectrum of our society. We have to promulgate the laws that our society needs to achieve our shared objectives, and then we have to ensure that those laws are fairly applied, and that's a two step process. But you were going to say something about innovation. Yeah, because I should have said in the beginning that my core belief is, of course, if regulation is in the way of innovation, it is wrong. I mean, that's maybe the simplest way to put it, because I think innovation must prevail in a competitive world in the end for the benefit of the consumer. But what I want to say about innovation is this whole idea of HAI, which actually addresses some of the concerns which we discussed earlier. I just learned earlier today from a telco provider that currently 25% of the bandwidth of that telco company is only used for data encryption and decryption. So there's only used to get data from the phone which you have in your hand to the data center and crypt it, decrypt it and back. 25% that's enormous. And if you think about the energy which is then consumed on the far end in the data center, this is not scalable in my view, which gets me back to this idea of HAI where I think a lot of the focus should go to, not only delivering the advantages of what I think is data protection but also from a sustainability perspective. Yes, ma'am. Hello, I'm from China. Just now, I know this panel is mainly about the Atlantic alignment on HAI governance. However, I still want to raise China because I know China is very important in AI development as well as governance. So my question for our dear panelists is, do you think it's necessary to engage China in AI governance if so? How? Thank you. Anyone? Well, I would definitely think so, yes. China has passed laws on AI. I don't know them in any kind of detail. But we have between the European Commission and our Chinese counterpart, what we call sort of a high-level digital dialogue, that encompasses basically all kinds of technology. And I think it's really important. One can have different systems, but you still need to be able to exchange about them. I think how we see our relationship with China is a complex relationship. Because we must be a partner on fighting climate change, the point just made about tech also being a part of the responsibility in doing that, because without China and both there will be no fighting climate change. We are an economic competitor in many, many, many different reigns, and we are also systemic rivals, because we have different systems. But that doesn't change the fact that we need to engage one another in how we see technological development, how governance should be developed, what should be the restrictions, what should be the enabling factors in the marketplace? I definitely think that one needs to engage. I spent half my life doing Tai Chi, a real revered Chinese culture, and I would remember this to say that I like most Americans, I believe, believe we should have very severe restrictions on exporting our enormous advantage to China. I hope we can reach a place where China and America and its allies can actually work together, but I think we are very far away from that in a harmonious relationship, which is the way a relationship at some point could work. But I think 20 years ago when I said we wouldn't sell our weapons of war to China, it was controversial in America, that's because of a banality. And I think being open about the fact that we are in these weapons, these are at the margin are technologies that can and should be used in the west to defend the west, like in Ukraine, like in Israel, but they are at the end weapons, technologies that will define who controls the world order. And I'm very, very in favor of that world order being controlled by the west primarily by American and its allies. That doesn't mean that we should be xenophobic or engage in bigotry, certainly not in America. One of the core things we have to avoid in the west is anything that even smacks of something that's xenophobic, that's our core strength is actually to integrate minorities of which I include myself. But I do think that we who are tech leaders and business leaders and I dare say other leaders should be very clear that we are going to do everything. And I believe Americans technology built in America should only be sold to American allies and certainly should be made available to all western governments. But don't you think one can do both things at the same time? No. Because we have an economic security that is being developed, that is being applied. We have our five-year toolbox to make sure that we have trusted vendors. But that doesn't prevent our president to have a summit with Chinese leaders. I'm very in favor of summits and then you're I believe there are two kind of voters, those who are single issue and those that have no power. And so you're talking about various issues with China and I'm not an expert in those issues, but I am somewhat of an expert in building weapons of war with software and using AI. And those things I do not think there can be transfer of technology. In the other areas, well, you know, I mean we should be in dialogue and I do think understanding a great and interesting culture that is the culture of China is very important, including for our own development. And doing it a way where we're not xenophobic and open is crucial. But I would draw a bright line there and I very much do everything I can to see that's enforced. Kurt? Yeah, I just I thought at least part of your question was about alignment on the regulatory environment relative to consumer use of AI. And there I would say absolutely yes, of course, because it remains a huge market in a way. So not everything is about weapons and not everything is about selling technology to China. But the regulatory environment when it is about consumer use of AI, I think if purposely naive. If no, if there is a way to say your edge technology will not be used as a weapon. It's the one of the most interesting ways to build a weapon. No, you misunderstand me. What I'm saying is, I'm directly understanding you. No, what I'm saying is the use cases with consumers if there is a regulatory environment which the Western world considers reasonable to be. To align that with inputs from China, there is no harm of doing this. That is not about the product getting there. It's about understanding the regulatory environment. It's like camel's it's like a famous way of creating a president. Obviously what you're really saying is you'll plan to sell technology that you view as consumer that's clearly dual purpose to a nation that you are not that you're adversarial with. By the way, that's a perspective and you should make that argument. But you're trying to make two arguments at once and I'm just telling you, be feel free to make that argument. I respect you for it especially if you actually made it. I'm making the other argument and I'm going to fight for the other argument and America is behind me on this. I'm just happy on the moderator. Let me, let me, a saffron. I do actually think both are true. First of all, dialogue, fantastic. Wouldn't it be wonderful if some of our adversaries or competitors or whatever we're referring to would actually follow the rules that we agree on. That would be great. I think that sometimes they absolutely will when it's in their interest and I think dialogue could open up some interesting possibilities. I also think that some technologies are so powerful and they are dangerous and we've taken that position at my company for decades. Which probably doesn't make us very popular in China. But we feel that they are so powerful that they need to be restricted. And we've made that restriction choice on our own without it being mandated towards us. I don't think that not talking and kind of screaming into the wind is necessarily the right approach either. The saffron has been very courageous on this and I would like to say that in the last couple months the big issue has been where do people stand on Israel. And I think that the government and the government and the government are in a few corporate leaders. And America obviously have been extraordinary on this issue and one of the unsung or properly sung heroes on this has been saffron. Now very happy to be on stage with you. Thank you Alex. It's an eye thank you. Thank you. We stand with Israel. It's very widely known. We also stand with Ukraine. And we view when I actually don't think the difference between right and wrong is complicated. I think small children know the difference between right and wrong. And it, you know, has made me extremely unpopular in Russia. I am on that list that says you cannot enter. That's okay. It wasn't on my bucket list. And, you know, and I think it is really a privilege to be at a company where you can decide that you're just going to do what you think is right regardless. And it actually makes life a lot easier if you want to know the truth. I don't see things quite as great as everyone else. And being with Israel and being against a terrorist organization that kills children and rapes women and takes hostages isn't a complicated concept. And I don't mind if people want to pick it me or my company. And the same with Russian Ukraine. Not complicated. We left immediately. And, you know, and I applaud all the other companies that did the same thing. And that's that. And never look back. I'm going to say this. And before I say thank you to our esteemed panelists and to all of you, all of you being here at the Munich Security Conference reflects your devotion to citizenship. What does it mean to be a responsible citizen in the world? The issue of security is an element of responsibility. There is a principle of corporate citizenship as well. Corporations also have a responsibility, a responsibility to citizenship as entities. We are here with divergent views, but a dedication to living up to that core principle. And I just want to thank our esteemed panelists and thank all of you for the wonderful discussion. Thank you.