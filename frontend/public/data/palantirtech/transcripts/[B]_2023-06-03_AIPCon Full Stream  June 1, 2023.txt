================================================================================
METADATA
================================================================================
Title: AIPCon Full Stream | June 1, 2023
URL: https://www.youtube.com/watch?v=7EyWLo1XG4w
Published: 2023-06-03
View Count: 19,932
Duration: 10948 seconds
Score: 55.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

you you you you you you you you you you you you you you you you you you you Thank you, Sasha. And thank you, everyone, for joining. It's my pleasure to open up the day again with a conversation with Dr. Carp. I'm only called Dr. Carp. I saw him here. I don't know this. But when we started, we had no revenue. We had no product. We were almost going out of business. The only thing anyone believed in was that I was a doctor. I kept trying to get rid of it and I realized, oh, we got to have something they believe in. And so that's why I'm still Dr. Carp. But we can call me any four-letter word that you say. I can say it in public. Perfect. I'll shorten it to Carp as we go. I wanted to start by asking you about the letter that was in the news a lot this week by the Center for AI Safety that said paraphrasing that mitigating the risk of extinction posed by AI technology should be treated as a global priority, the same as societal level risks like pandemics or nuclear war. And as the leader of a company that supported governments and private institutions through the pandemic, has been outspoken about the risks posed by the invasion of Ukraine on nuclear activity. How do you respond to that statement? Well, I think it's great to be here. Thank you for the light, softball question. You're like, you're going to get someone else next year. We've clearly picked the wrong person. Well, so we've been involved in building systems in the classified environment and in the last five, six years systems that are involved in identifying targets using AI. AI, in this context meant finding targets in very large spaces. So space is the size of Texas, find this kind of person and then a handoff. So you find target. People assume that when you find a target that you would then automatically, which just disappear. But in fact, what really happens is it's very hard to find these. You need to be able to work on disparate kinds of data sets that are very large. And then there's a handoff mechanism where it's like, is the target, is the identified object next to a hospital, is it an identified object next to children, is the identified object actually an asset of ours, is the identified object, the idiot we want to not die. So there's a lot of complicated things that involve that. But and where what I think is yes, these technologies are very dangerous. But our adversaries are even more dangerous. And that we, because of that, have no choice but to run headlong. What's interesting about a lot of these statements and what's going on in AI, which is mostly focused around the large language models, is that you really have different factions. You have a faction that is saying that it's hyper dangerous because right now you need very, very specialized technology, which I believe we provide, to make large language models really, really important in your enterprise so that you're not delivering a piece of poetry to your enterprise. It's like, no one has time to deliver poetry. We need margins to change, safety to be better. Generally, understanding of our business, the knowledge of one part of our business to be transferred to another. These are things that large language models do exceedingly well with infrastructure that will be showing off today. And I don't want to take away from the things that are coming, but there's a lot of things we built that will allow you to do that that are very valuable. So there's one part of that faction that is saying that because they're right and these things are very dangerous. But they're often right, but it's in, you're not, it's like not also mentioning if we don't build it, our adversaries will, and that won't be very good for us when we have no rule of law. And I'm in a constant battle with my academic friends about this because they believe that in the absence of hard power, either using, being able to use AI now or nuclear, essentially nuclear warheads, we would have a rule of law. We at Palantir believe that you need these weapons to enforce a rule of law. And that's our deeply held belief. And we've had that for 20 years and it's cost us a lot, cost us investors because we wouldn't work in China or in Russia. It cost us sometimes people. We didn't want to work at Palantir. But then you also have a coalition and this is actually what I'm not related to people here. But in the defense establishment where we play a role, quite frankly, there are very few providers of software that's useful and everyone else wants to have a debate about how dangerous they are. Let's just debate it and debate it and we can implement these things in five years. So like in that, that we have to avoid. And again, my view of our company is very dangerous, very valuable. One of the things I do really like about it though is that for commercial enterprises, it gives you the ability, if you're adaptive, to outmaneuver everyone else. And the industries that are going to do that most effectively are largely going to be in America because American industry and its executives are just very, very pragmatic. If I can change the margins of my business, I can understand my business better. I can implement the cultural and knowledge advantages I have because I developed a way of building my business over the last 20 years better than anyone else in the world. I'm going to do it tomorrow. And that's just enormous advantage. And that's quite frankly why this audience is packed. And so I think that's just something we have to run towards and that's what we're doing as a company. You mentioned pragmatism and the implementation of software there. And I think maybe I started with a question around extinction because I'm a pessimistic person. If you're trained as an economist and you work as an Intel officer, you spend a lot of your time thinking of how things can go wrong. I think software engineers by and large are optimistic people. You're going to build something that doesn't exist for the first time. Well, they're optimistic in the long term and pessimist and you tell them what they should do. It's going to stay in transition. But yeah. And maybe the synthesis of those two things I think is realism here at Palantir. And the reason I have stayed here this long is we spend a lot of our time I think in that synthesis of taking the optimism of that software and putting it against the pessimism of these problems in the world. Where are you most excited about that combination? We are software that allows you to identify adversaries at a high level and we constantly caution not to say much except for that the Ukrainians use our software. Change the course of history. Demonstrurally. And software that, you know, we built 20 years ago. Change the course of Europe because we stopped terror attacks while protecting civil liberties. Software that we're now rolling out will change the trajectory of the U.S. economy in a very positive direction. And I, you know, I'm not. There certainly flaws in the West but we are the most, the best group of countries and structures that this world is ever known. And we have now technologies that will allow us to lurch forward. And we have a cultural, we have cultural and training biases in this country that are tech-friendly, pragmatic, able to implement things. Very high level of technical competence inside organizations built up over the last 5, 10 years. Super willingness to bring the best town in the world. And that, one of the things that's, one of the things about large language models that is just really cool is that for our partners is it, it, it, it's like many of these things are horrifically unfair but it's going to make places that are already strong, pragmatic, have specific ways of doing business that are quite valuable. It's going to allow those industries to lurch forward very, very, very quickly. And, and we haven't, you know, we, I've been at this for 20 years. So, like, without, you know, like the products we built on, you know, we built products for Intel, products for special forces, products on identifying adversaries. And none of them have the ability to transform a whole economy like this and, for what variability in the hands of very talented people. Ethically, legally, safely. But, and it's doing thing also is that, you know, we've, and this is more academic, but we've been in the trenches, it's like one of these things, no one ever believed we cared about civil liberties, but we made a ton of money caring about civil liberties because you have to, you have certain architectural, from a technical perspective, civil liberties means, you need a branching extra structure so that you can segment who sees what, you need access control so that you can see, you can verify who sees what, you need the ability to do that dynamically, you need the ability to impose what objects and a mean to each other. So what we call an entology, you need the ability to write against that where you only write against the segment part of your data. But now, in the LLM context, you can think of that as just a way to process something that is moderately useful to very useful into something that is crazy valuable. When Shams is going to show you this in this concept, this thing we built called agents. But all that processing, all those things about like academic data protection, they're really just like taking an unrefined product, moving it into a refined product and making it deadly. And to see that something that looked philosophical became valuable in the anti-terror context is now deadly in the AI context and can help people transform their businesses very, very quickly within the context of how a business actually runs. So you have proprietary knowledge, you have data sets, you have things that actually regulate, you have things that you do not want to share, you have some things that you would expose to a large language model and other things you wouldn't. You have areas where the large language model needs tooling, you have areas where it doesn't need tooling. You have areas where you can accept 80% accuracy in areas where you can't. You have specialized knowledge in your business that even you find it hard to articulate. Like, why is America and Silicon Valley and just in general this culture so good at building enterprise software? I don't know how to articulate that, but it's very, very hard to explain our selection and building products and like, but it works. But getting that specialized, not how do you manufacture something very complicated that one company manufactures very well, but another company doesn't. How do you actually take all those insights and roll them against your business while being able to drill down into those insights so that you can make sure that the decisions being made are actually ones that you would support, not just ethically, but from a business perspective. And all that comes down to things that we've built that are actually in demand and that we don't have to convince people are valuable because they are just valuable. So that is super cool. When you think of that transformation of the software through those gates and delivering that value, you know, last month in Copenhagen you were giving a talk. And I think you've got a question which was, you know, is the west ahead of adversaries in technology like this? And if so, how far ahead? How big is that lead? Then you mentioned in your answer that yes they're ahead, but the issue to work ahead isn't other people catching you from behind. It's Western governments not being able to move as quickly and efficiently as they can. You talked about budget appropriations and programmatic things. For this room and most of our audience today that's in the private sector, what do you think that acceleration looks like on the commercial side and maintain? Well, again, I think what everyone in this room is going to do and what I think people already have done and one of the coolest things I've ever seen in the history of Palantir is you go next door where these demos are and we're showing off our product and we have current partners showing other partners how you do this. This thing about software that was always true is it's all BS until you try it. It's just, it's like, you know, I was constantly asked what makes Palantir different than these five other companies. I don't know. Go try all of us. It's like, it's just, it is just try. Why don't you have a payment strategy? Because I know our partners, future partners are smart enough to pay us a lot of money if we create a lot of value. How do I know it will work? Well, we can show you it working and we can show you how valuable it is and what it basically means in the government context you have this problem globally. That 98% of software spend goes to people building things by hand that take five years and maybe then take 10 years and then it take 20 years and beyond that, that's just not how software is built at a world class level. You can't have security if it's not a product. It's like, well, how are you, and it's very hard to do these things but it's definitely not going to work. And this is not just, this is not just America. This is everywhere. And then you have a lot of places, you know, one country doesn't want to buy from another country and quite frankly many of our allies have a problem that all the products come from America anyway that works so like how do you explain that? In a commercial context it's just very, it's very different. It's like we have a problem, Palantir has, you know, in the commercial context, multi-year, 10-year reputation for delivering very complicated systems that have worked across heterogeneous industries. Great. We're going to take, they're making some pretty bold claims. You're going to say great, if those bold claims are true, we want to see it and then you go and test it and then we enter into a relationship after you've gotten value. And the only thing I would say is this is kind of obvious and but where it's not obvious we as a culture have to make it even more obvious because on paper AI sounds like it's very hard to know it will be valuable and enterprises have very complicated internal technical challenges that are now being exposed. So one of the very advantageous things for us is AI will pen test your whole enterprise. So you can use our products but the stronger your enterprise the more value you're going to get. So that's like, so you're going to see this and try it, get value and then the next question is well how do I get even more value? And that's just a process that it's not theoretical. It just has to be tried and proven. Maybe we should go to questions. Yeah, I was going to say let's take some questions from the room. Or we could just talk about extinction. There's always one person who has like five questions so that person should ask one. We have our long-term advocate here. Friend, ask a question. Yeah, you. I don't know. I want to ask a question. Okay. Okay. I'll ask one more while we. It worked. I will ask one. I didn't know you were looking directly at me. Put it me on the spot. I mean, I'm representing one of these, but there's historically places in the world that have not had similar values to the West or to the United States. And sometimes they're aligned. Sometimes they're less aligned. And bringing something that delivers this kind of power and this kind of insight and efficacy into those markets. How does Palantir look like? Or how does Palantir look at that? In terms of like you're saying, bringing some of these Western values and the benefits at the way we think in the West, give us this kind of advantage. How do you look at bringing some other places that might necessarily not always align with us, bringing those kinds of capabilities to bear to actually help us in the long-term, deliver the values that we really want everyone to share? Well, you know, it's interesting. I've been asked this question a lot. But I have a select, I don't actually know the real answer now because when you see what we're building with these agents, it's really scary. So it raises the threshold of where I, so the agent basically, it's a charm, we'll show you this, but it takes the output of an LLM, creates it in a hybrid algorithm and allows you to run it passively, meaning all the time against your whole enterprise, and depending on the quality of your security, you can segment. But it's still, you can see how that could be easily abused. And I do wonder if that should be sold to local law enforcement. And so I don't know. In the past, we've always been, like, I'm not, I'm in no way in Neocon, honestly. I just think we have the West, we have the Cor West, and we have allies, and we have customers all over the globe. And if they're on our side, I think we should cut them slack, and if they're not. But slack doesn't mean everywhere. And we always have these ongoing discussions, and we've refused to work with lots of people, and it's cost us huge money, and I've been yelled at, and quite frankly, if I was fireable, I would have been fired many times over this. And I still am, everyone's fireable, but it's a little harder because the alternative to me is an engineer. And nobody, nobody, everyone's afraid, even with our products, we'll have no revenue. So it's really hard. Like, wait till you see Sean Stem out, it's like that. I'm sure we should sell this to the US industry. I'm sure we should encourage client-destined service, special operators, current clients, the US military, the five eyes. I'm sure we should give it to them. I think we're going to have to have long discussions about where else, because you know, it's like you don't want to have something that could, you know, we've been in the business actually of protecting everyone's right to their own liberty, which also means your own lifestyle, your own secrets, your own personal proclivities that are yours, your health records. And I think that's one of the things that makes our society so special. So there's a lot of new thought that's going to have to go on about this. But in the near term, if you're a US industry, industry in Europe, client-destined services in the West will definitely sell it to you, and we'll have to think hard about everyone else. Other questions from the room? Yep, one right here in the front. There's no shortage of problems in healthcare, and now that you're kind of getting under the hood in healthcare, how do you see foundry transforming the whole industry across the different hospitals across the whole spectrum? Well, thanks to the great work of two people are here, and others where we power, I think 13% of hospital beds in the US. Those use cases are super intricate. If you just look at foundry, the use cases are optimization. How do you take scarce resources and disperse them in the most financially beneficial, but also ethical way of a million hospital beds, as you have a million five patients who gets them under what conditions. That is both economic and philosophical moral implications and legal implications that you can deal with in foundry. You also in the hospital industry, and this is before you begin to integrate AI, you have highly trained workers, nurses, doctors that need to be involved in the judgment chain. And so how do you do that and then do it systematically is a classic foundry problem? I think you're also going to see that given the way we can manage data in a completely transparent way and show the transforms, meaning how the data is joined in a transparent way, that that industry is going to be ideal for a volunteer and AI. Simply because of certain optimization and knowledge-based transfer issues, so not everything in nurse understands or doctor understands should be transferable to an AI. But some precursor decisions that can be evaluated should be just in the same way in other contexts you identify and then have a hand over to a human. But that can only be done under the condition that you can actually see how that was done, even simply for legal, ethical, and reputational reasons. And you also have the other reason why software is so important in that industry is it's margin challenged. So if you have a margin challenged, meaning the industry or a resource challenge industry, that is with complicated engineering and societal variables, that is something you need software for. And that's why our software has been so impactful during the COVID epidemic, why it's the, I mean, we barely had software sales into the hospital industry a year ago. It's just going like that. But it's going to, you will see where you begin to integrate, it's going to be very hard for other people to get in. Our products ideally suited for that plus AI because just purely, you know, one of the big concerns in the hospital is litigation. So it's like, I brought this patient in. Okay, great. I'm going to get to you either way, but like, like, you need to be able to show, well, this is exactly how the decision was made based on these data sets. That requires a branching architecture, ACLs, and ability to do this transparently, ability to show how the data was organized, meaning the transforms. And then if you're running AI on top of it, you're going to have to be able to unpack that in court, which we do natively. And so, and then one of the valuable things for us besides helping hospitals, which is incredibly valuable and gratifying. And my father's a doctor. So finally, might get some respect at home. If, is that it is a much more intricate, difficult use case than people realize outside that industry and in a high lights what, what where product work and where, where it doesn't. So we also have an invested interest because we can show off, okay, these are the very complicated issues that, by the way, you're also going to have if you're building an engine or drilling for oil and gas or if you're doing pharmaceuticals or if you are organizing building water plants or if you are, if you are doing really anything that involves the convergence of complicated engineering and regulation, which is basically every industry in this country. But this one particularly highlights it. Partly because of the challenges on the resources and partly because of the ongoing litigation challenges. Oh, we'll just repeat that question for everyone. Just to repeat the question for those listening to the stream. The question was putting aside the remark about Ganesh, a colleague of ours. Who is the main person in the C-suite that you think is the- Well, no, I think that part of it is like say there's resistance in the org. The real answer is it just depends on the org. You know, we have partners here where the CEO wants to get involved in that, in technical decisions. We just need somebody who has the authority if they see value to push quickly. And so in some more, some more exists this, that's the CFO actually, surprise, in some more exists the CEO. Usually it honestly ends up being a coalition of like somebody who's got credibility. By the way, sometimes it's not in the C-suite. I mean, I see this all the time. We got our company off the ground because special operators went to the generals and said, yeah, you may not like that guy, but he's bringing this home safely. And the generals were like, yeah, I don't like that guy, but if you bring him home safely, I will get by your software. So, and that's a classic pound here. The AI thing has just shifted this though. It's like a year ago the answer would have been two years ago to have been CEO or it doesn't work. A year ago it was like mostly CEO. Last time we did this conference, I guess, was a couple months ago, it would have been like 70-30. Now we have just a lot of very technical people in the technical part of organizations saying, okay, I'm going to do this. I have these five highly technical questions which largely, you know, you'll see it being answered, but come down to, you know, safety, security, understanding the limits of LLMs, understanding where they have to be augmented, those kind of questions. And if you can answer those questions and more importantly, show it, they're off to the races. So, it really, really depends. And it also depends geography to geography. One of the things that's made America very successful for us is more people can make these decisions. So, when we're in Europe, it really has had to come from the sea suite and then we've had a lot of resistance. Then you also see, even in government, there's huge differences. Special operations work different than Intel, which works different than military. And in some of these cases, it's a very disparate. You can work with one part and the other part you can't work with. But again, you know, we constantly get asked by experts, meaning I probably shouldn't say this, but I could have built a business. I should have built a business. I could have gone to hedge fund. But now I am an expert on software analysis for, and I rate the software products and decide how valuable they are for Wall Street. And they always want to know how valuable, how big is the TAM? And it's actually quite hard to calculate it for us. But one of the things that has made the TAM much bigger in the US is more people can decide to say yes. Much more. And in the AI context, it's really, since we're on the frontier, and everyone knows we're on the frontier, it's, one of the really cool things is, the first time I've seen a market, maybe since we've built our Intel product, where everybody knows we're on the frontier, and therefore it's like, okay, there's no playbook. This really helps us, because when there's a playbook, maybe we disagree with the playbook, which we often do. Like software needs to do these four things to fit into our architecture, or we're not going to buy it. So that's really slow, foundry, just growth down, because we actually have a different view. Our view is that it should be category defining. Meaning you should be able to answer these questions independent of what an expert says software should be like. Because someday you're going to have to ask and answer and write to your enterprise under difficult conditions, questions that you're not asking and answering tomorrow, and you're going to have to be able to do it in a way that's not just data science, but is algorithmatic. We've always thought that. We lost a lot of those battles. And even though foundry, basically foundry grew 67% last year, in a world that was more frontier probably would have grown three X of that. And so now in the AI context, there really is no playbook of how it should look. People just want it to work. And that's again one of the main reasons we've had more inbound for Palantir in the last couple weeks than we had all last year. And it's precisely because the playbook is out the door. Everyone knows this. This could be very valuable if implemented correctly. Everyone knows if it's not implemented correctly, you're going to get some poetry. And it's going to be expensive. And or, yeah, so that's very different. Great. I think, thank you all for the questions. I think this is a great introduction of what we're talking about here and what that frontier will look like. Any other closing remarks? Thank you for coming. For those of you who need to palantir, you've picked a great time to come. We've never had a vibe this good. It's been pretty good in the past, but it's not like this. So I hope you enjoy being here as much as I enjoy having you here. And hope to see you soon. Thanks. Thank you. Please welcome from Palantir, Chief Technology Officer, Sham Samkar. Morning. I am so excited to be here to launch AIP. This product we've been working so hard on, in my almost 20 years at Palantir, I've just never been excited about what we've been building to this level. It's not just the impact we've worked on, tons of impactful problems. It's really the speed that this impact is going to be happening in here. So AIP is really our core set of technologies that are designed to bring LLMs to your enterprise. To supercharge and accelerate your experiences. Starting from integrating data, highlighting your ontology, building AI-enabled applications and even AI agents and co-pilots. AIP enables you to deploy LLMs anchored in your data on your private networks. It enables safe handoff between the tools in your enterprise, the actions, and other AI models you've already built. It enables you to govern and control this so you ultimately have deep trust in the AI. This moment, I mean, the AI technology is going to be massively disruptive. It's absolutely a case where the dynamics here are winner-take-most if not all. So be the winner by disrupting first. And as I've been thinking about this, I've been thinking where is the value likely to accrete? And I believe it's going to be in the workflow and the application layer. And that should be quite exciting for all of you here. And that's because the models are already commodities. The pace here is accelerating and exhilarating. This slide, I made it a few weeks ago, it's already out of date. If Alkin has been released with an Apache license yesterday. So we've gone in less than two months from Lama to Alpaca to Vikunia. We've gone from GPUs to CPUs. We've gone from massive cloud software stacks to running these models on a Raspberry Pi. So the editorial from this, what does this mean? This means that you're likely going to have a menagerie of models, not a single model. And you're going to be able to cheaply customize and tune these models to your needs. It also means that the biggest, baddest model is not the one that's most likely to win. It's going to be there's this gold elox of powered iteration speed. What is the right sized model that you can iterate most quickly on? And the reason that's the case is that LLMs alone are not enough. You need tools, actually they need tools. For example, they need a tool that will help calculate the enterprise profitability of an account. Or compute the forward looking inventory for a specific product. They need access to an action registry to execute operations across the enterprise. They need access to a semantic layer with rich objects and links to actually define the proper grounding and act as an anti-holucinogen. And sometimes this is called retrieval augmented generation or rag. You probably have heard that term a few times now. It also needs access to a branching environment, something Dr. Carp was mentioning, where it can actually stage proposals or edits to the world for humans to actually review. So AIP comes not only with an incredible set of tools, but it comes with a tool factory that you can build your own tools to augment them and make this maximally useful in the context of your enterprise. How do you get an LLMs to post and invoice a NetSuite? You need to build a tool for that. Or how do you reallocate inventory and SAP? That's what AIP really empowers here. The vision here is really this kind of cyborg enterprise, really imagining human and agent teaming that business processes are managed by an army of human agent teams that employees oversee the AI and the AI's recommendations. Your enterprise is moving at machine speed. Let's build that enterprise together, brick by brick. Let's start with data integration and really an entirely new paradigm for that. When I was young, Whizzy Wig met what you see is what you get. I think now it really means what you say is what you get. You can move much more quickly building things by simply saying what it is that you want. So let's start by transforming some of these data sets that we see here. Very clearly, I can see what the AI does and does not have access to. In this case, it's just the metadata. So I can select the data sets that I would like to transform, and I can simply say something like, give me all the claims from the West Midlands. I can say that in English, in German, or even Ukrainian. And what I get back is a series of transform boards that I can easily inspect and make sense of and see what is the AI doing. I can ask more complicated questions. Give me the unique landlords with open cases and constructed GeoPoint column that has latitude and longitude. So I can visualize these items on a map and verify the location. So if we fast forward a little bit and we assume we have a more complicated looking graph here, and I'm new to it, I can actually ask AIP to explain to me what are these transforms doing? And you think about how that's going to transform how you do documentation, how you do change management, actually the comment, and a code commit when you're changing your pipeline itself. But why do I need to say anything at all? If I have my target ontology here on the right, and I have the data sets I'm trying to integrate on the left, why can't I just select it all and ask AIP to connect the dots for me? And what we will get back is a series of builder boards, which we can very clearly see with the purple annotation with AI-generated content that I can step through and verify as a human that these make sense to me. AIP is your AI operating system. Every operating system has a command line. AIP is terminal. With terminal, I can easily interact with all of my enterprise knowledge and my enterprise applications through a large language model. Let me show you that. So we start off in our supply chain control tower, and we see that we have a new notification about a disruption to our Vellanore Distribution Center. So this email is coming. So why don't we open up terminal, load up our distribution centers, and start by simply saying I received this email, we'll paste in the content of the email, and then we'll ask to visualize the order statuses that are impacted by this context here. And what you can very clearly see on the right-hand side is the handoff review. I can see both the chain of thought and the chain of tools that AIP is employing to answer this question for me. So it's interpretable, it's understandable. I get back the visualization. I select just those that are waiting for shipment, and I can drill down further into this. So the relevant question I think now is maybe to figure out what's the revenue at risk here? So what's the total value of my high priority orders that are impacted by this distribution center disruption? Again, I see through the handoff overview how AIP is breaking down to answer these questions, how it's employing the tools that we talked about earlier to solve this for me. $13 million. I can see all of the objects I have access to here. You can kind of think about this as like LS at the command line. More importantly, I see all the tools I have access to. Not only the tools that are native to AIP, but also the tools that I've used the tool factory to custom build. So let's call one of those ML models now that I would like to run an order reallocation model that is specific to my enterprise. AIP will find it, bring it to me, and allow me as the human to go execute that model. So we get the results of that, but this is not the way to look at it. What I want to do is I want to look at this in the context of my operational applications. So I ask to open up my operational inventory allocation application. And I can see I have 53 high priority orders with $13 million at risk. I can see on the map the distribution centers I'll be drawing inventory from. And on the right, I see the actual edits to my inventory plan that's being proposed to me. And from right here, I can take this operational decision. So I've taken a problem. I would have taken me 300 minutes this all and solved it in three minutes. And with AI agents, I will show you soon how you can solve this next time in three seconds. But you don't want to live in the command line all day long. You want to be able to create on the Rails workflows for your enterprise users. And you want it to fit them perfectly. You want to be able to adapt those workflows to their evolving needs. And you want to do that by simply just saying what it is that you want. So how did we build that supply chain control tower application that we started terminal with? Well, by asking for that application. So if we start here, we provide a description. I would like a supply chain application that allows me to look at manufacturing plants, distribution centers, customers, and some other metadata. And this gets me 80% of what I want. I get the scaffolding of my product generated for me. Now I want to add some metrics to this. Let's look at OTIF. Let's look at monthly sales, deliveries. And I can get the widget created for me. Now this is not an application. It's a dashboard. Do you think, then, I have a supply chain problem. I can see it, but I can't do anything about it. The alchemy of AIP is to be able to change that simply with a single spell to ask for a button in the header that will allow me to reallocate my inventory. So let's do that. And we'll see the blue button, the pure, and the top right. But how is that working? It's obviously not magic. This is a concrete manifestation of a tool. So if we go to the ontology and we look at the management application, I can see I have this function, reallocate product, that takes an Atari and Source Distribution Center product ID and amount to reallocate, and that it triggers via a web hook a call and write back to SAP. This, again, is a concrete manifestation of a tool. In this case, a human is clicking the button to employ that tool. But this is a little bit of foreshadowing where we will see how we give this to an LLM to supercharge our enterprise. OK, wizzywig applications. Is that what I want? Because I think what I want is a wizzywig enterprise. I want to build an army of AI agents that do what I say for me. I want my employees to become managers of agents who review AI-generated recommendations. I don't want to be 100% better. I want to be 100 times better. Let me show you how. Let's build that together, brick by brick, starting with AIP logic. So here I'm going to build a new function. And the input to this function are going to be these emails I get about my supply chain. And then I can add a logic block. It could be a Python logic block. It could be a Java logic block. But let's make this an LLM logic block. And I will pass into this a prompt, which is both the content of the email, but also a task to read this email and extract locations from it. And I will define my output of this function. It's a string array of locations. It's called locations. This is an integrated development environment. So now I can go run my function, create some mock data around a hurricane coming in Southern Florida, and test and see what is this function able to extract from me here. How does it work? So let's run it. And we'll see we get back Miami and Florida, Adale. And we can open up the debugger to actually step through and see the interaction between my code and the LLM. And what are the prompts I'm sending? What am I getting back? How is that working? So great. But this is not what I want. I don't want string locations. I want to know what distribution centers are going to be impacted by this storm. So to answer that question, we have to give the LLM its first tool, the ability to query the ontology for our distribution centers and a prompt of how to use this tool. Use this as your location data set. And then I need to change the output. I no longer want strings. I want object references. I want an array of distribution centers as the output value. It's strongly typed here. So let's make that change and rerun our function and see what we get back. As you'd expect, we get distribution centers. You can hover over them. You can see these are rich objects that are defined, the semantics of my ontology here. And now the debugger is substantially more interesting. You can actually see the call and you can see how it's employing the tool of calling the ontology service to go figure out what distribution centers to return as answers. You can't make these up. This is a retrieval augmented generation. But I don't think this is what I want either. What I really want is the LLM to help me figure out what to do about the inventory shortages that are caused by this disruption. So let's enable that by adding another LLM block here. So we're chaining our logic together. And I'm going to pass in the email, the locations from above, and a new prompt to use these tools I'm about to provide to determine how to resolve the shortage. And so we'll go through three tools. The first is Reallocate Product. We saw this tool earlier in the supply chain application and a prompt of how to use this tool. In addition to that tool, we're going to give it two more tools to calculate the shortage KPI and to get realizable inventory. Now I want to change the output type as well, though, because what I want back is a scenario. I want an AI recommendation of edits to my inventory plan that I could consider making. Now when we run this, we will get back a rich set of edits to the inventory plan, a scenario that I can evaluate. But the debugger is substantially more interesting now. The first block here shows us where it's getting the distribution centers. And the second block shows us repeated calls where it's how the LLM is invoking different tools, the return values of each one of those calls, the chaining of these calls to ultimately arrive at the solution and to provide me this case. I can save that as a test. This is a unit test. I've expected input, expected output. Now I have an ability to regress over this model. If we also have the full telemetry, if you allow me a cooking show moment, say this model is, this function is run in production, 5,000 times or so, I can see every production run of it. I have the full trace of the debug log. I can, for example, select just the times that we call the Reallocate product tool. I can select a single run of that and see what happened. Walk through the trace. I could save this as its own unit test. This is how you build fundamental trust in these LLM functions. It's how you ensure quality. As you upgrade your model or model version is changed over time. The final part of this, though, is to turn that logic into an AI agent. So let's start by defining when I want my agent to run. On a schedule or when a new email object is created, which would be the case, select the object type, and I connect it to the email alert categorizer we just built. I set up who has access to even approve the AI-generated scenarios here. When we put this into production, we can go to a live view where we actually watch as the human agent team, the agent's processing objects as they come in. I have full access to the chain of tools that the agents are using. I can actually view the suggested AI edits in the context of the operational applications to make well-informed decisions. And I can switch to a view to see and manage my agents overall, the process view of how many agents do I have running, what process is really working on, what is the historical performance of these agents. And there you have it. Brick by brick, we built this cyber-e enterprise with AIB. What you say is what you get. I think LLMs are going to change every aspect of user experience and software. So in addition to sharing what AIP is today, I also wanted to share a little bit of the sorts of things we're working on, how we're thinking about user experience in the future. We have started to experiment with cutting-edge approaches to UX that deeply integrate LLMs, ontology, and agents into your AI operating system. So let me show you some of those concepts. So we start here, and on the left, we'll have a panel that has the ontology agents and logics directly accessible. And on the right, we have Leo, our AI co-pilot, that not only allows us to ask questions, but more importantly, wields the applications itself. I want to create a new work plan. Leo tells me the first thing to do is data integration. It opens up the pipeline builder application for me. Through the ontology I can directly interact with. On the left, I can see the objects and their relationships in the context of the apps here. I can ask Leo to bring the new data to bear both from the ontology side and the data sets that I need to integrate and use features that you've already seen to, for example, select this and ask AIP to connect the dots. I very clearly can see what content is AI generated. And I have the explainability. I can step through, step by step, and understand how this problem was broken down. And that trust is a core part of the concepts around human agent teaming here. So now I want to deploy this. So now it will open up a branch, a proposal. It will allow me to submit that to compare the depths between the old and new pipeline. I'm getting workflow assistance from the agent now. And then once I push this production, it will move me to an operational view where I can actually drag my agent to the business enterprise conbon process to start the automation. Through Leo, I have full access to see what does the agency, but on top of that, through what you say is what you get, I can build entire new widgets to help me in this context of human agent teaming see more and make better decisions. At a glance, I can see what data the agents do and do not have access to. And I can view the guardrails and the rules and security around any one of these agents. And I can also view that in the context of the operational applications themselves. I mean, I think every UI is going to completely change. This is the integration layer. I think, I'm very excited about this. I think this is the moment that we should be wondering why should we not be even more impatient. How do we make decisions even faster? How do we think bigger about the potential of transformation of these technologies? We will have boots set up throughout the shire to show you more of this stuff. You can get your hands on it, you can play with it. We would love to ideate with you. Thank you all so much for joining us. Applause. Thank you. Applause. Applause. Applause. Applause. Applause. Applause. Applause. Please welcome Senior Director Engineering Government Solutions at Cisco, Mike Yonkers. It's hard not to want to run up there. I always watch people do that. And I was like, I don't want to run on stage. I appreciate the opportunity to be with you today to explain what we're doing at the company I work with, with Palantir. As was stated, my name is Mike Yonkers. I focus on government solutions inside of a company called Cisco, that's Cisco with the C, the networking company, not the food company, in case that there's any confusion about that. I've spent 20 or so years focused on the US federal government at Cisco and a pre-sale systems engineering role. And about a year ago, I shifted into an IT operations role inside of Cisco supporting that customer. Today I want to share with you, I'm going to try to thread a needle here, and depending on where you sit in the audience, if you support the federal government or deal with regulations based on the US federal government, you'll understand kind of the lens that I'm applying to this. But if you support global governments or operate in other regulated industries, I think this will resonate with you as well. So the needle I'm going to try to thread is to kind of talk about some different problem sets that we're faced with at Cisco, and how we're solving them. To be crystal clear, it was only a few months ago that I sat in the audience where you are now, and I kept hearing about Foundry and the ontology, and it turns out I'm an Apollo customer of Cisco. So I mean, of volunteers, so I just want to be clear about that upfront as well. I was at FoundryCon thinking and trying to figure out how to adopt Apollo, and here I am at AIPCon to talk about Apollo, but I just want to be clear about the problems we're solving. So after plenty of years and a lot of money invested from Cisco and me, I can stand before you today and say my purpose in life is service. And I work for a company whose purpose is to create an inclusive future for all. That's what we're doing at Cisco. It is our stated intention to create an inclusive future for all. And I think that's really cool. I love these big aspirational goals. I think they're really important to have, because it's how you rally troops and how you go take on big problem sets. However, I've learned over time, I've always heard this statement in existential threat, and I've never understood it until I really started thinking about the problem sets that were facing myself and my team at Cisco. And what I mean in this context is if I am trying to provide service to the customers that I support, which in the context of this discussion is the US federal government. And if Cisco is trying to build an inclusive future for all, but if we can't deliver our capabilities to our customers, so that they can serve their customers in the environments that they needed in, that is a true existential threat. I supported a team of a couple hundred engineers around the world supporting global governments. And the idea is that we weren't gonna be able to help our customers solve their problems. Ultimately, if you play that out, means that we as a team don't need to exist. That's an existential threat. And I had heard this statement all along, people say this, they're like, oh, we're facing this existential threat. I had no idea what that meant until I started looking across my team and realizing, I don't ever wanna have to lay off people ever again in my lifetime. So to me, very viscerally, it was this, kind of what can I do, what sorts of problems can I solve inside of Cisco? But if you extend that and think about, if my company, if our entire purpose is to create this inclusive future for all, if we can't reach all, then we can't actually realize our own vision. So we found a way to solve this problem, surprise, it's with volunteer. But let me kind of build this out a little bit. And this is where I'm gonna try to thread this needle. If you look at this picture, the kind of logo's in the middle. If you're Cisco customers at all, you might recognize WebEx, you might recognize Marockie. The cloud is our CX cloud, which is something that we're doing to try to provide better capabilities and services to our customers. You may or may not be familiar with that. And then at the bottom is meant to represent the kind of global nature of the company that I work with. So the government services and solutions that I'm now responsible for providing inside of Cisco are global in nature. They're not just focused on the US, but the US government is where my background is, so that tends to be where I kind of talk through these use cases. But if you think about this, there's kind of Europe on the left. Think about things like GDPR, data sovereignty, types of problems. There are issues there that need to be solved for. That are challenging if you're a company like mine who wants to provide cloud-based services to our customers in Europe, but we're a US-based company. And if our data resides in the US, and that becomes a problem for our customers, right? In Europe. And then the middle is kind of North America. We can bore you to tears with US government regulations, be they actual federal government regulations as it applies to the government itself, or the regulations that they push forward into these other industries that we all have to deal with. And then on the right is Australia. And I put that there because part of my heart is in Australia right now. My youngest son is doing a study of broad in Australia. But the point is we have actual legitimate use cases that we're trying to solve with the Australian government, which kind of proves the point that I'm trying to make here. But if you think about this, multiple cloud offers, I'm just representing three, of which we have a bunch inside of Cisco in this picture, as represented by WebEx, Marockie, and CX Cloud, going to multiple geographies, and then inside of those geographies, multiple sets of regulatory requirements that we have to meet along the way. This is an incredibly complex problem. And the question over here was asked about it, what level of the company do you have to be engaged to kind of push these things forward? I'm a few steps removed from the C suite inside of my company, but I could tell you this is a problem that the C suite of the company that I'm working for is trying to solve. How do we drive this inclusive future for all? Meet the demands and needs of all of these customers in this world of sort of economic nationalism. That's another one of my favorite phrases that I never understood until I started having to live it. You know, how we solve in these, right? Because the idea, the whole promise of cloud is, I could build something where I want to build it and run it on behalf of customers. And the customers don't have to deal with that problem set anymore. But if we can't meet the requirements of where we want to take these solutions, then we have a real problem. And one of the ways we could meet these solutions, and maybe some of you guys try this, is just build separate environments everywhere you want to go. So let's take a solution, we'll pick on Cisco WebEx, and let's think about this. If I wanted to build WebEx and meet the United States government, just as itself a customer, it has five different sets of requirements when you look at cloud requirements to meet the United States government. They're classified for the intelligence community, the Department of Defense. There's unclassified for the Department of Defense, but not all unclassified is the same inside the context of the United States government. And then there's truly like sort of civilian services. So in the US, just supporting the government, that's three different accrediting bodies. That's GSA doing FedRAMP, that's Disaduin, all the DOD certification stuff, and then that's the intelligence community doing its own certification stuff. So if you're interested in this kind of stuff, I'm not gonna dwell on these, but if you're interested in this kind of stuff, Google the blog, the Palantir wrote about how they saw for DOD Impact Level 6 or I-Hell 6. It's fascinating reading and really kind of reinforces the point I'm making here today. But the point is, we had to figure out a way inside Cisco to separate product development from product deployment. So I can't, there's not enough time and not enough money in the world, even in a big company like mine, to go build bespoke solutions. To the order of five, just to meet the United States federal government requirements, I haven't even touched private industry inside the US, and then you extend that globally. There's not enough time and there's not enough money, and there's not enough talent to go do that. So I've spent the last six years ranting and raving about DevOps and the notion of crashing together your development team and your operations team. It's awesome. It's culture change, it's hard to get done, but it's really, really cool, and it's really, really powerful when you can pull it off. But the problem is you can't have DevOps teams and meet those global requirements if you don't separate your development from operations. So my head start turning it. And I'm like, wait a second, I've been trying to bring these things together, and now somehow I have to separate them again. I'm gonna lose all the goodness of what we were trying to solve for when we brought development and operations together. We can't have that. So the problem we were trying to solve was logically, logistically, physically to meet requirements, like certain citizens with certain data living in certain places, like those are hard requirements that are given us globally. How do we solve for those in operating these solutions, but how do we get the goodness of DevOps? So the first thing we were trying to figure out was in a physical way, keep development from operations separate. And then the notion was, okay, but one of the cool things about cloud and DevOps is we can build it once and deploy it many. So we're faced with this, like, oh my gosh, like we spent all this time crashing together DevOps, now we're gonna separate them, but we still wanna build something once and deploy it and solve all these problems. So the solution is Apollo, and that's why I'm here today because we work with Palantir, we use their platform called Apollo, and we solve those two problems that I just described to meet our customer demand. This is an interesting kind of picture. It took us forever to figure out how to try to represent the complexity of what we're dealing with in a very simple graphic. But the point here is, at the top, I'm still picking on WebEx because our executive vice president of engineering, security and collaboration, we're taking WebEx and we're driving through this. We're providing WebEx to meet these requirements on a global government basis. The little picture there is this thing called a monitor. The monitor is what you build when you're building out Apollo. It drags along through Apollo, Central Hub is where we register all this stuff. And if we were in a perfect world and everything we're contained and we're all registered properly through Kubernetes and we had all our Helm charts all straightened out, like life would be easy. Life is not easy, right? We're all practical people that's not the world we live in. So we do some interesting things in the Central Hub and then we get this notion of a very hard line. This is where I start to separate if I'm doing classified and unclassified work, if I'm trying to meet localized requirements in the country of Germany, for example. I can't have people back here operating those environments. So it's a very hard line between the Central Hub and then these remote hubs. Now I can meet customer requirements in the remote hubs, but I have this interesting problem, this clock that sits in the middle. I have different accrediting bodies with different sets of requirements before I'm allowed to push stuff remotely. Again, back to my United States government example, I gotta go deal with GSA, I gotta deal with DISA and I have to deal with the intelligence community. All have different requirements, all have different timelines, all have different things they wanna see before I'm able to move things. But Apollo gives us this capability and the cool thing is where I'm in a company where we're figuring this out on our own, we're partnering with a company in PaloTier that's already solved these problems. So I don't have to go and roll my own and figure this stuff out the hard way, I can leverage Apollo and do this interesting thing where I can let the development teams inside us go that are not my responsibility, but I work with very closely, they can do what they do best, they can do their development wherever they are. From a global point of view, they can drop off features, some of our be used business units, deliver stuff on the order of like tens to hundreds of new software drops a day. Let me tell you, if you try to push that inside of a regulated environment, it makes people's head explode when you say, I wanna bring tents off or updates every single day, including weekends across this boundary, that hard line, the accreditors are like, no, try again, that's not gonna happen. But this is what we can do with Apollo, we've separated development from deployment of the environments and then we allow the product development teams to go do what they do best. And then we build service and our site reliability, engineering teams or SRE teams to actually go run these environments that can meet the local requirements of whatever environment is we're going to. Citizenship, clearances, if they need it, and we can kind of meet the requirements along the way. So we end up in this really cool and I wanna say magical place. Now, I am a huge fan of Simon Sinek, if the engineers and architects who I get to work with every day were here, I like to claim I'm an engineer, I have a double E degree and a computer science degree, but the people I work with every day will tell you, I've been a manager and a leader for so long, it freaks them out when I touch keyboards. They actually call me in the context of SRE, they call me chaos monkey, because I break things in ways they didn't expect. I think that's good, they don't see it that way. But why am I here? So Simon Sinek is one of my favorite authors when it comes to leadership. And Simon Sinek says, always start with the why. And I'm breaking that rule because I'm ending with the why, but I wanted to share this with you because I had this opportunity. More than anything, I wanna express gratitude for the Palantir team that I get to work with, and the Palantir capabilities that we're bringing inside of Cisco, because we are solving a real hard problem that I'm convinced is an existential threat to me as an individual and my company as a company. So I was sitting right there in the back row because I'm a back row con guy right in the middle of this audience at the last conference. And I took precisely one note, the entire time I was here. And that note is this quote, I brought this with you, isn't it cool when you have a prop? That note was iterate with a partner you trust. And to me, that's what this is about. I'm headed into uncharted territories and a company that is a massive as the company that I work with. And I wanna work with someone who understands, not necessarily has solved all these problems, but at least understands the problems that we're faced with. So we got a fighting chance to iterate through this thing and go figure out how to solve for that existential threat. So my quote, the thing that brought me back here today and why I'm so happy to be working with Palantir in Apollo as a platform is exactly this. I'm iterating with a partner I trust. And so more than anything, I just wanna express my gratitude to the Palantir team for everything that they've done to support us. If you have any questions about what we're doing inside of Cisco and how we're using Apollo, I'll be around all day. I'd love to engage with people. Thank you for your time and attention. Please welcome Chief Digital and Technology Officer at JD Power Bernardo Rodriguez. Hello? This works. Awesome. So I'm gonna give you a little bit of a show on tell of the things that we're doing with AIP and LMS before that letter of introduction. I think we're gonna have to do this with a lot of things that we're doing with AIP and LMS. So I'm gonna give you a little bit of a show on tell of the things that we're doing with AIP and LMS I think you know JD Power because we give awards to cars. We do benchmarking. We talk to a bunch of millions of customers of mostly OEMs. And then we give awards. So you probably see commercials on maybe the Super Bowl so that's a dance review of the year or the best experience in a luxury car. So that's us. But in reality, that's a very small part of our business. Most of our business is around data analytics. So what we've done the last few years is to build and aggregate data sets that in a way they find inner workings of the auto industry. We, which is a $1 trillion industry, which is a big, big industry. So we understand what cars can be built, what cars actually build, where are they in scent, what cars are sitting in parking lots and the dealers, when are they sold, the price of the soul at, when incentives are applied, demographics are who bothers that, buy those cars. The problems the cars have when they're repaired, warranties, et cetera, et cetera. So we have a complete view of the car industry. And we spent, you know, many years doing things with these data sets. We do some machine learning models, very domain-specific models, traditional models. And we have decided, we decided about a year ago that we're going to get into AI with more conviction. And particularly this year, we've been driving to become an AI first company. So we're happy to partner with Palantir. I think the last light about iterating with our part of your trust is very relevant to us, because we've been learning a lot over the last five, six months. We actually been working together for about five, six months. So why now? This works. OK, great. So what we've seen over the last few months is that even my mother asked me about Charget B.T., correct? So there's a big step in innovation in AI, correct? Things that be coming in a way commoditized. If you go to sites like Hagen Face, there are hundreds of thousands of open source models there to be leveraged. Many other names, some regression models, classification models. Some models have been downloaded tens of millions of times. So now the secret source of AI is not on the models that you can build, but how do you apply them to the data that you have? And as you will see, how you deploy them into applications that can actually move the needle. And again, we have consolidated this data since we have bought many companies over the last four years that because we wanted those data sets to come into the fold, correct? So we bought companies that have inventory data, for example. Six months ago, we bought a company that had data around EVs. So now we have all these data. And we say, awesome, with all these data, and then with AI with all the links, why can we do? And as we look at the industry, a trillion dollar industry, it becomes a very exciting and open field opportunity. Our job with Palantir is not to necessarily focus on efficiencies internally, but actually build solutions that move the needle in the auto industry. Those are our main clients, correct? So it's a trillion dollar industry. Any problem that we saw is a big problem to be solved. So you can think about problems like when you buy a car, correct, and you try to figure out what is a car that you want that you need, where can I find it? What is the right price? That's for a consumer, a big problem. Dealers have to figure out what car should I order? How should I price them, correct? And OEMs have a lot of challenges and opportunities ahead, what car should I design? Which ones are actually built? Where should I send them in the US? What should be the right price? The incentives? And our car is breaking. What are the problems in repairs? In repairs, for example, in warranty, there's about a $7 billion spend today in the auto industry just to manage warranties. Can we move the needle in a $7 billion online, for example? So what we're trying to figure out, we're trying to experiment with Palantir, is how can we use AIP, and again, when I say we're trying, we started four or five weeks ago when the launch, correct? So it's impressive how much we have done, and I'll show you a little bit where we are. But what type of problems can AI help us fall, particularly in LLMs? So let's start with the problem statement that I started at the beginning, correct? I want to buy a car, and I want to, an AI to help me buy a car. So the first thing you can think about is something like this, correct? I want to buy my first plug-in hybrid. I currently have a small SUV, and I think is the right car for me and my family. What models can you recommend to me? So you can think also, I love AI, I'm going to go to Chad Gpt and ask him this question, correct? But unfortunately, if you go to Chad Gpt, and you ask them, hey, when will you last train? It will tell you that it was trained in September 2021. So how can a machine, an AI that was trained so long ago, help me buy a car now? And if you look at the industry, there are a lot of things that have happened in those 600 days before, from the time that Chad Gpt was trained, correct? 600 new models were launched in the industry. 1.5 different car configurations were made. 1.2 million cars in inventory are in each day in the dealers, but 1.1 are sold on the average. And that's got actually getting now higher than we're getting away from COVID. And there's about 2.4 billion dollars a month spending incentive. So how can an AI that was trained 600 days ago help you understand what is the right choice for you now? So we're trying to figure out that. What we're doing now with LLM, what we've done for the last few weeks, is starting to determine how can we take the best that an LLM can offer and map it with the data that we have that is real time high quality data. So I'm going to show you, I'm sorry, so we asked Chad Gpt for the question that I'll show you about the plug and hybrid. And they gave me some models that were actually 2021 models obviously because it was trained that way. But at the end, he said, additionally, checking with local dealerships or visiting a manufacturer website will provide you with the most up-to-date information on the latest plug and hybrid models of the world. Great, because that's the only thing you can say, correct? Can we do better with that data? So I'm going to show you a demo. Let's not start it yet. And a couple of things before the start. One, this is not a consumer-facing application. This is an application that we're building for us to prepare and build that consumer-facing application. That's going to be in our site and it's going to be in the site to some of the OEMs, correct? So what we're learning now is the interface. But most importantly, how do we tell the LLM how to quote unquote behave? How do we put all these things together? And I'll give you some of the lessons that we have learned over the last few weeks. And then second, what is important to us is to understand that the dialogue that a person has with an LLM can go in many, many different ways and can go very deep or very shallow, correct? I'm going to show you here just a couple of questions that a user might have. But then we can talk about what's happening on the background and how that conversation can be extended to many other use cases. So let's start the demo. Cool. So we start a session. We call this session family car. And the user types, basically, the question that I talked to you about in the first slide, which is, I want to buy a hybrid. Can you help me out? So this goes to an LLM. The LLM takes under the stand what the question is about. And then the LLM says, OK, I'm going to look at JD Powers data. And I'm going to find the best answer for this question, correct? So the LLM takes that and gives that to the application. And it says, OK, these are the cars that I found on the JD Power data that I think you will appreciate. Although it would be good for you. But then there's an additional question. Hey, I like this feature that keeps me in the same lane. This is customary language, not technical language. And actually, I don't want to spend that much money. So the LLM takes that. Try to understand the message, go back to the JD Power data, and say, OK, here you go. Here are three potential models that you can take a look at. And by the way, here are the trims, which are specific trims for those models. The customer can select the couple of things that they like. And then we tell the LLM, awesome. Here are the two things that I want you to compare, LLM. And you also say, here you go. So those things that are written there, if you look at it, are basically the reasons why the LLM recommends one or the other. This text is written by the LLM. And you see things like, OK, I got you. It's Lane Keeper Assist. It's great for your family. On the other side, there's a bunch of features that you might like. But it's pretty expensive. You told me you were not, you need to watch your budget, et cetera. And then we tell LLM, please give me a list of the features that you think are relevant on these two cars. Let's find a car. LLM, help us find a car. So LLM goes to inventories and shows you where the cars are. And then just to select the one that you're going to go, this one is a bunch of miles away. But apparently, potentially, it's the best car you have available. And then there you go. Correct? You find your car, et cetera. Again, short conversation, but just keep in mind that the LLM is driving all this. And I'm going to give you a quick look at what does it mean. So I told you this is an internal application. So as you train the LLM, you might tell them things. Like, for example, great. But when you show our car, also show the model here. Or you could also show the payment, the monthly payment, because people don't understand MSRP very well. Show the monthly payment. So what's happening in the background? Very quickly. I don't know if you guys are working founder or not. But basically, here we have the yellow, which is the interface with the customer, with the chat happens. The green things are what makes it possible the interaction between the LLM on all the parts of the applications, the ontologies in the middle. This is where the data is. The data that we think is relevant for this use case. And then the applications on the other side. Correct? The beauty of having a Foundry and AIP is that you can build this really, really quickly, really quickly. So we build this in a matter of days, and iterate in a couple of weeks. Now, the cool thing is then, obviously, we're connecting all the systems, but what about the LLM? How do we tell the LLM how to quote unquote, behave? So you look through a profit engineering. And that also AIP allows you to build that into the system. So this is actually what we tell the LLM to behave like, to do. So you are an AI assistant that provides guidance on someone looking to buy a vehicle. This is an actual instruction. You are friendly and helpful. This is an action instruction. It's kind of crazy, no? Et cetera, et cetera. So that's the first one. The second one is, only in the information of vehicles from JSON, which is the jetty power, basically, data. But make inferences about what the customer may want based on your query. This is actually what we typed as a prompt to build the application. So on the last one, we're telling open a charge of BTE. We're telling them, when somebody wants to compare vehicles, don't go crazy and go back to 2021 and find some stuff, don't do that. Just focus on the jetty power data, correct? So there are more things that are happening here. We're telling them, for example, data on a Vs. So if you can get, we will tell the LLM. If you can get a zip code from the, ask for a zip code, and you can check how much snow falls in that zip code. If there's a lot of snow, think about all-wheel drive and the clearance of the vehicle. If you have a zip code, you can know that the price of electricity and the price of gas. And you can give me a total cost of ownership comparison between plug and hybrid and non. Also miles, for example, you drive a day, et cetera, et cetera. So it's very compelling. The beauty of the system, again, is that on the top, you see some of the stuff that we're doing in volunteer, we have several applications, some of the applications are out in our clients already. We basically have data flowing all the way to an ontology, and then applications feeding that ontology. One of those applications, for example, is an application around repair analytics to understand warranty costs and optimize warranty costs. So what we're doing now is an application used in LLM that will take verbatim from repair. Every time our car is repair, the technician in the dealer writes, this is what the customer told me, and this is what I found and how I repaired it. So you have hundreds of thousands of those, millions of those. So if you're a system engineer trying to focus on how to minimize warranty, you want to understand root costs. Why is this failing? At what speeds? At what temperature? What are the behaviors? So we believe in an LLM, that application that is powered by LLM, that will allow us to do this. And this is really real. I mean, we'd present this to a client in two weeks. If we get it right, once we're convinced that it's right, we'll deploy as an application to our clients. Few things that are really critical for us, like the slide of the previous talked about is speed. We need to be able to do this fast. We need to be able to not only take things to market pretty fast, but learn really fast. And the iteration cycles here are not measuring month or weeks or days. This is about every hour where we're learning things about how do we train LLM's and how do we understand how do they behave and how to leverage their insights, et cetera. Extensibility, we need to connect every single application, every single model that we have in our platform to an LLM driven experience. And the last two are completely fundamental for us. We have our data, is our IP, is the value of our company. The data that our customers put in our systems is absolutely critical. So this has to be bulletproof. It has to be very secured in privacy or governance are really must for us. Finally, the road ahead, the first one we have done this for a few years. So we bring data analytics, and we do domain-specific models. Now we're leveraging LLM's to integrate into GD Power data and also bring all the models to provide new experiences. We've been working on that, and we're actually releasing applications in a couple of weeks. And ultimately, what we think in the challenge is how do we build intelligence that actually understands the auto industry and can tackle fundamental questions. And that is combining LLM's with domain-specific models. And we're even arguing, should we train our own LLM to be able to be more nuanced about the discussions that we have in the auto industry. So, run our time. I want to thank the Pantor team, great partners, Taylor, Suzanne, Jan, various, all those guys that have done amazing work. A lot of respect and appreciation for the work. And looking forward to the next few months. Thanks a lot. Applause. So, thank you. Please welcome Chief Digital Officer at Cleveland Clinic, Rohit Chandra. That was pretty cool. Now we know where we start shopping for a new car next. So, my name is Rohit Chandra. I'm the Chief Digital Officer at the Cleveland Clinic. And I'm going to tell you a little bit about the work we've been doing with Palantir for the last couple of years. A little bit of background on the Cleveland Clinic with a large healthcare system, and our work is all over the world. A large healthcare system, and our work is organized around four key stakeholders. First and foremost, our patients. There's caregivers. There's the organization. And then the communities in which we operate. And from a technology perspective, the approach that we focus on is to make sure that we're working backwards from providing value to one or more of these key stakeholders. In addition to striving to provide the best healthcare possible, we have a strategic imperative to touch as many lives as possible and take care of as many patients as possible. And that's what drives the work that we're trying to do with Palantir, which is how do we improve hospital operations, throughput and efficiency and serve as many patients as possible? So talking a little bit about, I'm sorry, can we go back one slide? Yeah, thank you. So just to give a little bit of flavor for what it takes to operate a hospital, many of you in the audience who are in healthcare will be familiar with this. But just for some backdrop for the Cleveland Clinic, we operate more than 20 hospitals, more than 200 outpatient locations. We have about 300 operating rooms, more than 6,000 beds, and we employ more than 6,000 physicians and more than 15,000 nurses. And we need to coordinate the work of all of these caregivers for a daily activity volume of more than 25,000 outpatient visits, more than a thousand surgeries, and more than 30,000 pharmacy orders. Now, orchestrating all of this activity so that it functions like clockwork is not easy. All of the work in terms of scheduling physicians, nurses, supplies in an operating room, making sure you have an ICU bed, a step down bed. All of these things are complex to orchestrate. And like all organizations, we're a hundred year old organization, we have grown organically, we have grown through mergers, and a lot of this orchestration is done, mostly manual with light assist from technology. But what we're striving to do here is, how can we lean into automation so that all of this coordination is mostly automated and assisted as much as possible with technology. So when we looked at the products in the marketplace, we felt that they didn't really go deep enough in terms of tackling these problems. And so we actually went out and we chose to work with Palantir because we were looking for a technology partner, not somebody who was a domain expert willing to sell us a product. What has been unique about Palantir over the last couple of years is, Palantir is not just willing but is actually thrives on solving the hardest problems as opposed to selling us an existing solution. And this translates into not just willingness, but eagerness to sit side by side with us, spend the time understanding healthcare, understanding our needs, understanding our process, understanding our culture, and then developing solutions from the ground up and literally from first principles. So how did we approach this? There's a crawl walk run approach and let me talk about sort of the first step. As in any complex enterprise that has existed for a while, most of the operational information for the enterprise is littered across a variety of archaic systems. And just pulling that information into a single coherent view that you can actually reason about the product and business concepts is not to be underestimated. And that's sort of the first step that we've taken with Palantir to say, can we bring the information together? Can we construct the views that at least give us an intelligent visibility into what is going on? So that we can actually take actions, make decisions, and drive the enterprise forward. And then I'll touch a little bit later on the things that we're trying to do to go from the crawl to the walk to the run stage. So I'll touch on two areas. The first is capacity management. And this is a screenshot of the Hospital 360 module within Palantir, which gives us a view into bed occupancy across the enterprise. So I know that the screenshot may be a little bit hard to read, but we can now see in a single place all of the beds, the occupancy, we can double click and we can see the beds by unit by facility. On the left hand side, we can see all of the inflow of patients. And patients can come in from a variety of different sources. We have patients that are undergoing surgeries and will come in from an operating room. We have patients that we will admit from an emergency department. There are direct admits. And then there are hospital transfers where patients may need care that may only be available at one of our facilities. On the right hand side, you can actually see the output overview, which is all of the discharged discharges that are planned from the hospital so that you can actually have a view into bed availability across the enterprise. And previously, this information was really hard to get at. So when you were faced with trying to see, do you have the room to admit a patient? Do you have the room to accept a hospital transfer? It just wasn't possible. The other thing that we were leveraging to this one in this view is it's not only giving you a current snapshot, it's also forecasting or predicting which are the discharges that are going to happen later in the day. So instead of discovering at 8 p.m. that you were able to discharge a patient and you actually have a bed, you can actually predict which patients are likely to be discharged earlier in the day and allow you to make a decision because by 8 p.m., it may be too late to accept a new patient. And you can actually have a view into bed availability, including forecasting and prediction, so that you can know which patients you can accommodate and make their decision and actually several patients. So what is the benefit that we get from this? We were able to see about 8.5% more patients in terms of hospital transfers. That's roughly about 9 to 10 new patients per week. Now this is currently this module is live only in one of our campuses, but it's highly encouraging being able to see 9 to 10 more patients per week. The second part is we see a 75% reduction in time spent calculating bed activity. As I showed you on the previous screen, you can actually see all of the information at a level that's actionable and in a single view, as opposed to having to click to five different systems and having to decipher the data. And there's a 33% increase in patient acceptance rate and that goes to our core mission to see as many patients as possible. The second module that I want to touch on is staffing. As many of you may have experienced or may aware of, there's a significant nursing shortage and being able to balance our load across our nursing staff is super important for us. Now this module is giving you a view. Again, I'll try and explain the visuals. I realize the screenshot may be a little bit small. It's actually trying to do two things in a single view. The first is it can show you the occupancy literally by every unit in the hospital. What is the bed occupancy? What is the nursing requirement? What is the assistant requirement? What is the peer requirement literally by unit across the entire hospital? The second thing it will show you is what is the current allocation of staff? So in a single view, you can actually see where you may be overstaffed, where you may be understaffed and what are the adjustments that you can make to actually serve all of the patients and all of the demand across the entire facility. The second thing that we can do is we can base to we can forecast both the demand as well as staff availability over the next two weeks so that you can actually develop schedules that can be 7, 14 maybe as much as 30-day projections to give people predictability in their scheduling over the next weeks. This visibility allows us to make these adjustments and if in the past all of this coordination required multiple nursing managers spending hours a day looking at spreadsheets or calling people coordinating through phone calls from one unit to another to figure out, hey, I'm sure is there somebody, do you have spare capacity? All of that was done through phone calls spreadsheets and without a single coherent view of what was happening across the enterprise. Now the nice thing is that that's module is live, people can actually have a single view on what is going on and the impact is for us is significant, which is we now have 400 plus users who are using this module literally on a daily weekly basis. The time that it previously nurses were nursing managers are spending four to five hours a day just managing nurse assignment and now they're able to do it in 45 minutes and instead of discovering that you need to adjust a nurse from one unit to another a few hours into the shift you can actually do that ahead of time so that you give people a little bit greater predictability and you're able to manage your staffing needs and the enterprise. Stepping back, I think we've now been activated these modules over the last six months across different portions of our enterprise and it has been amazing. Many of those screenshots illustrate how we've been able to drive visibility and increasing automation across how we manage all of these day-to-day operational tasks. It's important to keep in mind though that technology is an excellent enabler but carrying the people, the process is an equally important pillar in driving these changes in a complex business. I'm sure all of you see that in your experiences but for us it's been very important to do this in a way that you actually are able to sit side by side with Palantir, design the tools but at the same time co-design them with the people in process so that they go hand in hand to achieve success. It's not just that you can enable technology and will magically just work. We're highly encouraged by the benefits of automation. Being able to reason, being able to move the conversation from just the mechanics and a litany of data and different systems to a coherent view where everybody's operating off of the same base has been excellent. The walk and the run stage that we're pushing on now is how do we layer in AI and predictive technologies so that we can actually forecast what is happening so that we can plan not just in the moment but forecast into the future. The second thing is we can actually make recommendations. I showed you a screenshot where you can have visibility on where we may be over and understaffed but the next thing we want to do is actually make recommendations so that you can actually simply accept those recommendations for the most part, maybe after a little bit of a manual review. And as we build the confidence, then we can automate some of these recommendations and run a closed loop system. And all of this journey is driving towards increasing tools, increasing automation, maximizing throughput and efficiency with the eventual goal of serving as many patients as possible. Thank you so much. I'm going to give you a hand. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Another round of applause for our first half of speakers. All right. We're going to give everybody who's here with us live, who's here with us on the live stream about 20 minutes and we're going to have a coffee to get some food to connect with each other and we'll see you right back here in 20. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. All right. We've got some incredible speakers left to follow, some incredible demos. Hope you're energized. Hope you're caffeinated and hope you're ready. Allow me to please introduce Justin Herman, CIO of Panasonic Energy North America. Hi, everyone. My name is Justin Herman, CIO for Panasonic Energy North America. I'm extremely excited to be here today. And during the break, I was chatting to a few of the keynotes. And here's a comment thread that's coming out here is the partnership with Palantin and how we iterate with Palantin to create business value. And today I want to take a little bit of time just to share with you the Panasonic Energy North America or Panasonic Story and how we've partnered with Palantin to create value within the enterprise itself. So behind me is one of my favorite quotes from one of my favorite leaders. I won't tell you who that is. I'll let you search that and see if you can guess who that is. But what do we mean by the impossible? What I'm holding in my hand here, I'm sure many of you know what this is. But this is the highest quality, safest, most cost effective lithium ion battery. And a sure of hands real quick, who drives EVs within this audience? Quite a few put their hands up and you're welcome, by the way. They are between 3,000 and 10,000 of these lithium ion batteries in every single EV on the road today. And an industry that has grown exponentially over the past decade. In 2011 they were approximately 22,000 EVs on the road and as projected in 2025 there will be over 23 million on the road. So demand is only growing and we need to be able to meet that demand. So at Panasonic we started our operations in 2016. We shipped our very first cell in 2017. We reached 100 million cells shipped February of 2018, a billion one year later and to date we are shipped at a 7 billion cells. This type of growth is not only nice to have but it's an absolute necessity. So how is this made possible? Well it was made possible by the vision of Panasonic and its leaders as well as our journey towards achieving industry 4.0. Now industry 4.0 is a pretty loose term right? We all have different meanings and exactly what that means. But let me explain to you at Panasonic what that means for us. So at Panasonic when we talk about industry 4.0 we really talk about integrating multimodal data into our manufacturing process. We look at upgrading legacy systems and manual processes and streamline them into more modernized versions of that. Discovering inefficiencies but not just discovering inefficiencies acting upon those inefficiencies. And then leveraging the foundation of incremental value and agility to rapidly scale our capabilities through technology. And through cutting edge use cases we build a framework of robust edge integration that we're unable to unlock key capabilities for our business. What does this all lead to? What is the goal? The goal is to create a connected data infrastructure which drives value. Where we can connect disparate data systems extremely fast and pull meaningful value from these various systems. This means or this leads I should say to quality improvements, safety improvements. And also it frees up the time of our resources to focus on more value added activities. And of course there's always a multi million dollar ROI associated with these types of activities. So where did it all begin? Well we like to reference Panasonic Energy as a 100 year old company that really acts like a startup. And within our culture, within Panasonic culture, we really take innovation and marching into the unknown as a core value and it's ingrained into our culture. And by partnering with Palinter we will further enable that innovation. So right over here is a quote that our president Alan Swan likes to mention quite a few times. And as you can guess that group of 4,000 people is really referencing Panasonic and is pushing into the unknown and building towards and meeting an ever increasing need. So I'd like to take a second and dig into what really takes to achieve industry 4.0. At Panasonic we identified two challenges. The first one being a business value of a speed and the second the smart factory versus traditional infrastructure. So for us developing use cases was absolutely critical to demonstrating key value to our key stakeholders. But investing in impactful use cases can be quite challenging and bandwidth intensive when you try to achieve this in advance of buying. In addition when you look at the factories and the various machines and the variety of timelines that they were implemented in the data sources that is producing, this introduces significant complexity into modernizing. So any amount of downtime for our operations can be extremely impactful. So of course delivering value at speed keeps you current with the industry. But for us it was really demonstrating value to our key stakeholders. And this was extremely important for us. And I recall one or two hundred pounds ago I can't remember the exact question that was asked of Dr. Cop that his response to that was take your timeline and cut it in half. And this was this really resonated with us at Panasonic because that is exactly how we think. And with Palincer we were able to do this. And now you might ask yourself the question how are we able to do this. And I believe the key differentiating factor for us was the ontology itself. So behind you is kind of a little eye chart but this is the back end of our ontology model at Panasonic. And it's taking all the disparate systems and integrating the disparate data into a reusable, highly valuable data asset. To worse the ontology is more than a tool. Right. It's really mapping up processes to create real enterprise value. Other eye chart for you. But once you have the ontology and all your business processes can be contextualized within that ontology you create what we call the manufacturing ontology. And once you have that we can then connect through this any external systems to further compound the value leveraging ontology SDK. So I'd like to talk to you about connected operations and one of our use cases. This use case in particular is in our electro control tower and it was delivered within one month. Actually the first working model of this was delivered within one week. It involved a highly manual process where our engineer would literally take a thumb drive, plug it into the machine, wait for the data, take that same thumb drive, visually inspect the machine, download the data on the machine and then run it through their models. This entire process took about four hours. Within one month we were able to give them the tools that took that four hour process and now condensed it down to 15 minutes with significantly improved data integrity. So five months later what we're looking at from a speech value perspective is not only that one use case we have six additional use cases and these six additional use cases run over predictive maintenance, material traceability, really connecting our operations together and delivering contextualized data within the organization which is driving value to our stakeholders. We have significant more use cases in the pipeline so much so that our team is actually putting in some guard rails to make sure we can meet that demand. To wrap it up these quotes you see on the border actually from our end users because at the end of the day you want your end users to be happy with the solutions and the tools and the data and analytic tools that you're providing to them. This was the reason why we have such excitement within the organization right now has to do with our partnership with Palantin. The teams came together and the most significant thing that I saw throughout this engagement so far has been our Palantin came in and understood our business processes, sat with the operators on the lines, understood their daily challenges and then took that and leveraged the technology to solve those problems. So this helped Panda find value that we ourselves did not even know was there. So in closing I would like to thank the Palantin team for everything they have done for us. Our partnership is strong where our infancy. I am extremely excited to what we will achieve in the future and how we will achieve the impossible. Thank you for your time. I hope you enjoy the rest of the keynote. Please welcome Chief Executive Officer at Jacobs, Bob Pregada, an EVP and president divergent solutions at Jacobs, Shannon Miller. Well thank you everyone. Good day. It is a great privilege and honor to be here with everybody of Palantin. On behalf of the entire Jacobs team I want to thank Palantin for the invite and the opportunity to speak to all of you. Before diving in, I did want to share with the group a bit of a personal story. This town, Palo Alto, has a very unique and special meaning to me. Today as we were walking from the Sheraton with my colleagues down University Boulevard, it was a pretty reflective moment for me. It was reflective from this context. There are three events that happened in this town that have forever changed my own life. The first was I did have the privilege and honor to go to school down the street for grad school several years ago. That definitely did set the course for things that I had the opportunity to do later in life. Secondly, I started off my career in the service. When I finished grad school, I went back to the service. My first job out of the Navy was right here, back in the Bay Area, very close to Palo Alto. That was unique, but that second one really wasn't the piece that was life changing. My younger son was born about three kilometers away from here at El Camino Hospital while I was here. The third, which happened recently, is I had the good fortune to send my older son to school here at Stanford. My quick plug for GoCard, GoStanford, it's great to be here in Palo Alto and I'd love to share some of those experiences as well. So maybe by a show of hands, because I know we have some clients in the room as well as some partners. Who here knows who Jacobs is? Okay, that actually was going to be more than I suspected. So, interesting enough, you know, Jacobs is one of the world's largest engineering and technical services companies around. US-based, before getting into some of the mechanics, I think it's important to set context on where we came from. We started off with deep engineering routes in the chemical process industry and over decades diversified into other markets. But really what Dr. Jacobs started was we're in the business of making our clients business a better business, hard stop. And that's producing outcomes and providing solutions for some of the world's most difficult issues. So today, the end markets that we're in, critical infrastructure, think water, transportation, environment, energy and environment, everything going on around energy transition, advanced facilities, deep domain expertise and life sciences manufacturing, as well as semiconductor manufacturing. And then natural security, we've been in the middle of some of the biggest missions around the world, supporting the US, UK and Australian government. We won't bore you with all the statistics, but needless to say, we're a big company and we do a lot. We do a lot in the world. But what's probably more interesting, and I love the Simon Sinek reference on, start with the why. You know, why do we exist as a company? Who are we? And really is, we are in the middle of some of the most, or the biggest mega trends that are affecting us in the world. And I list the one there, climate response. I heard a statistic the other day, is that it is kind of dark. So bear with me on the darkness and then we'll bring it to light. If you think about the probability of some kind of nuclear holocaust, it is, there is a probability there. I'm not even going to mention it. However, if you compare that to the probability, if we do nothing as a society on solving climate change, or at least slowing climate change with everything we're doing around climate response, you know, that's 100% probability that we won't exist. That's my dark comment. Let's get back to light. So what we're doing is, is we're in the middle from that science-based domain expertise that we built over decades of addressing each one of these issues. And kind of when you go around the matrix and you see it coming down to, what are all of these issues surrounded by in the physical world? Data. All about data. So our partnership with Palantir has really accelerated that effort on taking deep domain science-based experience, coupling that with strong data science and data platforms to really reinvent the way we're solving these issues for our clients. And so some common themes there. I think some of my predecessor speakers spoke to them speed that goes without saying, you know, we at Jacobs, we can customize for a single client in a single market and a single geography. But being able to do that at scale across multiple sites around the world, that's what the Palantir partnership brings to us. And then specialization, you know, we have deep domain expertise in the science. And with Palantir, deep domain expertise in the data science, whether it be any of the platforms we're talking about today, that combination is powerful. And it leads to this. Our vision for the world is to take that deep domain science expertise, couple that with data science and data platforms and make a positive impact in the world. We do have a use case. My colleague Shannon Miller is going to, is not going to join me on the stage. I'm going to leave the stage and give the stage to her. But look forward to interfacing and interacting with everyone moving forward. So thanks everyone. All right. Thank you, Bob. Good day, everybody. So as Bob mentioned, I run our digital data cyber and cloud solutions business at Jacobs, where we're really focused on solving some of the most complex problems in critical infrastructure. And I've been really honored and excited to develop this partnership along with our team with Palantir to really solve the most complex problems for critical infrastructure and the solutions that are around that. As Bob mentioned, our goal at Jacobs is to create a safer, more resilient and connected world. And I can't think of a use case that isn't more exciting than focusing on how we improve the water cycle for the entire planet. So if you think about this, this is critical for a lot of reasons. Not only climate change is stretching our need to expand our ability to leverage our resources, the need to reduce our carbon footprint. As Bob said, not soon, but quickly, very fast. And then of course the staffing shortages and the waves of retirements of some of our most experienced and excellent operators across the entire utility community. So although this might not be the most glamorous use case, our friend Bernardo at JD Power got me really excited about buying a new car. I probably don't need to buy a new car. I'm going to get you excited about how we're harnessing the power of artificial intelligence to improve water treatment. So we're going to see how AI acts as a co-pilot. Sean did a great job showing how we set this up from not only using it in real time to optimize decision making while we're operating our utilities. But also when we think about when the stakes get higher in the wake of a massive storm, and then of course for long term planning and how we deploy our assets going forward. So this allows our operators to interface with troves of data, complex data using natural language as we've seen today. So I'm really excited to show three use cases of what we're working on together with Palantir and what we've got getting deployed here to our customers very soon. So first up we're going to talk about how we're operationalizing our data. This is Jacobs's Aqua DNA platform where we combine our deep domain expertise and wastewater treatment coupled with Palantir and the Foundry platform and AIP. So first up if you take a look at this, we're looking at the entire city. So this is an entire wastewater treatment system on our Aqua DNA platform powered by AIP. So if you think about it, it encompasses millions of people. It's the city's core infrastructure. It's the drainage, the sewage, the treatment plants, and everything that happens in this complex system. So it's the valves, the sensors, and the catchment basins. And at any moment in time, our operators are making thousands of decisions to optimize what they're doing. So if you think about it, first of all, if you send too much water to a wastewater treatment plant, you could flood it, causing millions of dollars in equipment damage. That's taking, that would take down the abilities, the city's ability to treat wastewater. And if you don't manage your storage appropriately ahead of a storm, you could run out of critical capacity, causing an overflow and leaking polluted water to the local environment. So to guide these decisions, systems are typically outfitted with numerous sensors. And what we've heard from our utility operators is in the last two years, they've captured more data than in the last 20 years combined. Think about how difficult that is. The flow of information, no pun intended, becomes very difficult for them to leverage and optimize their systems. And on top of this, with all these assets being added to the networks, it introduces a new vulnerability for cyber attacks. All right. So in the face of all these challenges, let's see how AquaDNA helps me monitor our day to day operations with the data that we already have. So this is just day to day operations in a utility treatment network. So first of all, everything is centralized in Foundry. We've been able to connect all of our data from design, operations, security, and bring it all together within the ontology. So this means we can compound our returns and introduce and have fewer vulnerabilities. So we're able to rapidly ingest and process all the disparate sets of data, which were previously disconnected, creating confusion, and often unproductive noise in the system. So again, it's all being processed real time into standardized reusable models or our ontology. So AIP is enabling me to proactively monitor for the changing conditions in the system that might require human attention, such as maybe a cyber breach or even a clog. We were talking last night, surprisingly, one of the things that we find often in clogged wastewater treatment systems are blue jeans. We were hoping to maybe recycle some jeans for y'all here today, but we didn't do that. So anyway, so we'll see here that there's an alert that there's a potential clog. Let's assume it's some some Levi's jeans in one of our drains. So I'm going to zoom in on this clog and see what action I need to take. So again, we've got real time digestible data of what's happening and where this clog fits into our system. So it is going to require maintenance. So I obviously want to understand how urgently I need to dispatch a crew. And I also know that a storm is forecasted for this weekend. And I want to make sure that I'm taking that into account and how I make prioritized decisions. So with that in mind, I use the AIP assistant to help pull in that forecast for the upcoming storm and it simulates it across the entire system. So AIP is going to pull in the weather forecast data. It's going to bring it in as a new layer and estimate how much wastewater is going to flow into this system. The AI is unable to call on our specialized Jacobs design simulation models such as our flood modular platform to really understand the impacts of this storm. So I can see now that we're getting two new alerts with this simulation with one showing that this clog is going to result in an overflow. So clearly this warrants a high priority fix. I'm going to go ahead and assign maintenance in the platform. And then that automatically updates their schedule and it redirects the crew. This conversational real time scenario model is really it's a huge step forward from the complex manual work that would have been required to perform this analysis in the past and get that maintenance crew to address the clog before this storm comes. And this is really due to our ability to query massive amounts of data in real time and map out different scenarios so we can make the critical decisions in a timely in a timely manner. So next we're going to amp up the stakes. So we've got a storm coming and we're going to see how we can leverage our aqua DNA platform to manage the forecasted storm. So here I'm looking again across the entire system but now I'm seeing how this storm is going to impact us in the future. So the platform tracks where wastewater is entering the system and continually updates our forward projections feeding our risk models and giving us alerts. Only now in addition to those alerts we have a few types of adjustments that are going to take place automatically without me needing to dispatch any crew. These are being executed by our AI agents that we've been talking about today and some of our other stories. They're trained in our systems historical data and they help adaptively keep things in check throughout the entire storm. They're combining machine learning with our expertise and our flood modeler platform to really define optimal system performance. It's important to know I'm still in full control. I can monitor all the actions that the agents are taking their effects and adjust override or disable their behaviors. But they're taking care of hundreds of optimal decision making adjustments for me which include things like adjusting valves, diverting wastewater and updating some of the treatment parameters. So with that being said some actions are clearly too consequential to be taken automatically. So here we can see that AIP has surfaced in alert. It's showing me that there's a risk of an overflow in the next two hours and it's going to make some recommended diversions to avoid that overflow. However, it is showing that it requires my input to take action. So I'm going to dig into those recommendations to understand which driving it and the potential trade-offs associated with it. So it helps me see the path leading to the overflow risk as well as its recommended diversion of the wastewater from a northern to a southern catchment basin. I can see the projections and the predicted metrics helping me understand the full picture of what's likely to happen if I make the diversion or if I don't. And so there's a trade-off here as you can see. On one hand there's a 24% risk of overflow if I take no action. And on the other hand the proposed diversion routes wastewater to a less effective or efficient wastewater treatment plant. I'm increasing the total treatment cost that's above a threshold parameter that I have in the system. So this is why the AI is unable to facilitate this action automatically. It needs my input and my approval to progress. I might also want to dig into what's behind these calculations so I can take a look at what assumptions, data models, calculations and simulations were behind making that recommendation. I can do that right here as well. So based on this information I do decide that the best path is to go ahead and in fact approve this diversion. I approve the diversion in the system, downstream actions flow automatically and in approval processes and communications kick off as well. I can monitor them and see how it plays out to ensure it plays out as I expected. So in a situation like this the automatic capture of all of our decisions and reasoning is essential. We need the platform to keep a full history of all of our actions whether it was done by a human or by the AI along with the associated context in the state of the world. And we can do that all within AIP. This enables me to show regulators why took decisions, what the circumstances and what alternatives were presented when I made those decisions. I can also use this to inform future operations, future operations planning as well as train the AI for future events. The great thing is all of this is controllable. AIP allows me to be in the loop of all of our AI automations, the data they're using, the patterns of reasoning that they're relying on, the guard rails that are set around it and it makes sure that it's performing accurately. It also enforces these guard rails. So the level of actions, the criticality where a human needs to be in a loop is decided ahead of time. And then we can also dig in further to those actions, how it was all generated and of course create a report at any time. So in the last scenario we're going to look at how we leverage AIP for future planning long term. So in the aftermath of the storm, it sort of, you know, it's ticked off a few things for me. I want to think about long term planning of my waste water treatment facility. So I want to re-examine my long term plans. I want to not only use historical information but also forward looking data, right? So to really create a complex scenario for my simulation. So let's go ahead and we're going to build a case study that looks 30 years into the future. All right. So we're first going to start with our current world and layer in things like population growth, urban development and of course climate change. We're first going to ask the AIP assistant to pull in plans for development and the forecasted population growth. And then what we're going to do is we're going to take the top 10% of storms last year and then add 25% to that, which is what's been recommended by the AI. And that's going to build our case study for future planning. So now I want to test how our current infrastructure would fare in this scenario. So as the simulation runs, it shows me that there's several overflow risks. I want to look into the infrastructure level changes to prevent this from happening well into the future. So in the past, being an engineer, I know I used to do this. I sit down and work on simulations and think about different analyses and simulations that I would do to prevent this. And it would have taken maybe months or years to really think about what the potential impacts are. So now with AIP, we can use this immediately in real time to help us understand what exactly can be done. So what it shows me is adding waste water treatment plants or storage tanks would of course solve this problem, but at a huge monetary and environmental cost. So we're going to see if we can improve our networks of resilience by improving our ability to divert waste water within the system. So for example, I asked AIP assistant if any waste water treatment plants or tanks have spare capacity in the system and it identifies three for me. I then asked for it to make recommendations or adjustments to the system to improve or rebalance capacity. So it takes into account all the other factors that I've outlined, population growth, urban development, and it recommends that I consider installing two new pipes. So I can adjust this further, but for now I'm just going to go ahead and generate a report that captures this case study. It gives me my recommendations for my stakeholders, shows me all of the data and simulations that went into the analysis. So if you think about it, this would have taken us a long time to pull this all together with probably a lot of different opinions around what it looked like and tweaking any of those assumptions would have created a lot of recycle in turn. So we're really excited about where we're going. You can see we're developing an end-to-end solution that brings everything together, whether that's security for mission critical infrastructure. It provides control that keeps humans in the loop at every step of the way where you prescribe it. And it's real time. It provides us actionable AIP assistance to deliver those in the moment decisions for simulations, long-term planning, and it helps us make sense out of the massive volumes of data that we're creating all of the time. And it gives our operators this natural language interface to interact with to really make these complex decisions when they need to be making them. And of course it always has the ability to show us the context, the inputs, why decisions were made. I'm excited if you can't tell about our relationship with Palantir, mostly because it's going to allow us to solve problems at a pace and a scale, and it's really that pace, right? That's going to have a tremendous impact on the world around us for all of our people, our customers, our stakeholders. And although we talked about just waste water treatment today, I hope you see the applicability to a lot of different markets or industries and sectors around how we can leverage the power of AIP, deep domain expertise as Bob talked about to really improve our world around us. So thank you very much. Please welcome from HCA Healthcare, AVP of Clinical Operations, Canaan Stage, and Director of Management Engineering, Ben Spears. Thank you all. It's really great to be here and to be able to share a little bit of our experience with you as I introduce, I am Canaan Stage. I'm the AVP of Clinical Operations, a registered nurse by trade. I'm Ben Spears, I'm a Director of Management Engineering for CTNI, and historically I've been on the labor management side. That's, I think, important part of the story is historically there's conflict between these groups, and for those not in healthcare, I give you an example, when I was dating my wife who wasn't nurse, her friends met me, found out what I did, and they were all petitioning for her to break up with me. I won them over, like I won Canaan over, but there is conflict historically, and you'll see what that's important. I think that's a great story to kind of paint that picture, and kind of what we're going to tell you a little bit about is how our teams come together, and how we've been able to deliver a step change in healthcare that we're very proud of, and we hope to see kind of continue to grow through healthcare. I'm going to start with telling you a little bit about our organization, a little bit about our background, and really focus on the people part, the piece that I think is important, and then I'm going to turn it over to Ben and let him share a little bit of the data for. There's a lot of people here that I'm sure are really interested in that, that's just really not my cup of tea and hence why this relationship works so well, and oftentimes works not at all. So, HCA healthcare is over 180 hospitals throughout the United States with a few in England as well too. Our impact that we believe we have in healthcare is really painted perfectly in these numbers. 93,000 nurses work for our organization, and one of the things that I know you all are very well aware of is that healthcare experience, quite a shake in these last couple of years with the pandemic and the challenges that that brought. And one of those prominent challenges was around staffing and our ability to deliver the right patient care that we were trying to achieve. That affected our organization as it affected many other organizations, and it's what led to our desire as an organization to think about things differently. Our leader Dr. Slasher created the care transformation and innovation department, or team, or wing within our organization that is focused on taking a step change in healthcare and really delivering that, you know, through clinically led innovation. And I call that out because that's where I want you to know why my importance on the team is just a little bit more important than Ben, that clinically led part. You saw that too, right? Jokes aside, I think that's been part of the lesson that we've learned throughout healthcare and why we've had challenges in progressing and moving forward has been not our inability to listen, but where we were listening and how we were applying that. Ben mentioned the relationship between the process improvement teams and our financial teams within our organizations and then the clinicians themselves. And somewhat of that balance or that approach that takes place day in and day out. And a lot of that comes from the ability to have access and understanding to data and knowing what's there to be able to have those discussions. For us, our care transformation and innovation team, our focus starts with building out really from the bottom up and starting with our clinicians. We have two hub locations, which are really an opportunity for us to embed our members of our team side by side with clinicians, learn from those clinicians, understand what their challenge points may be before we even begin to design or create operational challenges or challenges to those operations that are in place. We then have two other larger facilities and why that's important to kind of touch on is the realization that we're in an area that requires a strong balance of risk and reward. The understanding that if these are high stakes and high pressure environments, changes that we make to our healthcare process can have very positive impacts on our patients. They also could result in some possible risk that we wouldn't want to see. And with litigation that was brought up earlier being a significant part of healthcare, unfortunately, we have to balance the idea that if we're going to make changes, we need to be sure that those changes that we take into account what the downstream impacts could be. And the very best way to do that is to do that on site with the team and understand the challenges that they're having. But the other part of that is being over 180 hospitals, there's a lot of customization that goes into the way that each individual hospital operates and each individual unit within that hospital operates. And so understanding the why, the Simon Sinek, I'm a big believer in him as well too, so I love hearing that today. Understanding the why of those challenges and why they may deviate from what is maybe an accepted standard of care is really going to help us understand how do we attack that challenge and that change and move forward in our process. So when we challenged the idea of taking on first and foremost staffing, particularly coming right out of the pandemic, there was a lot of people that believed this was the right answer. It can't be done. We can't theoretically change the way that we approach this. Staffing for many, many years has been about taking what's available to you and as team members come in and labor team members come in, they give us their availability, they work on the shifts that they have. We wanted to take a little bit of a different approach and we wanted to understand and value our employees somewhat differently. And so we presented this idea to a few different companies and this was a direct quote from one of those companies. It cannot be done what you're trying to achieve. And another organization that we met with, we worked through part of the project and we realized that maybe it couldn't be done with this group and this team. And then we found a new partner and that partner was Palantir. And what you'll see on the screen is that there were a lot of similarities and a lot of alignment between our organization and our thoughts and where we could take the steps to improve that and to put this process into place. We've heard several things called out today, the speed of deployment, the ability to integrate with our teams and be on site. And I'm very fortunate to share actually a few photos of our teams working together right on site. This is at two of our innovation sites, two different innovation sites and on this picture to the far left is actually one of our groups of Palantir team members and someone here is in the audience from that team that we both very much appreciate the opportunity to work with day in and day out. Because what's different about Palantir for us has been the willingness to understand the why, the willingness to embed themselves with our teams. In fact, sometime push us, hey, we haven't been on site in a little while. Can we go back? That type of relationship and that type of interaction is really what has led us forward to being able to build forward a platform that is transformational. There's no other way to say it. And what I think it's done is a nurse myself. It's empowered nurses to have better conversations about needs, better conversations about how we support each other, and better conversations about how we deliver the very best care we can possibly have. And I will say that over time I've learned to appreciate that process improvement idea and how we can work together through that. And so at this point what I want to do is turn this over to Ben for him to bore you. I mean to provide you a little bit of the details around how we achieve this new process in format. Thanks, Gayne and Ford. So this is what it looked like today. So unfortunately you have what are in the black boxes compared to the orange boxes is we didn't know and we had no insights today on those black boxes. We didn't know what the original schedule that was posted was because we didn't have changed data capture and so many changes happened after the schedule post. As a company we talk about our scale but what that looks like is 2000 nursing departments with 3000 leaders us trying to teach them what's the right way to balance and post a schedule. We have 20% turnover within those roles and it's very tough to get to those 3000 individuals in time. This is the right thing to do and this is the right schedule to post. We saw a lot of variation, we saw a lot of bias and to be honest we didn't really know what that looked like. We had assumptions but we flipped over to future state. We now have all these data points we're able to see on the staff input side system inputs we turned it on and we're like oh my gosh we understand we need change management because this is a big change but I don't think we truly appreciated what the change was going to be until we were able to drill into our data and see some of the practices that have gone on. So how our process works is we have the staff give us information about themselves so we have the talent profile to understand what kind of roles they can do on the unit. We get their schedule preferences. We marry that up with volume demand prediction business logic to generate a schedule. We want that schedule to be 95% of the way done. We want the manager to then review that schedule before posting. We're strongly believe that the automation is not going to do 100% there's going to be nuances that the manager needs to do but in the current process that we have today because it can't be done it's relying on that nurse leader and that's 10 to 20 hours going on every month with the nurse leader having to build the schedule across 2000 apart. It's been very successful so we've been able to get that number down to one hour so 95% reduction at some of the best utilized hospitals and departments that we have and we're really excited. So this is what it looks like. We're utilizing a handful of different workshops throughout the process. We have the personal workshop where staff members are able to enter information about when they want to work request GTO, those type of things. We have the staffing workshop is where the managers will go in, run the schedule, hit the automation, come back, do their edits, post the schedule, and then we have the staffing workshop and the facility workshop to take care of all the edits that need to happen after the schedule post. Because we need to insight and we can overview the CT and IT and our executive leaders can use those dashboards to understand the process, look for ways to improve and educate and coach that feedback loop back to those nursing leaders. We really hit on the value to the nursing leadership but to the organization of a whole having ontology and having this data is transformational for us. Today what it looks like, a bunch of people like me are looking at the tea leaves and looking at the smokes and trying to figure out what contract labor and what kind of premutalization we're going to have this month and next month and do we need to bring in these contractors at this rate to fill our needs. We were able to build screens where we can turn that art into a science and we can have everyone calculating it the same way. And it's so easy to access the data, it's so easy for us to merge the data with other things. The other use case that's been brought up is how do we, now that we have all this information, we can almost do a forensic level analyze of each of these staff member schedules. Let's mirror that up with turnover information and see what are the root causes when we have these turnover? Can we identify issues whether that be orientation process? So today we know we have a best practice of what orientation should be. We've turned it on, we have the insight, we know what we say we should be doing and what's going on in our hospitals are completely different. So let's tie turnover rates to preceptors or when we say we want one preceptor for the whole 12 weeks or we actually doing that or we bouncing around 12 other people and they're not feeling involved. So this is kind of the road map that we are. So we kicked off the partnership in January, we've quickly scaled, I would say this slide is a little optimistic and it looks pretty, we've had some road bumps along the way and like to share that with this group. I think the biggest thing in innovation, especially in health care is kind of mentioned is there's this desire to always be perfect. And when we have bugs or we have these fixes, there's a, it's even, the quote I heard yesterday, it's rewarding to close the ticket. And I think we've had to, what happened is we kind of got into this three week period at the end of March and leaking into April where we have our short term architecture as we transition away from our existing solution and as we move to the long term architecture. We had some, I'll call it issues with the short term architecture and we were spending a lot of time trying to fix what the problem was right now. But when we go to August, all that work is going to be throw away. And so we had to look herself in the mirror and be okay with breaking a couple things and saying in the long term to hit our medium term goals, it's going to be okay to break some things at this smaller scale. And that's really what this department's about is understanding that it's okay to tinker, it's okay for things to break and a safe environment. We're going to may ask our department leaders at these hospitals to wear a little bit of the burden for the short term knowing that we're going to build a product so much better six months from now. And that product is going to be able to serve all of our nursing leaders across the company. The one thing I want to say in this process and really want to call it volunteer because I've been really impressed is they understand where very aligned and what our goals are. And there's been moments especially going from 25 departments to 50 departments where the scale, the difference between the departments we are expecting to see or the experience of the 25 moving to 50, there was differences. And so we even gave them out, hey, let's, here's a short term fix. We're going to give you the short term fix and it's going to create technical debt. It's going to make life harder down the road. But they're like, no, we do not want to do that. We're going to do the right thing. We know it's going to be harder now. We're going to do extra work now so we can hit our goals. And so a common theme today has been speed and we're quickly transitioning out of that building the product and transition into speed. And so we plan on going to five more facilities in August with ultimately the goal to hit 40 by March of next year. And trust was another big thing that came up this morning. I think without pale interior. Could this be done? I'm not sure. But I do stand up here today and have the trust in the faith and our team to hit our goals. And just I know there are a lot of them in the room or listening and want to give them a thank you as well. Yeah, and I think the last thing that I will add to that is when we were younger, we were probably the guys in the back of the class that were told we were disruptors. And that was not a good thing to be. But in healthcare, when we've been able to disrupt some of our general thinkings and some of our general thoughts and do it with the support and the power that Palantir has brought with the data, it truly does become a very valuable resource. The feedback from our frontline team members obviously is one that could be a little bit uncomfortable at times. But overall time and time again, we hear the words thank you and those are the words that we want to leave with the Palantir team as well too. And that is thank you for an exceptional partnership. And we look forward to sharing our story with Boomeris to hope you'll have a great day. And a final round of applause for our customer speakers today. All right, we're getting ready to break for lunch. We've got a packed afternoon plan for all of you with a customer demo, expo a series of meetups, a series of whiteboarding sessions. Before we close things out, I'm very honored to introduce a member of the team Morgan Schwartzman who is behind the past few Foundry CUNS and today's AIP CUN to close things out. Hi everyone. I am responsible for all personalized agendas for Foundry CUN and now AIP CUN. I used to do this in a very manual and painstaking process via several spreadsheets and data collecting sources and templates. This process was extremely error prone, had bandwidth and functionality limitations, and if there are any scheduling updates during the programming, there was no real way for us to communicate that to you. AIP CUN is now completely powered by Foundry. I used dynamic scheduling, a product that launched at last Foundry CUN in February, just four months ago, to personalize over over a hundred hundreds of agendas, tailored to all of your goals, and even the people who were on the wait list, you also got your personalized agendas. You saw our keynotes ran slightly over today. So we're going to go in and adjust your schedules. Previously, to make a change like this, it would have taken a crazy amount of hours and manpower. Using AIP, instead of making an individual change to all agendas, I can simply provide the LLM a description of the change that I need to be made. It can be applied to all individual agendas at once. Now imagine some customers of you here with us today are responsible for managing flight swaps for hundreds of aircrafts when they need maintenance. Others are staffing thousands of nurses across hospitals. Still others are managing complex production schedules. It's the same products across industries. The adjustment that we just made live together has now automatically propagated and updated any downstream effects to meetings and other sessions. If you've opted in for our tax messages, you'll receive your scheduling update directly to your phone. For those of you who dialed into the live stream, thank you for joining us. We hope that you take the stories that you've heard this morning and continue building on them. We encourage you to participate this trusting environment and connect with each other. And now, on to lunch. Thank you. You You