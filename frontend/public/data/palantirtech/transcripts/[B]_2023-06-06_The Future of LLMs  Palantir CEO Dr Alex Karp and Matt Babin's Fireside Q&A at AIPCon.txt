================================================================================
METADATA
================================================================================
Title: The Future of LLMs | Palantir CEO Dr Alex Karp and Matt Babin's Fireside Q&A at AIPCon
URL: https://www.youtube.com/watch?v=ov3iILzXFt8
Published: 2023-06-06
View Count: 34,891
Duration: 1834 seconds
Score: 63.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Thank you, Sasha, and thank you everyone for joining. It's my pleasure to open up the day again with a conversation with Dr. Carp. I'm only called Dr. Carp. I saw him here. I don't know this. But when we started, we had no revenue. We had no product. We had no investors. We were almost going out of business. The only thing anyone believed in was that I was a doctor. I kept trying to get rid of it and I realized, oh, we got to have something they believe in. That's why I'm still Dr. Carp. We can call me any four-letter word that you say. I can say it in public. Perfect. I'll shorten it to Carp as we go. I wanted to start by asking you about the letter that was in the news a lot this week by the Center for AI Safety that said paraphrasing that mitigating the risk of extinction posed by AI technology should be treated as a global priority. The same as societal-level risks like pandemics or nuclear war. And as the leader of a company that supported governments and private institutions through the pandemic, has been outspoken about the risks posed by the invasion of Ukraine on nuclear activity, how do you respond to that statement? Well, I think it's great to be here. Thank you for the light, softball question. You get someone else next year. We've clearly picked the wrong person. Well, so we've been involved in building systems in the classified environment and in the last five, six years systems that are involved in identifying targets using AI. In this context meant finding targets in very large spaces. So spaces the size of Texas, find this kind of person and then a handoff. So you find target. People assume that when you find a target that you would then automatically just disappear. But in fact, what really happens is it's very hard to find these. You need to be able to work on disparate kinds of data sets that are very large. And then there's a handoff mechanism where it's like, is the target, is the identified object next to a hospital, is it an identified object next to children, is the identified object actually an asset of ours, is the identified object, the idiot we want to not die. That there's sort of a lot of complicated things that involve that. But and where what I think is yes, these technologies are very dangerous. But our adversaries are even more dangerous. And that we, because of that, have no choice but to run headlong. What's interesting about a lot of these statements and what's going on in AI, which is mostly focused around the large language models, is that you really have different factions. You have a faction that is saying that it's hyper dangerous because right now you need very, very specialized technology, which I believe we provide, to make large language models really, really important in your enterprise so that you're not delivering a piece of poetry to your enterprise. It's like, no one has time to deliver poetry. We need margins to change, safety to be better. Generally, understanding of our business, the knowledge of one part of our business to be transferred to another. These are things that large language models do exceedingly well with infrastructure that will be showing off today. And I don't want to take away from the things that are coming, but there's a lot of things we built that will allow you to do that that are very valuable. So there's one part of that that faction that is saying that because they're right and these things are very dangerous. But they're often right, but it's in, you're not, it's like not also mentioning if we don't build it, our adversaries will, and that won't be very good for us when we have no rule of law. And I'm in a constant battle with my academic friends about this because they believe that in the absence of hard power, either using, being able to use AI now or nuclear, essentially nuclear warheads, we would have a rule of law. We at Palantir believe that you need these weapons to enforce a rule of law. And that's our deeply held belief. And we've had that for 20 years and it's cost us a lot, cost us investors because we wouldn't work in China or in Russia. It cost us sometimes people. We didn't want to work at Palantir. But then you also have a coalition and this is actually what I'm not related to people here. But in the defense establishment where we play a role, quite frankly, there are very few providers of software that's useful and everyone else wants to have a debate about how dangerous they are. Let's just debate it and debate it and debate it and we can implement these things in five years. And that we have to avoid. And again, my view of our company is very dangerous, very valuable. One of the things I do really like about it though is that for commercial enterprises, it gives you the ability, if you're adaptive, to outmaneuver everyone else. And the industries that are going to do that most effectively are largely going to be in America because American industry and its executives are just very, very pragmatic. If I can change the margins of my business, I can understand my business better. I can implement the cultural and knowledge advantages I have because I developed a way of building my business over the last 20 years better than anyone else in the world. I'm going to do it tomorrow. And that's just enormous advantage. And that's quite frankly why this audience is packed. And so I think that's just something we have to run towards and that's what we're doing as a company. You mentioned pragmatism and the implementation of software there. And I think maybe I started with a question around extinction because I'm a pessimistic person. If you're trained as an economist and you work as an Intel officer, you spend a lot of your time thinking of how things can go wrong. I think software engineers by and large are optimistic people. You're going to build something that doesn't exist for the first time. Well, they're optimistic in the long term and pessimist and you tell them what they should do. It's going to stay in transition. But yeah. And maybe the synthesis of those two things I think is realism here at Palantir. And the reason I have stayed here this long is we spend a lot of our time I think in that synthesis of taking the optimism of that software and putting it against the pessimism of these problems in the world. Where are you most excited about that company? We are in business. But software that allows you to identify adversaries at a high level and we've been constantly cautioned not to say much except for that the Ukrainians use our software. Change the course of history. Demonstruely. And software that we built 20 years ago. Change the course of Europe because we stop terror attacks while protecting civil liberties. Software that we're now rolling out will change the trajectory of the U.S. economy in a very positive direction. And I, you know, I'm not, they're certainly flaws in the West but we are the most, the best group of countries and structures that this world has ever known. And we have now technologies that will allow us to lurch forward. And we have a cultural, we have cultural and training biases in this country that are tech-friendly, pragmatic, able to implement things. Very high level of technical competence inside organizations built up over the last five 10 years. Super willingness to bring the best town in the world. One of the things about large language models that is just really cool is that for our partners is it, it's like many of these things are horrifically unfair but it's going to make places that are already strong, pragmatic, have specific ways of doing business that are quite valuable. It's going to allow those industries to lurch forward very, very, very quickly. And we haven't, you know, we have been in for 20 years. Without, you know, like the products we built on, you know, we built products for Intel, products with special forces, products on identifying adversaries. And none of them have the ability to transform a whole economy like this and prohibit variability in the hands of very talented people. Graphically, legally, safely. But anything also is that, you know, we've, and this is more academic, but we've been in the trenches, it's like one of these things, no one ever believed we cared about civil liberties, but we made a ton of money caring about civil liberties because you have to, you have certain architectural, from a technical perspective, civil liberties means, you need a branching structure so that you can segment who sees what, you need access control so that you can verify who sees what. You need an ability to do that dynamically. You need an ability to impose what objects and a mean to each other. So what we call an intelligence, you need ability to write against that where you only write against the segment part of your data. But now in the LLM context, you can think of that as just a way to process something that is moderately useful to very useful into something that is crazy valuable. And Shams going to show you this in this concept, this thing we built called agents. But all that processing, all those things about like academic data protection, they're really just like taking an unrefined product, moving it into a refined product, and making it deadly. And to see that something that looked philosophical became valuable in the anti-terror context is now deadly in the AI context and can help people transform their businesses very, very quickly within the context of how a business actually runs. So you have proprietary knowledge, you have data sets, you have things that actually regulate, you have things that you do not want to share, you have some things that you would expose to a large language model, and other things you wouldn't. You have areas where the large language model needs tooling, you need areas where it doesn't need tooling. You have areas where you can accept 80% accuracy in areas where you can't. You have specialized knowledge in your business that even you find it hard to articulate. Why is America and Silicon Valley, and just in general, this culture so good at building enterprise software? I don't know how to articulate that, but it's very, very hard to explain our selection and building products. But it works, but getting that specialized, not how do you manufacture something very complicated that one company manufactures very well, but another company doesn't. How do you actually take all those insights and roll them against your business while being able to drill down into those insights so that you can make sure that the decisions being made are actually ones that you would support, not just ethically, but from a business perspective. And all that comes down to things that we've built that are actually in demand and that we don't have to convince people are valuable because they are just valuable. So that is super cool. When you think of that transformation of the software through those gates and delivering that value, last month in Copenhagen you were giving a talk, and I think you've got a question which was, is the west ahead of adversaries in technology like this? And if so, how far ahead? How big is that lead? And you mentioned in your answer that yes they're ahead, but the issue to work ahead isn't other people catching you from behind. It's western governments not being able to move as quickly and efficiently as they can. You talked about budget appropriations and programmatic things. For this room and most of our audience today that's in the private sector, what do you think that acceleration looks like on the commercial side and maintain it? Well again, I think what everyone in this room is going to do and what I think people already built and one of the coolest things I've ever seen in the history of pounders. You go next door where these demos are and we're showing off our product and we have current partners showing other partners how you do this. This thing about software that was always true is it's all BS until you try it. It's just, it's like, you know, I was constantly asked what makes pounders different than these five other companies. I don't know. You try all of us. It's like, it's just, it is just try. Why don't you have a payment strategy? Because I know our partners, future partners are smart enough to pay us a lot of money if we create a lot of value. What, how do I know it will work? Well, we can show you it working and we can show you how valuable it is and what it basically means in the government context you have this problem globally. That 98% of software spend goes to people building things by hand that take five years and maybe then take 10 years and then it take 20 years. And beyond that, that's just not how software is built at a world class level. You can't have security if it's not a product. It's like, well, how are you, and it's very hard to do these things but it's definitely not going to work. And this is not just, this is not just America. This is everywhere. And then you have a lot of places, you know, one country doesn't want to buy from another country. And so, you know, I think many of our allies have a problem that all the products come from America anyway that works. So, like, how do you explain that? In the commercial context, it's just very, it's very different. It's like, we have a problem. Palantir has, you know, in the commercial context, multi-year, 10-year reputation for delivering very complicated systems that have worked across heterogeneous entities. Great. We're going to take, they're making some pretty bold claims. You're going to say, great. If those bold claims are true. You want to see it. And then you go and test it. And then we enter into a relationship after you've gotten value. And the only thing I would say is this is kind of obvious. And by, where it's not obvious, we as a culture have to make it even more obvious because on paper, AI sounds like it's very hard to know it will be valuable. And enterprises have very complicated internal technical challenges that are now being exposed. So one of the very advantageous things for us is AI will pen test your whole enterprise. So you can use our products, but the stronger your enterprise, the more value you're going to get. So that's like, so you're going to see this, try it, get value. And then the next question is, well, how do I get even more value? And that's just a process that it's not theoretical. It just has to be tried and proven. Maybe we should go to questions. Yeah. I was going to say, let's take some questions from the room. Or we could just talk about extinction. There's always one person who has like five questions. So that person should ask one. Oh, we have our long-term advocate here. Friend. I don't know. I want to ask a question. Okay. I'll ask one more while we, it worked. I didn't know you were looking directly at me. Put it me on the spot. There's, I mean, I'm representing one of these, but there's historically places in the world that have not had similar values, right, to the west or to the United States. Sometimes they're aligned. Sometimes they're less aligned, right, and bringing something that delivers this kind of power and this kind of insight and efficacy into those markets, right? How does parents here look like? Or how does parents here look at that? In terms of, like you're saying, bringing some of these Western values and the benefits that the way we think in the west give us this kind of advantage, how do you look at bringing some other places that might necessarily not always align with us, bringing those kinds of capabilities to bear to actually help us in the long term deliver the values that we really want everyone to share? Well, you know, it's interesting. I've been asked this question a lot, but I have a, I don't actually know the real answer now because when you see what we're building with these agents, it's really scary. So it raises the threshold of where I, so the agent basically, it's, I'll show you this, but it takes the output of an LLM, creates it in a hybrid algorithm and allows you to run it passively, meaning all the time against your whole enterprise and depending on your, the quality of your security, you can segment, but it's still, you can see how that could be easily abused. And I do wonder if that should be sold to, like, local law enforcement. And so I don't know. In the past, we've always been, like, I'm not, I'm in no way in Neocon, honestly. I just think we have the West, we have the Cor West, and we have allies, and we have customers all over the globe. And if they're on our side, I think we should cut them slack and if they're not, but slack doesn't mean everywhere. And we, we always have these ongoing discussions and we've refused to work with lots of people. It's cost us huge money and I've been yelled at and quite frankly, if I was fireable, I would have been fired many times over this. And I still am, everyone's fireable, but it's a little harder because the alternative to me is an engineer. And nobody, nobody, everyone's afraid, even with our products, we'll have no revenue. So it's really hard. Like, wait till you see Sean Stamm out, it's like that. I'm sure we should sell this to the US industry. I'm sure we should encourage client-destined service, special operators, current clients, the US military, the five eyes. I'm sure we should give it to them. I think we're going to have to have long discussions about where else because you know, it's like you don't want to have something that could, you know, we've been in the business actually of protecting everyone's right to their own liberty, which also means your own lifestyle, your own secrets, your own personal proclivities that are yours, your health records. And I think that's one of the things that makes our society so special. So there's a lot of new thought that's going to have to go on about this. But in the near term, if you're a US industry, industry in Europe, client-destined services in the West will definitely sell it to you. We'll have to think hard about everyone else. Other questions from the room? Yeah, one right here in the front. There's no shortage of problems in healthcare. And now that you're kind of getting under the hood in healthcare, how do you see foundry transforming the whole industry across the different hospitals across the whole spectrum? Well, thanks to the great work of two people are here and others where we power, I think 13% of hospital beds in the US. Those use cases are super intricate. If you just look at foundry, the use cases are optimization. How do you take scarce resources and disperse them in the most financially beneficial, but also ethical way of a million hospital beds as you have a million five patients who gets them under what conditions? That's both economic and philosophical moral implications and legal implications that you can deal with in foundry. You also in the hospital industry, and this is before you begin to integrate AI, you have highly trained workers, nurses, doctors that need to be involved in the judgment chain. And so how do you do that and then do it systematically is a classic foundry problem? I think you're also going to see that given the way we can manage data in a completely transparent way and show the transforms, meaning how the data is joined in a transparent way that that industry is going to be ideal for a parent here, and AI simply because of certain optimization and knowledge-based transfer issues. So not everything a nurse understands or a doctor understands should be transferable to an AI. But some precursor decisions that can be evaluated should be just in the same way in other contexts you identify and then have a hand over to a human. But that can only be done under the condition that you can actually see how that was done, even simply for legal, ethical, and reputational reasons. And you also have the other reason why software so important in that industry is it's margin challenged. So if you have a margin challenged, meaning the industry or a resource challenge industry, that is with complicated engineering and societal variables, that is something you need software for. And that's why our software has been so impactful during the COVID epidemic, why it's the ... I mean, we barely had software sales into the hospital industry a year ago. It's just going like that. But it's going to ... You will see where you begin to integrate. It's going to be very hard for other people to get ... Our products ideally suited for that plus AI because just purely one of the big concerns in the hospital is litigation. So it's like I brought this patient in. Okay, great. Well, you're going to get sued either way. But like, you need to be able to show, well, this is exactly how the decision was made based on these datasets. That requires a branching architecture, ACLs, and ability to do this transparently, ability to show how the data was organized, meaning the transforms. And then if you're running AI on top of it, you're going to have to be able to unpack that in court, which we do natively. And so ... And then one of the valuable things for us besides helping hospitals, which is incredibly valuable and gratifying. And my father's a doctor, so finally might get some respect at home. Is that it is a much more intricate, difficult use case than people realize outside that industry and in a high lights what where a product work and where it works and where it doesn't. So we also have an invested interest because we can show off, okay, these are the very complicated issues that by the way, you're also going to have if you're building an engine or drilling for oil and gas or if you're doing pharmaceuticals or if you are organizing building water plants or if you are doing really anything that involves the convergence of complicated engineering and regulation, which is basically every industry in this country. But this one particularly highlights it partly because of the challenges on the resources and partly because of the ongoing litigation challenges. Oh, we'll just repeat the question for everyone. So, first of all, China and the various countries are representative. And your perspective, which is the biggest deciding person in the system, the board of the government, the CFO, the chief innovation officer, the chief digital officer, the chief technology officer, who is the belly button, really, the production cost of life inside culture that's not raised. Just to repeat the question for those listening to the stream, the question was putting aside the remark about Ganesh, a colleague of ours. Who is the main person in the C suite that you think is the...? Well, no, I think that part of it is like say there's resistance in the org. But the real answer is it just depends on the org. You know, we have partners here where the CEO wants to get involved in that, in technical decisions. We have partners. We just need somebody who has the authority if they see value to push quickly. And so, in some more, some more, that's the CFO, actually, surprise, in some more, it says the CEO. Usually it honestly ends up being a coalition of like somebody who's got credibility, by the way, sometimes it's not in the C suite. I mean, I see it's all the time. We got our company off the ground because special operators went to the generals and said, yeah, you may not like that guy, but he's bringing this home safely. And the generals were like, yeah, I don't like that guy, but if you bring him home safely, I will get by your software. So, and that's a classic pound here. The AI thing has just shifted this, though. It's like a year ago the answer would have been two years ago to be in CEO or it doesn't work. A year ago it was like mostly CEO. Last time we did this conference, I guess, was a couple months ago, it would have been like 70, 30. Now, we have just a lot of very technical people in the technical part of organizations saying, okay, I'm going to do this. I have these five highly technical questions, which largely, you know, you'll see it being answered, but come down to, you know, safety, security, understanding the limits of LLMs, understanding where they have to be augmented, those kind of questions. And if you can answer those questions and more importantly, show it, they're off to the races. So, it really, really depends. And it also depends geography to geography. One of the things that's made America very successful for us is more people can make these decisions. So, when we're in Europe, it really has had to come from the sea suite and then we've had a lot of resistance. Then you also see, even in government, there's huge differences. Special operations work different than Intel, which works different than military. And in some of these cases, it's a very disparate. You can work with one part and the other part you can't work with. But again, you know, we constantly get asked by experts, meaning I probably shouldn't say this, but I could have built a business. I should have built a business. I could have gone to hedge fund. But now I am an expert on software analysis for, and I rate the software products and decide how valuable they are for Wall Street. And they always want to know how valuable, how big is the TAM? And it's actually quite hard to calculate it for us. But one of the things that has made the TAM much bigger in the US is more people can decide to say yes. Much more. And in the AI context, it's really, since we're on the frontier, and everyone knows we're on the frontier, it's, one of the really cool things is, it's the first time I've seen a market, maybe since we've built our Intel product, where everybody knows we're on the frontier, and therefore it's like, okay, there's no playbook. This really helps us, because when there's a playbook, maybe we disagree with the playbook, which we often do. Like software needs to do these four things to fit into our architecture, or we're not going to buy it. So that's really slow, foundry, just growth down, because we actually have a different view. Our view is that it should be category defining. Meaning you should be able to answer these questions independent of what an expert says software should be like. Because someday you're going to have to ask and answer and write to your enterprise under difficult conditions, questions that you're not asking and answering tomorrow, and you're going to have to be able to do it in a way that's not just data science, but is algorithmatic. We've always thought that. We lost a lot of those battles. And even though foundry, basically foundry grew 67% last year, in a world that was more frontier probably would have grown three X of that. And so now in the AI context, there really is no playbook of how it should look. People just want it to work. And that's again one of the main reasons we've had more inbound for palantir in the last couple weeks than we had all last year. And it's precisely because the playbook is out the door. Everyone knows this. This could be very valuable if implemented correctly. Everyone knows if it's not implemented correctly, you're going to get some poetry. And it's going to be expensive. And or, yeah, so that's very different. Great. I think, thank you all for the questions. I think this is a great introduction of what we're talking about here and what that frontier will look like. Any other closing remarks? Thank you for coming. For those of you who need a palantir, you've picked a great time to come. We've never had a vibe this good. It's been pretty good in the past, but it's not like this. So I hope you enjoy being here as much as I enjoy having you here. And hope to see you soon.