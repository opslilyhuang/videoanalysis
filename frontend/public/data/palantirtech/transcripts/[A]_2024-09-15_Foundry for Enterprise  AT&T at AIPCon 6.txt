================================================================================
METADATA
================================================================================
Title: Foundry for Enterprise | AT&T at AIPCon 5
URL: https://www.youtube.com/watch?v=jLYsw3z7IJA
Published: 2024-09-15
View Count: 11,882
Duration: 754 seconds
Score: 70.0/100
Rank: A (Active - 高参考价值)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

Please welcome from AT&T Vice President Data Science Mark Austin and Director of Technology, Dan Wagner. Well hello everybody. Since this is an AIP conference, we thought we would start off with a little bit of history of AI from AT&T's perspective. We've been an AI for a very long time. In fact, we were the first ones in the room when the AI term was coined. It was us, IBM, Dartmouth, and Harvard. And then we went on to doing some of the cool stuff with neural networks in the 80s and 90s, invented those. And then the largest competition for data science in AI from a dollar point of view that I know of was the Netflix competition for a million dollars and AT&T won that. Now the new thing that I just wanted to bring up is we did it again. Last week we won a Gen AI competition to do explain and ask questions of data, okay? In the Gen AI world they call it text-to-sequel. So you ask a question, you try to figure out what table this is, you try to get an answer. So on the right there, you see that leader board AT&T's top of the list and there's some very renowned names on there. You got Ali Baba, you got Google, you got Uber, you got Stanford, a variety of different universities, IBM research. So this is very hard problem, okay? And the concept is if you have lots of databases, this particular competition was 95 databases, 12,000 questions, ask a question, try to figure out what table has an answer and get that answer out correctly. Now the reason I bring this up as well is this problem we used understanding the data, understanding the metadata, understanding the connections very similar to the ontology that Palantir uses, same concepts. So let's talk about this Gen AI now. So we've been on a journey on Gen AI since chat GBD came out. We call that ask AT&T. So that's our private, secure, content filtering, we have all the security in place and AT&T. And the goal of this platform is to teach it about AT&T for our employees and sometimes for our customers. So inside of AT&T, we have 100,000 employees and contractors on it, we've done 120 million API calls, we have 55 use cases in production and you can see the tokens, okay? So this is the words kind of going in it out of the platform on the right there. I didn't put the numbers but that's in the billions, okay? So very large scale at AT&T. Now if I think about Palantir, we've been on the journey with Palantir, we have many tools at AT&T about five years. And we have almost a thousand data sources in there, 995. And believe it or not, we've had 36,000 users since we started and we're at 8,500 users a month, 580 use cases. So these range from data engineering, machine learning, and as you're going to hear today, some of the Gen AI stuff in AIP. And all of this on the ask AT&T side is connected, okay? So the calls in and out to the large language models, the embedding models, and the rag use cases are connected to ask AT&T in a secure way. So let's talk about the ontology. Remember, as I talked about in the ask data, the text-to-sequel thing with the competition, it's all about understanding your data, understanding how it's connected, what's a customer, what's a location, what's a facility, okay? And you kind of see those are the different colors there and you can see that they are connected. Now that takes a bit of work putting it in there, getting it right. But then if you have it, you can do use cases very quickly. You get concepts and you can kind of reuse these things. So I'm going to start off with a traditional AI example and then my colleague Dana is going to give you three Gen AI examples. So this one, we call it call before you dig. Now believe it or not, we get 20 million calls a year of different facility, other facility providers, anybody that wants to dig up your yard, your street, whatever it is, we get that call. And why do we get that call? Because we have to go out and mark the facility with a spray paint on the ground so that somebody doesn't dig it up and then there's a fiber cut, okay? Now the way you save money is if you can figure out that you don't have any facilities there and you don't need to go out and mark it, okay? So out of the 20 million, you try to avoid as many of those as you can, hopefully they're not re-rat. So that's what we try to do. So we do that by using data, piecing it together with the ontology and machine learning to actually do that. So let's take a look at that. Okay, so it starts off with geospatial indexing. Where is this call coming in? Let's create a ticket. And we put it on the map, we kind of locate it, we have the hexagons, so this is the Uber H3 kind of thing there. And then you take the tickets and you match them up with the parcels in the middle. Sometimes you use computer vision, do I see a manhole? Do I see some of my facilities there? That's a pretty good clue. Putting all those together, we come up with a predictive model that basically says we have a problem there or not, okay? So this is the very nice thing. This is the great thing about Pontear. You have this view. You can see your entire pipeline. You have different colors there for the facilities, the tickets, the purple that just flew past there. That's the machine learning. Ultimately it all goes together and what comes out on the right is a estimated decision or predictive model as to whether you have facilities there or not. Okay, this is just a different view. So there's the actual widgets there. And the cool thing is you can go and you look at geospatial. So now I can look at it and you can see, I'm looking at whether I've copper, whether I have fiber, you can see the lines there. That's kind of where our facilities are at. And ultimately we'll put the ticket there over top. And hopefully we don't have to go out there, okay? So we like the voice of many of those. Now at the end of the day you can go into the rules engine. So here it's taking all of that. You can kind of configure it. You can kind of figure out what level of reliability or predictability you want than that. And ultimately you get your decision there. So that's a view of traditional AI. Now I want to hand it over to my colleague. And let's talk about some of the Gen AI stuff using AIP. So Dan, give us the three examples. Got it. Thanks, Mark. Like Mark said, you know, we've been on this journey for five plus years. We started with call before you dig. And now we're getting to the point where a lot of our use cases are using AIP as part of their workflow. The first one I'd like to talk about is Scal. Now AT&T's Vast Physical Network is managed and monitored by a number of disparate ticketing and alarming systems. This makes it incredibly hard for a network operations center to have an understanding or view of what's happening at any one given point in time. What Scal was I was built for was to be able to do a holistic view of what's happening on the network at any one given time and correlate tickets and alarms together for better network incident management. As you can see here, two and a half million tickets analyzed year-to-day on Scal and growing, right? As we get tickets and alarms from all the equipment or sensors or cell sites across the network, I'd love to show you what Scal actually does, but it does reveal a little bit of our critical network infrastructure. So maybe we'll save that for another time. The second tool I'd like to talk about really takes advantage of AIP's functionality and was built by our AT&T Labs team to be able to get a view of our legacy circuits and legacy equipment that could be decommissioned and taken out of the network and allowing AT&T to realize cost savings. If you can imagine how this might have been done in the past, a lot of swivel chairing, spreadsheet analysis was the only way that we could actually take a look at all the different circuits or equipment across the business, how's the multiple different systems. The labs teams built the mobility legacy transport optimization ontology and using the network ontology are able to get a view of what the potential possibilities are to be able to take costs out of the business. What you see here is a representation of what the MLTO application does and you can take a look and you'll see how many circuits we might have in the inventory or what some of the equipment is. The MLTO bot allows a user in the business to interact with all that ontology and all the data. We're asking questions like how many third party suppliers or how many third party circuits do we have passing through the network. What you can see here is the LLM actually thinking and reasoning and going through how they can actually solve that problem. Filters out the number of circuits in a particular market like Phoenix and then gives us a cost that's associated with it. We can even drill down further and ask, hey, was that a monthly cost or is that a yearly cost. What it allows us to do is move faster. And not only can we ask questions about the information that we have here, we can also action the workflows to take those circuits or that extra inventory out of the business. Saves AT&T money. And I think what we'll get here is a view of all the circuits that could be candidates here and allows us to get into the details such as what the costs are, what are they used for, where they're located and give those engineers in our business the ability to go take care of them. The last thing I'd like to talk about was built and developed by our construction organization. Our access construction and engineering team built this tool called FLARE to help us understand our suppliers and what happens with them when we give them work to do, for example. When AT&T wants to go build fiber in a neighborhood, we often issue out a job or a request to a third party supplier to go do that work for us. When a supplier comes back and issues a proposal or they actually complete some work, there's an opportunity for AT&T engineers to give feedback on what those suppliers actually did. Now with thousands of jobs and thousands of proposals and thousands of suppliers, this can be a daunting task for a leader to get a really good evaluation of any one supplier at any one time. This tool allows our leaders to actually do that. You can see here what it will do is take all the survey information, all the survey responses provided by AT&T engineers and does things like sentiment summary, came in clustering for issues to get all those out. And provides a review summary in the middle of the page here that allows us to quickly understand what the performance of a supplier is. We can even drill down on the positive or the negative issues that we see here. Included in what the engineers built was a chatbot that can interact with everything that the user sees on the page and ask additional questions about the supplier and give us the information that we need to make actionable decisions inside the network every day. You're probably going to say this doesn't look like everything else we've seen in Foundry or AIP and you're right and that's because it uses the OSDK to integrate seamlessly with our existing applications. This is a great tool and I would love everything that we build to be in Foundry or AIP but a lot of our users still use some of our legacy tools. This allows us to bring the old and bring it with the new and get Gen AI incorporated into their everyday workflows. With that, thank you. Thank you.