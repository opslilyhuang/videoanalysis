================================================================================
METADATA
================================================================================
Title: Operational AI for Critical Institutions | Palantir CEO Alex Karp at CERAWeek
URL: https://www.youtube.com/watch?v=hkeohWt6rGA
Published: 2023-03-08
View Count: 31,196
Duration: 2041 seconds
Score: 45.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: whisper

================================================================================
TRANSCRIPT
================================================================================

You're in for a treat. I think this is going to be one of the most fascinating discussions you hear over the course of Syracuse, which is saying a lot. Technology, algorithms, algorithmic warfare, energy, the power of information. Increasingly what we've seen is that information is transforming the way that we think about the world operationally in terms of costs, in terms of efficiencies, but it's also transforming geopolitics and security and the way we think about it for the future. And to help us go through this discussion, we have two people who have, we're at the center of this in our practitioners. First Alex Carp, the CEO of Palantir, a revolutionary, someone who is a revolutionary in the world of information and Bob Dudley, the chairman of the Oil and Gas Climate Initiative, and prior to that, the chairman of BP and CEO of BP. And together you've also done an amazing amount of work and we want to come and explore this. But Alex, let me start off with you. And can you tell us how the use of information has changed and been applied from data which is available to data which has applied and changing the ways that decisions are made in both business and in politics? Well, first of all, I'm very happy to be here, honored to be on stage with both of you. It's been a long journey in building a business and one of the more important people in building it is here to my left. So it's, I think, one of our first commercial clients and at the time we were not well-known and we were only known for government. It was a huge chance to, so grateful that you're here and honored to be here. So we began building products, honestly, our internal version is to support the West, meaning America and its allies. Against its adversaries, roughly 20 years ago when data was viewed as, we barely got funding because the VCs and their wisdom told us data is not valuable, governments are worthless. There'll be no value to building platforms for governments with data or commercial entities and you don't have a business. So in any case, it's a very different time than now where everyone has a business in data. Most of these businesses don't work. So the first thing we, to go through a progression that we built a product called PG, which allows you to find terrorists through analytics while protecting civil liberties, which is a very hard thing to do, actually, because you have to rebuild the way software is built, because you have to take apart things and I won't go into all the details, but can catenate and decon-catenate the data. Otherwise, you can't deploy the product in most of the West. So if you can't just go out and find terrorists, you have to show it conforms with law. Now, this product, which powers a lot of Intel servers in the West, was able to reduce terrorism, especially in Europe dramatically. And that reduction in terrorism, I think, changed the arc of who got elected in Europe over the last 10 years, because de facto, the rise of the far right was muted because terrorism, in accordance with their data protection laws, was stopped. And so you've seen far, far fewer terror attacks in the West. And it's not only because of this product, but it's, you know, and then we built another set of products, commercial products, every if you're vaccinated in the US or Britain, or you got a mask that was distributed in our products. And I guess most famously, we build products of war, which we'll talk about later. But the super interesting thing about what's happened in information is it went from something that's useless and affraud to something that has changed every institution we're involved in, how you fly, where you fly, how the product, how your planes are maintained. That was like a phase where data, like oil and gas, is the processing of it and processing of it has to happen according to norms. And then you have an output. And now we're moving into a phase where that processing of the data is going to be done with algorithms. And you have lots of issues around that. So, you know, what's the handoff function for an algorithm? When is the algorithm deciding? When does a human decide how to institutions that are regulated, like every institution come to terms with that? And now we're moving into kind of a, from useless to political changing to potentially dominant. So the institutions, and we've seen this in the Ukraine war, and we see this in innovative industries like BP. But the institutions that actually can implement tech and now can allow, can interact with tech that implements itself. So, more AI generating code, AI generating algorithms in the context of norms are the institutions that win. So it went from joke to cosmetic to changing your life without you realizing it. The almost no one in Europe realizes the impact our product had. We sign all these contracts, we're not allowed to say where we, but we get protested against. That's why one of the reasons we work so well with oil and gas companies is we know it's like we protested against while doing something we believe in. And change your life, you don't realize it. Now we're in the phase where it's changing your life and it's not just the human, it's the human and the algorithm, and you kind of know it. And how does society come to terms with that? Bob, it made you a believer. Well, it's pretty extraordinary story. We had a number of problems in BP for a while in the early part of the last decade. We pieced up for big problems. We were dealing with the Gulf of Mexico spill and had issues, we had legal issues. And I won't go into that, but unbelievable. That's what opened my eyes. Unbelievable ability to see data from all different directions, put it quickly, like within days, and visualize it. We realized how big our problems were at that point. But then I thought this is amazing because I used to be a production engineer in the North Sea. And I remember what it was like. You had your well file, and there was a geologist down the way, and it was offshore equipment data, 20 years of history on the well. I said, Alex, do you think your team could maybe simplify this process? So to intrepid, Palantir, people came in. I think they worked the weekend and came in, and they put this into some program you have. The engineers, the geologists, and offshore were just amazing. It was suddenly like all that friction, I'm getting all this stuff together, to make decisions was done like that. So I thought, hmm, okay, let's expand this. Never wanted to make it a top-down initiative in the company. So pick different parts of BP around the world. It might have been retailing, what's on the stocking shelves. It might have been optimizing refinery. Going to places like Azerbaijan and sorting out something called sand control, which won't mean anything to most of you, but it's a big deal. And it just took off. And the engineers and the people that were all working on them always worked really well with your engineers. I guess you call them engineers or software engineers or smart people. Really smart people. And then we said, okay, let's try something that we have a giant field in Oman that we've discovered and we want to build it out. And what you would have done is you would have got engineers, put it on a grid, and you had a plan to drill all the wells. And it'll be just like this, the flow lines and the facilities. And you said, one of your teams said, we might be able to do that better for you. Let's start with the first well. What does it look like? What's the subsurface? Look like what are the temperatures, the pressures. And you put that in the model we thought we had. Every single well was different. So there's an oil, a giant gas field in Oman that's built out like capillaries in the human body. It was done half the time, much more efficient, great, great investment. And they helped us with that. So then suddenly I was faced in the company with everybody wanted to use volunteer because it was demand pool. And so we had to prioritize it. But I have to say revolutionized BP, BP people at 1% of volunteer to align what we were doing, which was also another good investment. And we had an exclusive agreement in the energy industry. So I'm really grateful to the talent there. And that's how I found out what big data was through all that stuff. And Alex, you've gone from the oil and gas industry to the world of defense. I don't know how much you can tell us about what you've done in Ukraine. It's certainly been impactful from some of the side stories I've heard. But let me give you an open field and let you talk about what you can talk about in terms of the transformation that you've made there. Well, we were laboring in, we had these weird ideas about products we should build. And most of them don't look valuable. So we built a mapping technology which allows you to integrate. It's built for the special forces. Many of the special forces use it. And then we, there's a lot of, it's very similar actually to oil and gas. There are all these technical challenges that people on the outside don't believe exist. People on the inside know are really tough to solve. And so we built a number of things. But the most important thing we built, of course, Silicon Valley that loves to talk about its mission was not willing to support the US government's efforts to build AI. At the time, this was five years ago, we thought AI was a joke. And every one time at AI, we're like selling snake oil. But we didn't want people working on this that we didn't think we're good at software. And there's one of these, I wouldn't call it bigotry, but I'm very skeptical and hardware companies want to build software so everyone that was signed up for this project was a hardware company that buying large doesn't work. So we agreed to work on this and build products. And what we built was what warfighters call a kill chain, what we in public call something else. But it basically, it has certain characteristics. At a high level, you can use AI meaning you can use algorithms to identify targets on any data source, which is, again, those of you in the oil and gas business it's like very similar to this. That sounds easy. It's actually crazily hard because satellite data are different than sensor data. And the data streams have to be segmented for security reasons. And then in the context of building a kill chain, one thing that another thing it's not quite understood is there's an ethics to AI in the military. You can't just have the out, first of all, you can't have the algorithm decide when to engage. When is the human in the loop? Who decides what targets are allowed? What distance from a hospital or a school can a target be taken? What family members or other people can be in the cause? And then at what point is the handoff function happened? And then the after action report requires a handoff function as well. Did the algorithm work? What were the feeds? You have to be able to look into the feeds and see what inputs the word of the algorithm before taking a human life. And these things are crazy important. And we built a whole set of technologies for that. So that's some of this you have to use your imagination for. But the part you don't have to use your imagination for is the Ukrainians, there are certain inputs that have changed in the fighting of war. So one input is the Ukrainians are heroes. Whatever you think of our efforts there, I've met you will not meet a group of people that are more willing to fight for their cause than them. And they're very good technically. So that's not us. But another input that has changed is you can see a, you know, Russia's been spending $65 billion a year on military for decades. And you have a country which essentially started from nothing that has done very, very well against them. And this just shows the power of algorithmatic warfare plus hero actually can change the course of history and has changed the course of history. And this single event will change how everyone fights wars. Because if a country can spend a couple billion dollars and have, you know, tough heroes and can be a large country that's very similar to that to a startup destroying a large company. And it just shows you what the power of these things are. And so that the good news is these weapons of war are in our hands. The bad news is everyone now knows it. And, you know, our adversaries mainly China and Russia are going to work very, very hard to build similar capabilities. Fascinating. The transformation of defense and the creation of intelligent defense. If we think about that being applied to, let's say, strategies in the US defense budget, what kind of implications could it have on what you would spend on and how much it would cost? It's going to get me into trouble here. But, okay, something I like to tell people again somewhat in private, but since you're such a good interviewer, it's like I run around Congress and Senate and when the door closes, I say, could we spend 5% of our budget on something that scares the bejebres out of our adversaries? Now, or like, now, it's like, I don't believe that, of course hardware is necessary. Of course, we have some of the best hardware providers in the world. But our single advantage in America is in building operational, institutional software that allows you to target our adversaries. And we are the best in the world at this. And now, it's not just, and then we have to avoid buying something, and this is something I would caution you, you have to avoid buying software from a PowerPoint. If you listen to what Bob did, he's like, okay, that seems interesting. He seems kind of odd. I'll test it. Software has to be proven on the bat. Software on a PowerPoint, like every jurisdiction of the world copies our power, our software, and makes it into PowerPoint, that stuff doesn't work. We need to focus on, the USD to focus on, increasing the size of the budget to at least 5% on software products, meaning it actually works before it's not a bespoke system. It actually has been proven on the battlefield. And as at a common sense level, this is something our adversaries do not have and scares them. And, you know, the best thing we can do to make American as allies strong enough so that maybe less good actors don't act up is to make sure we're actually spending our enormous resources on things that really, really work and are terrifying as opposed to things they have, they have the same stuff. They're not scared of the same missile we have, no, I'm not against, I don't obviously we shouldn't stop missile production, but it's, you know, that we, you know, one of the lessons you learn in building a disruptive business is you have to really focus on what you're really good at and not focus on what your neighbor is good at. And then you just focus and focus and focus and focus and focus on this. And not just America, but every single Western government needs to have an internal program. How good is the software we're buying? Are we just buying it because we, it's from our neighbor or our local vendor or because we like the person? That's, that is the single most dangerous thing we are doing in the West and the, in the most weakening thing we do. So the critical thing here is to have the knowledge to change impact. You need to develop, it's actually quite hard. Again, I, a lot of people are from oil and gas. The metaphor I would give you is a lot of people, most people are not in industry, do not know how hard the engineering challenges are. So this is like the, you have to develop a capacity to know the difference between PowerPoint bespoke thing that may work someday, that you may be should invest in and something that has actually been proven on the battlefield. And it's actually harder to do than you think. The Ukrainians do this well. You have, you know, we have allied countries who are very good at this, but it is the difference between our spend scaring our adversaries and our spend not scaring our adversaries. Bob, as you implemented these changes in BP, was there a tension between defensiveness because we've already done, always done it this way versus I want more of it, which you outlined at the end. How did you manage that change in culture? Well, I imagine some of this interface work between that kind of technology and an organization is really important. The people are part of the culture and I think in our case that's why I didn't do it as a top down initiative. Did it by picking places that I knew they would be receptive, it would work, it might not work. And then it was by example. And then of course we used volunteer for things like in other ways, which was top down using it for detection of rogue trading. If you know an oil and gas, you really have to protect yourself from that. They had an amazing system which instantaneously told us that there were problems. We didn't have any rogue traders, but there were patterns. So I'm guessing similar to with BP, your people in your company have to interface that this is used in the right way at the right time, right next to them, rather than from far away you've given them a program and an algorithm. Yeah, but this is true, but one of the things that you're saying that is just one of the things that you know, it was made you such an extraordinary business person is you really do have to shepherd your organization into change, especially with technical people. The idea you're going to tell technical people buy this and use it against their will. Yeah, if they'll tell you yes, when you close the doors like it would ever the boss does. That's not, you know, that's just not an engineer's work and it can't work that way because there are a lot of safety and other issues where they're experts and you need the experts. Yeah, no, it varies in different parts of our different products quite frankly. If you're buying, you need a, you know, some areas like you know, the digital kill chain, you know, kind of you see it or and then maybe the products that are not well known, we do a lot more hand holding, but it depends, we now have five products and some of them are de facto the norm. But since the newer things we're building, we have something to manage other software programs appall, that's definitely one where we're sitting with people. You're going to have to use chat GPT to figure out a different name for digital kill chain. Well, it's not, it's definitely not the public, I guess we may be on TV, but it's, we've been, I've been encouraged internally. It's actually a huge debate internally because I, you know, we sometimes call it metaconstellation, metaconstellation is actually another product and then, but then like we already have a lot of hate mail when I'm talking in public and so I try to get, in any case, but it is actually, but the interesting thing about, as I mentioned, the interesting thing about a, the dangerous technology and all technologies. So what we're doing that's most radical is, is not even that, it's the net, the, all future enterprises are norm driven meaning your internal dynamics are controlled either by laws or by ethics or by the way you work or by safety. So norm driven institutions and AI and the convergence private networks. So you have open AI that's like public AI on private networks require a handoff function. So when is the AI used? When is it not used? When is it ethically relevant? When can it be forbidden? And do you have a taxonomy of all decisions and all data sources going into the algorithm? And that, that, that is going to be what every single institution in the world is going to confront in the next year. And institutions that figured this out are going to thrive and institutions that don't, and I would say, you know, since we're in Houston, that one of the biggest advantages this country has, America is just, it's crazy adaptive. So, you know, in a lot of other countries we have a large international business, but I would say you have this very, you have a slowness like, well, what are we doing yesterday by only buying things from the company you bought for the last 10 years? The ability to say, hey, okay, well, in the past, you know, software was a joke or it was not meaningful or was a tax, then it moved to things that are moderately useful. Now it's going to drive some parts of my enterprise, but not drive others. And how do you do that in a context like in a healthcare context where actually algorithms can't touch every part of your data? How do you do it in a, in a oil and gas context where the regulator does not believe your emissions data? Well, how do you prove to the regulator that you've actually outperformed the norms that they're imposing on you? Let me ask a hypothetical, present a hypothetical situation and you may not talk to me afterwards because it's a two-fear, unfair question. But the most challenging relationship that the United States has today internationally and on a security front, on a commercial front is with China. And if we took these principles of AI and said, all right, let's apply them to this relationship. We know the Taiwan situation, the security issues that are related to that. We probably have a pretty good understanding that how that is managed is also going to have ramifications around a whole series of regional relationships, including trade. Could we be a lot smarter about the way that we designed our security and foreign policy strategy around an issue like China and Taiwan if we had better the better? Well, there's a kind of rhetorical answer, which is actually what I believe and then I'll give you more. If America were to implement what we, you know, it's like this thing to know what institution knows. If we implemented effectively what we have, it would be much more likely we'd have war in the world because like the software and hardware capabilities we actually can produce are the leading in the world and then I don't think adversaries really want to screw around with that. Now, on the software, what could America do to, first of all, there are a lot of code dependencies and ways in which the economy is intertwined that are only impossible, only possible entangle with software. So the first step would be what is actually the lay of the land and that this just cannot be does you would need, you know, like data sets on IP and production and supply chains. You could analyze that in say, foundry and then generate a lot of understanding with human analysis and then with algorithms and that would tell you a lot about what our adversaries are planning, whether they're likely to do it under what conditions. That's actually something we're beginning to do with companies and because just basically we're not doing enough of that and therefore you really don't know where the adversaries encroaching and where it's not. And in some cases are instinctive response on problems like this is to impose sanctions and those sanctions may not get you very far, they become symbolic but the question that we're all really trying to think about is if you're trying to change behavior, what are those critical leverage points to be able to actually make that, make that to behavioral change possible? Yeah but again I think there's a lot you could do with software and I believe there's a lot you could do with our products but I think the biggest behavioral change honestly is fear. People don't attack people, they're afraid of, again, so I have this running, I'm a former PhD and I most obviously can imagine most of my family are academics and very progressive and I actually view myself as a pro-free speech progressive but I say it's ongoing debate with them all the time where they're like well people will follow the rule of law even if they have superior weapon review. I just view as nuts. I don't even understand that but that if you believe that you do not need advanced AI then you don't have to fund this. I have this intense fear of advanced AI on a personal basis, right? It's like infringement of information of data. Well that's actually a real and very important concern and again I don't know if I'm a ticket but like how do you, for example, we have a large business in Europe where they have GDPR we have, I would support, we should have in this country you have to protect the private sphere and that's why AI is going to have to have a handoff function. And what I mean by handoff function is exactly this and what are the data feeds going into the AI? For example in a you know are you actually going to be able to go let's say you know just to make it norm conformant you have an agreement with your wife that you will only estate sandwich on Tuesday every every month but somehow you really stepping out and you're getting a stake sandwich once a week that's your right but it's actually quite hard to protect that right unless you have a handoff function meaning what are the inputs going into the AI? What can the AI look at and what can it not look at? Because otherwise you will never have a stake sandwich and we all have a right to our various forms of a stake sandwich which is not sanctioned. And that's actually a hugely difficult technical challenge honestly you know you can look this up. Most people in American can I think really like my company and actually we do very well in Europe but we're controversial and and the but the interesting thing is we're controversial but we're bought there because to protect someone's right to have their proverbial stake sandwich on Tuesday is quite a hard technical challenge and if you want to protect that like in France you will have to buy an architecture that allows you to segment the data segment what control where that data is flowing so that an external partner can visualize it and now control the algorithm's relationship to that data because with with AI or even without it you know if someone has all access to your data they will be able to predict when and where you're going to have your stake sandwich before you even go out and get it and that that's not a society we want to live in that's not the way America should run it's not the way our western allies want to run. Bob on the issue of mitigating risk was this transformative? Oh yes it was the simple example of rogue trading although I'd much rather listen to Alex by the way although I think you should use it. We just got it cool down for a second now we're getting a little scared. Alex I think you should use digital KC it has more if you were heard earlier. I got to have you know we should do a road tour where I speak and then it's bleeped out and then you interpret it. It's like our road tour it's like a delay. That'd be entertaining. Bob's other way got a great sense of humor but he's smart enough not to do it in public. Okay well I get really serious about risk no. No but I mean the example of rogue trading is a great example of the expenditure and mitigated risk that made me sleep a better at night. And does Europe appreciate why they might sleep better at night? Well look some people I mean you know we look weird it really I mean Europe is a vast there's very different like we're I think you know we're very more popular maybe and it varies. It varies quite a bit but I don't think the thing is the Intel services are an enormous bind all a girl across the world. There've been you know in the last 10 years I know of 10-15 major terror attacks that were stopped in Europe. You know very world-class police and Intel services using our product. So but the Intel services of course don't go out and talk to their populations about that and there's got to be a better way to communicate that these things actually it actually does change the course. I mean I of history and you know but but I think there is a problem that there's it's very hard to discuss and therefore people underestimate how different their world would be had this had this not happened and again the requirements of data protection are so strict and actually again to use the stake sandwich I support those standards but it's it's normal software can't work under those conditions. Alex clearly I would think that there will be competitor countries competitor companies that are seeking to do similar things. Should we worry about that? Well I mean competitor companies I'm sure people are happy about you know keep keep us on the straight and narrow and the only thing I would say there is good companies. Yeah so just I mean countries. Well look China is very strong technically luckily for the west most of the AI capabilities have been focused on controlling their own population whatever one thinks about that and but again Russia and China and others will look at what happened in Ukraine and you don't you it's not building software is about knowing how to build it and knowing how to recruit the right people and knowing how to manage them and certainly Russian China know how to do this and I I'm quite certain they're off to the races and so that's why I think we really have to make sure in in in America and in the west we're we're not putting like tripping over our own you know just getting in our own way. I've said a number of times that I think we're at an inflection point in history because of the multiple challenges that we face today on the security side on the commerce side on the energy side and I think one of the things that you're illustrating is that at a point in time like that you need every single tool to be able to make the right decisions to guide us to be able to influence that and we simply haven't been using information and data. The only thing I would say this is not what you're implying but there's often an inference from that that we should throw out data protection we should throw out the norms that regulate our institutions we shouldn't have regulations around our health care regulations around privacy that protect us civil norms that you know presumption of innocence you know you could reduce crime to zero with my products but you would you would you would use you'd have to invent predicates not invent in the common sense way but like into it them and what what is very special about software and you saw this in the anti-terror context all over the world is you can both raise the moral standard and build better tech and so I know you weren't implying this but but but but very often the inference is let's okay we're at war with people who don't care about this therefore we should throw out these norms to win the war in fact I think it's much more likely that you win the war by by imposing the norms because then it requires you to be much more targeted in what you do how you do it and what will prevent us from winning against our adversaries is a breakdown and consensus and you know if you only have AI but no privacy well a lot of us including myself don't want to sign up for that I was actually trying to find a complementary way to end the conversation because we're over time but and the compliments you in the process but in the end you made another profound point and Alex this has been phenomenal Bob thank you very much for for joining this discussion and I think one of the things that we can take away from this is that we are at a point of of reinvention of not reinvention of inventing a new and we will discover things that we may not have imagined it could have phenomenal benefits to the world your commitment to norms and standards is refreshing you talk about ethics is absolutely critical and thank you for taking the time to discuss this with us at Sarawik Alex Barbarian I really appreciate it I really admit it