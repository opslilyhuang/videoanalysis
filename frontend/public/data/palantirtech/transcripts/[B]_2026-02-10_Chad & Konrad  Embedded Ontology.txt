================================================================================
METADATA
================================================================================
Title: Chad & Konrad | Embedded Ontology
URL: https://www.youtube.com/watch?v=yLD5I16XkOo
Published: 2026-02-10
View Count: 3,347
Duration: 1123 seconds
Score: 58.0/100
Rank: B (Basic - 基础背景资料)
Transcript: Available
Category: 
Source: youtube

================================================================================
TRANSCRIPT
================================================================================

I'm Chad Walkwist. I'm an architect at Palantir. Today I have Conrad who's a four-deployed engineer here at Palantir. We're going to talk everything edge, embedded ontology, edge ontology, all this great stuff. So thanks for joining me. Yeah, great to be here. So most people think about Palantir is this cloud-based, you know, SAS or pass offering, which it is. We also have a lot more going on just like our engineers being forward deployed. Our software is forward deployed out to the edge where our customers needed and where they are. And so maybe today we're going to spend some time going through the different components of what makes up these edge offerings and how we deploy this. So, you know, I think there's a pretty cool graphic here that you can walk us through a kind of high level. Let's look at some software too. Yeah, for sure. Yeah, as you said, Foundry generally, you know, sits in the cloud, but there's a lot of stuff that we do in the edge environment as well. So the way that we think about this is you can really think about edge as a continuum, right, all the way from like a full metal on premise deployment of Foundry to a lightweight version of where you deploy single servers into edge environments. And that's specifically where I spend a lot of time in the manufacturing and industrial segment with our customers where we deploy these single servers into plans, into manufacturing operations to allow real-time operations and disconnected operations to really take place. It's very cool. Well, let's just jump into this software that we can use. This is a good reference point for us to come back and forth to kind of show how all these things connect together. But the most exciting thing I like to see from engineers is the working products. So let's take a look at that. All right. Yeah, let's jump into some software here. I'm looking at the application, the command control application for the Onyx manufacturing company, they manufacture medical devices. This is a view that a production manager would see. Basically, this allows a bird's eye perspective on all the relevant metrics in real time about my plant. Uptime, first time fixes, schedule compliance and all the relevant KPIs that I'm tracking. As well as here in the middle of the screen, you can see the production lines that I'm responsible for. And you can see in like a singular glimpse like what's going well, where do we need to spend time, like where are our problems occurring in real time that we need to respond to? Yeah, and so this is this is built right out the edge for like low latency because or disconnected. So that is like this is happening real time. I might even be writing back to my SCADA systems to make things happen in the blue the plant floor and I can't work if it's disconnected or the round trip to the cloud is too long. So like this is running on like a single node out of the edge somewhere right and then gives us that capability. Correct. So this runs on a single node in the Onyx plant. So this is a single server that's powering this. And on that single server, there's the local ontology of the embedded ontology running that powers that powers this real time application. And it's connected to like you were saying, it's connected to the brokers, the sensors, the PLCs, all of that data that sits on the manufacturing floor that powers these that that powers this bird's eye view. Yeah. And so having the local ontology is bringing that stuff together, but you also have access to the cloud ontology that might have your ERP and master data and engineering standards that then you can bring all those together to these edge applications to run in that disconnected or high, you know, high performance real time space at the edge. And so I think that's where you get the benefit of the ontology at the edge, but also the cloud capabilities to sync things across. Yeah, you can be the interesting thing here is that you can even start becoming real intentional about where does what sit in your stack, right? So the raw telemetry data that you're looking at that should probably sit on the on the local ontology versus like your ERP or information that concerns larger use cases they should sit in the cloud. And so you can be intentional and bidirectional about this, which is really exciting and I can show you that a little bit. Awesome. Well, let's keep going. I'll just take a look here. Yeah. All right, so let's jump into one of these lines and we can understand them a little bit deeper and we can traverse our ontology here and understand like what machine really actually sits on this line. So if I jump in here, I see this telemetry data that we were just talking about embedded in SPC view, statistical process control view where I can you know, set up rules to then actually manage if there's drift or any problems that are occurring on my sensors. Very cool. So I've got real time telemetry data against this process controls and then alerting to those things. So now I can take action when we're kind of out of norm. Yeah, and I think there's an interesting point here that I want to make, which is like it doesn't have to be tabular data or numerical data that we're streaming. I think we can think about this also as sort of like in our like multimodal data plane, it's you know, something that we talk about a lot. So we can think about this also as sort of like video streams, right? There's some information that's coming from sensors, video footage and so on that we can then pull out and make useful as part of this application. Yeah, yeah, computer vision is definitely the the sexy fun thing, but it's like the universal IoT device that since you can apply different models at you know, at runtime. And so I think that's it's pretty cool that we can integrate both tabular and unstructured data at the edge and back in the cloud, you know, be able to manage those models. That's pretty neat. Yeah, and I think this is like a good point to talk about sort of that first loop that we just like hinted at, which is kind of the loop from edge to the cloud. Right? So especially when we look at that, all of that elementary data, not all of that is interesting, irrelevant, right? Like a lot of this stuff is like it's working as intended. There isn't any problems, there isn't any drift. But as soon as we have, you know, indicators that there are problems and there are things we want to talk about and want to detect that that sort of like should be part of a larger use case where we then you know, revisit design, understand, understand sort of the consequences of that work with our suppliers and so on. And so we can be intentional about what we actually then stream stream to the cloud. So if if I can, you know, go into detail here like we can then actually look at, you know, which data points we're we're deciding to stream into the cloud. And then from there, cloud side, we can then build applications on top of this. So if I hop over into an application that sits on the cloud, this would allow me now to use these SPC data and use these statistical issues that are that are that are upcoming and feed them into an agent that allows me then to build, you know, issue resolutions, take it on top of those and integrate that into our like global ontology. That's very cool. So just to like recap that capturing kilometer data looking for things outside of the control ranges, creating alerts that go back to the cloud, then I'm using LLMs in the rest of ontology with our agentic framework to then actually disposition what's going on. How should I triage it and then like what should I do with then even maybe like create a ticket for someone to go take action. All of that both edge and cloud happening seamlessly. Exactly. Yeah. And we can we can be intentional on how we're communicating between those points. And then we can also, you know, go all the other way. So that tickets can go back into the edge or, you know, the thresholds that we then have to configure go back into the edge environment. So the the bidirectional bidirectionality of it is, I think, important. Yeah. Yeah. And that's one of the hard things about the edge and I or T and other things is like just managing the sink and the number of endpoints you have and how do I actually deploy software and manage it at the edge like a lot of those complexities are there. But I think this is pretty neat that we now have this seamless way to be able to sync data through just ontology and the edge embedded ontology. Yeah. And and the overall management of this right is done is done through our polyester. If we if we look in, you know, in the our overall our overall architecture, we we are now just looking at one edge device at one like a server that sits in that plant. But you know, a lot of our customers are managing, you know, tens or hundreds of dollars in various different plants. And we're leveraging a poll to make sure that, you know, foundry cloudside is in sync with the edge side as well. So that's that's all within sort of like our software stack. Yeah. Yeah. I think that's the you know, Apollo is kind of the the dark horse here that most people don't think about, but allowing it to not only manage the cloud, you know, instances and tenants for our customers and for us. But for us to be able to use that to deploy out and manage software of the edge is is pretty important. I think that goes across so many different aspects of like, how do I just maintain and make sure I'm secure and everything else like all the normal stuff. But now I've got 10,000 of them out of the edge. That problem is very difficult, but that's where Apollo is like just clutch. Yeah. Exactly. I think the other interesting loop, like we just talked about local ontology and global ontology and that connection. I think the other interesting loop chat is the loop back into the PLC layer and back actually onto the manufacturing floor. So if we dive into that a little bit and jump back into our application, we can visualize sort of the production flow of the syringe line that we were just looking at. How each sort of item goes through each machine and how the sensors are interacting on that basis. And I think we can leverage the statistical process control and what we've just learned about, you know, the bounds basically to tighten up the PLC's logic and the latter logic as well. So we can then write back to the PLC layer to then, you know, make better decisions on the on the shop floor itself. Yeah. Wow. The fact that we now can actually then understand what needs to change and make those changes real back to the PLC's and sensors and controls like that's pretty cool to be able to really close the loop all the way there. Because now now that I can also then measure did that have the intended consequence on the outcome. I'm looking for that I'm measuring in the other part and that's the continuous improvement, you know, oot aloop that we're going for. Exactly. Yeah. And I think it's to your point of continuous improvement, right? Like we can use like in this case, we're looking at like rejections. We can use like when there's been a rejection and pull that back into the cloud and have a larger workflow around around quality control and end of line testing and all of these things. So you can start to see how these things actually like work together, work to well across cloud, across it of like the the machine skater PLC layer to sort of the edge layer. Yeah. And just to bring the point home here too, we've said it, we've kind of alluded to it a few different times, but like this can run in a disconnected state at the edge. So if internet connections down and you have spotty connections, whatever is going on, like this can run and stand alone. And then when I gain connection back in, I can sync the data I need to, I can pull new data back down so that disconnected state that then is allowed to be able to sync back up when coming back online, that's the kind of the store and forward piece. That's another component of the IOT kind of framework that's important. And that's here with the edge of ontology. Yeah. That's that's super important. The local ontology has everything that it needs, has to storage the runtime, the necessary pieces to operate these applications without network connectivity. And so these things allow operators to use these in environments where there's just spotty network or disconnected disconnected altogether. And so you can have these things where you use it, it stores these information about recent rejections or things that we've learned and then as soon as these connectivity, that syncs up back into the cloud and we can use that for our analytical or other workflows. But that's something in practice and on the ground, that's huge for our customers because it's just the fact that like plans are not like offices, right? So there's just you know, oftentimes you're in the spot where there's, where there's dead spots or you don't have connectivity. Yeah. Yeah. And so it's like all of these challenges together on their own are kind of difficult. But then you put them all together to make that cohesive picture we're talking about work. That's a lot of engineering and a lot of work. And I think that's really where the volunteer edge components come together to make that easier to manage at a scale. Yeah, exactly. And I think like it's really about the operators right at the end of the day like the extending the software to where it's most needed. And in these manufacturing industrial environments, you just you don't have the luxury of time. In a lot of these cases, you need to make a decision right now. And I think that's where we're rising up to the occasion with this, allowing you to scale these workflows in a disconnect in a real time way. Yeah. Very cool. All right, so that's pretty cool to see some of these different components in action. And we see the overall architecture here. Like what use cases does this unlock for our customers by having this capability? Yeah. So we really focused on sort of the manufacturing and industrial space. So a lot of this sits in the plants themselves. So production monitoring is a big one, right? So how do you respond in real time to issues that are occurring on the floor? I think the second one is around how do you actually then drive decisions and better decisions on a, you know, on a machine layer. So on a POC layer. And I think there's a lot of intelligence that we can bring from the cloud to the edge server to the PLC layer where customers use it. And then third is really what we just talked about a lot is like closing the loop, right? There's a lot of use cases where that production data is super valuable to then make better quality decisions, make better decisions when it comes to your design, make better decisions when it comes to like how you're working with your suppliers. So it's like the enterprise strategy around those, right? I think like on a larger picture. So that's probably the progression around these, like helping, you know, the plants specifically to operate better and then feed that into my global use cases. Yeah. Which is funny. I often say about like, I move from local optimization to global optimization. Usually that's in the frame across different business use cases and frames. But like in this case, it's the local physical place and I'm moving to global optimization across facilities, plants, everything else. And so that really about scaling that optimization across everything you're doing to close the loop. It's pretty cool. What other things are you most excited about? So as we're moving heavily in this direction, like what is the thing that has you most excited to do that on that you're working on? Yeah, I think like there's a couple of things on the horizon that are really interesting. I think the first thing is like, how do you scale this well within sort of one customer environment, right? Like I said in the beginning, we're not talking about one edge device in a lot of places where we're talking about tens to hundreds of them. We can do it from a software layer, but how are you thinking about it from a use case layer, from a consumption layer, from a resource management, right? Like all of these things that a solution architect on a customer side really cares about in an enterprise environment, making that easier for them to manage and then ultimately also deploy software across those environments. That's probably the next ridge that I'm really excited about. The other piece that that also is interesting is a lot of these edge devices come also with significant firepower when it comes to sort of like GPUs that we can leverage to also run local models. So that might not be relevant for all use cases, but for some of these where you want to run local models in these plans as well, that can be interesting. Yeah. Well, that's music's my ears because the thing I talk about is if it's not a production, it's not even value. And what you're trying to do is help people get the stuff in production, adding value, making a difference in their business. So that's pretty cool. Well, thank you, Conrad, for taking the time today. Show us a little bit about some of the volunteer edge work we're doing. I really enjoyed the conversation. Absolutely. Thank you so much.